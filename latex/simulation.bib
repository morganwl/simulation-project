@misc{__,
  urldate = {2023-05-06},
  howpublished = {https://scholar.googleusercontent.com/scholar.bib?q=info:hcjcll3qev0J:scholar.google.com/\&output=citation\&scisdr=Cm0CgsoqEMKlo\_eNRy0:AGlGAw8AAAAAZFaLXy0kOVBndeiJ-x1eSWWYpM8\&scisig=AGlGAw8AAAAAZFaLX3kzN5TRZi4u38niT5gUjpA\&scisf=4\&ct=citation\&cd=-1\&hl=en},
  file = {/home/morgan/Zotero/storage/P546XT6X/scholar.html}
}

@article{_pertDistribution_2023,
  title = {{{PERT}} Distribution},
  year = {2023},
  month = dec,
  journal = {Wikipedia},
  urldate = {2024-01-09},
  abstract = {In probability and statistics, the PERT distributions are a family of continuous probability distributions defined by the minimum (a), most likely (b) and maximum (c) values that a variable can take. It is a transformation of the four-parameter beta distribution with an additional assumption that its expected value is                        {$\mu$}         =                                                a               +               4               b               +               c                          6                             .                 \{{\textbackslash}displaystyle {\textbackslash}mu =\{{\textbackslash}frac \{a+4b+c\}\{6\}\}.\}   The mean of the distribution is therefore defined as the weighted average of the minimum, most likely and maximum values that the variable may take, with four times the weight applied to the most likely value. This assumption about the mean was first proposed in Clark, 1962 for estimating the effect of uncertainty of task durations on the outcome of a project schedule being evaluated using the program evaluation and review technique, hence its name. The mathematics of the distribution resulted from the authors' desire to make the standard deviation equal to about 1/6 of the range.  The PERT distribution is widely used in risk analysis to represent the uncertainty of the value of some quantity where one is relying on subjective estimates, because the three parameters defining the distribution are intuitive to the estimator. The PERT distribution is featured in most simulation software tools.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1192030410},
  file = {/home/morgan/Zotero/storage/QAQYXT4L/PERT_distribution.html}
}

@misc{_subwayBus_,
  title = {Subway and Bus Ridership for 2021},
  journal = {MTA},
  urldate = {2023-12-23},
  abstract = {In 2021, subway and bus ridership continued its recovery from the unprecedented low ridership resulting from the COVID-19 pandemic. See our total subway and bus ridership of 2021.},
  howpublished = {https://new.mta.info/agency/new-york-city-transit/subway-bus-ridership-2021},
  langid = {english},
  file = {/home/morgan/Zotero/storage/5EKSD3TL/subway-bus-ridership-2021.html}
}

@misc{905,
  title = {9:05},
  author = {Cadre, Adam},
  year = {2000}
}

@inproceedings{abebeRolesComputingSocial2020,
  title = {Roles for Computing in Social Change},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Abebe, Rediet and Barocas, Solon and Kleinberg, Jon and Levy, Karen and Raghavan, Manish and Robinson, David G.},
  year = {2020},
  month = jan,
  pages = {252--260},
  publisher = {{ACM}},
  address = {{Barcelona Spain}},
  doi = {10.1145/3351095.3372871},
  urldate = {2022-05-26},
  abstract = {A recent normative turn in computer science has brought concerns about fairness, bias, and accountability to the core of the field. Yet recent scholarship has warned that much of this technical work treats problematic features of the status quo as fixed, and fails to address deeper patterns of injustice and inequality. While acknowledging these critiques, we posit that computational research has valuable roles to play in addressing social problems {\textemdash} roles whose value can be recognized even from a perspective that aspires toward fundamental social change. In this paper, we articulate four such roles, through an analysis that considers the opportunities as well as the significant risks inherent in such work. Computing research can serve as a diagnostic, helping us to understand and measure social problems with precision and clarity. As a formalizer, computing shapes how social problems are explicitly defined {\textemdash} changing how those problems, and possible responses to them, are understood. Computing serves as rebuttal when it illuminates the boundaries of what is possible through technical means. And computing acts as synecdoche when it makes long-standing social problems newly salient in the public eye. We offer these paths forward as modalities that leverage the particular strengths of computational work in the service of social change, without overclaiming computing's capacity to solve social problems on its own.},
  isbn = {978-1-4503-6936-7},
  langid = {english},
  keywords = {ethics,frameworks},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Abebe et al_2020_Roles for computing in social change.pdf}
}

@misc{adamsAdventureland1978,
  title = {Adventureland},
  author = {Adams, Scott},
  year = {1978}
}

@misc{adamsHitchhikerGuideGalaxy1984,
  title = {The {{Hitchhiker}}'s {{Guide}} to the {{Galaxy}}},
  author = {Adams, Douglas},
  year = {1984}
}

@article{adhikariLearningDynamicBelief2020,
  title = {Learning {{Dynamic Belief Graphs}} to {{Generalize}} on {{Text-Based Games}}},
  author = {Adhikari, Ashutosh and Yuan, Xingdi and C{\^o}t{\'e}, Marc-Alexandre and Zelinka, Mikul{\'a}{\v s} and Rondeau, Marc-Antoine and Laroche, Romain and Poupart, Pascal and Tang, Jian and Trischler, Adam and Hamilton, William L},
  year = {2020},
  pages = {13},
  abstract = {Playing text-based games requires skills in processing natural language and sequential decision making. Achieving human-level performance on text-based games remains an open challenge, and prior research has largely relied on hand-crafted structured representations and heuristics. In this work, we investigate how an agent can plan and generalize in text-based games using graph-structured representations learned end-to-end from raw text. We propose a novel graph-aided transformer agent (GATA) that infers and updates latent belief graphs during planning to enable effective action selection by capturing the underlying game dynamics. GATA is trained using a combination of reinforcement and self-supervised learning. Our work demonstrates that the learned graph-based representations help agents converge to better policies than their text-only counterparts and facilitate effective generalization across game configurations. Experiments on 500+ unique games from the TextWorld suite show that our best agent outperforms text-based baselines by an average of 24.2\%.},
  langid = {english},
  keywords = {belief graph,ethics,knowledge graph,natural-language,transformer},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Adhikari et al_Learning Dynamic Belief Graphs to Generalize on Text-Based Games.pdf}
}

@misc{Adventure2010,
  title = {Adventure},
  year = {2010},
  month = dec,
  urldate = {2022-05-01},
  howpublished = {https://web.archive.org/web/20101227192243/http://www.wurb.com/if/game/1},
  file = {/home/morgan/Zotero/storage/CJAJ9RS6/1.html}
}

@incollection{aho_exampleTree_1974,
  title = {Example 3.2: {{Tree Isomorphism}}},
  booktitle = {The {{Design}} and {{Analysis}} of {{Computer Algorithms}}},
  author = {Aho, {\relax AV} and Hopcroft, {\relax JE} and Ullman, {\relax JD}},
  year = {1974},
  pages = {84--86},
  publisher = {{Addison-Wesley}}
}

@book{allenNaturalLanguageUnderstanding1995,
  title = {Natural {{Language Understanding}}},
  author = {Allen, James},
  year = {1995},
  edition = {2nd},
  publisher = {{The Benjamin/Cummings Publishing Company, Inc.}},
  isbn = {0-8053-0334-0}
}

@misc{ammanabroluAligningSocialNorms2022,
  title = {Aligning to {{Social Norms}} and {{Values}} in {{Interactive Narratives}}},
  author = {Ammanabrolu, Prithviraj and Jiang, Liwei and Sap, Maarten and Hajishirzi, Hannaneh and Choi, Yejin},
  year = {2022},
  month = may,
  eprint = {2205.01975},
  primaryclass = {cs},
  urldate = {2022-05-25},
  abstract = {We focus on creating agents that act in alignment with socially beneficial norms and values in interactive narratives or text-based games -- environments wherein an agent perceives and interacts with a world through natural language. Such interactive agents are often trained via reinforcement learning to optimize task performance, even when such rewards may lead to agent behaviors that violate societal norms -- causing harm either to the agent itself or other entities in the environment. Social value alignment refers to creating agents whose behaviors conform to expected moral and social norms for a given context and group of people -- in our case, it means agents that behave in a manner that is less harmful and more beneficial for themselves and others. We build on the Jiminy Cricket benchmark (Hendrycks et al. 2021), a set of 25 annotated interactive narratives containing thousands of morally salient scenarios covering everything from theft and bodily harm to altruism. We introduce the GALAD (Game-value ALignment through Action Distillation) agent that uses the social commonsense knowledge present in specially trained language models to contextually restrict its action space to only those actions that are aligned with socially beneficial values. An experimental study shows that the GALAD agent makes decisions efficiently enough to improve state-of-the-art task performance by 4\% while reducing the frequency of socially harmful behaviors by 25\% compared to strong contemporary value alignment approaches.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Ammanabrolu et al_2022_Aligning to Social Norms and Values in Interactive Narratives.pdf}
}

@misc{ammanabroluGraphConstrainedReinforcement2020,
  title = {Graph {{Constrained Reinforcement Learning}} for {{Natural Language Action Spaces}}},
  author = {Ammanabrolu, Prithviraj and Hausknecht, Matthew},
  year = {2020},
  month = jan,
  eprint = {2001.08837},
  primaryclass = {cs, stat},
  urldate = {2022-05-25},
  abstract = {Interactive Fiction games are text-based simulations in which an agent interacts with the world purely through natural language. They are ideal environments for studying how to extend reinforcement learning agents to meet the challenges of natural language understanding, partial observability, and action generation in combinatorially-large text-based action spaces. We present KG-A2C, an agent that builds a dynamic knowledge graph while exploring and generates actions using a template-based action space. We contend that the dual uses of the knowledge graph to reason about game state and to constrain natural language generation are the keys to scalable exploration of combinatorially large natural language actions. Results across a wide variety of IF games show that KG-A2C outperforms current IF agents despite the exponential increase in action space size.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Ammanabrolu_Hausknecht_2020_Graph Constrained Reinforcement Learning for Natural Language Action Spaces.pdf}
}

@misc{ammanabroluHowAvoidBeing2020,
  title = {How to {{Avoid Being Eaten}} by a {{Grue}}: {{Structured Exploration Strategies}} for {{Textual Worlds}}},
  shorttitle = {How to {{Avoid Being Eaten}} by a {{Grue}}},
  author = {Ammanabrolu, Prithviraj and Tien, Ethan and Hausknecht, Matthew and Riedl, Mark O.},
  year = {2020},
  month = jun,
  eprint = {2006.07409},
  primaryclass = {cs, stat},
  urldate = {2022-05-25},
  abstract = {Text-based games are long puzzles or quests, characterized by a sequence of sparse and potentially deceptive rewards. They provide an ideal platform to develop agents that perceive and act upon the world using a combinatorially sized natural language state-action space. Standard Reinforcement Learning agents are poorly equipped to effectively explore such spaces and often struggle to overcome bottlenecks---states that agents are unable to pass through simply because they do not see the right action sequence enough times to be sufficiently reinforced. We introduce Q*BERT, an agent that learns to build a knowledge graph of the world by answering questions, which leads to greater sample efficiency. To overcome bottlenecks, we further introduce MC!Q*BERT an agent that uses an knowledge-graph-based intrinsic motivation to detect bottlenecks and a novel exploration strategy to efficiently learn a chain of policy modules to overcome them. We present an ablation study and results demonstrating how our method outperforms the current state-of-the-art on nine text games, including the popular game, Zork, where, for the first time, a learning agent gets past the bottleneck where the player is eaten by a Grue.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Ammanabrolu et al_2020_How to Avoid Being Eaten by a Grue.pdf}
}

@article{ammanabroluLearningKnowledgeGraphbased2021,
  title = {Learning {{Knowledge Graph-based World Models}} of {{Textual Environments}}},
  author = {Ammanabrolu, Prithviraj and Riedl, Mark O},
  year = {2021},
  month = dec,
  pages = {12},
  abstract = {World models improve a learning agent's ability to efficiently operate in interactive and situated environments. This work focuses on the task of building world models of text-based game environments. Text-based games, or interactive narratives, are reinforcement learning environments in which agents perceive and interact with the world using textual natural language. These environments contain long, multi-step puzzles or quests woven through a world that is filled with hundreds of characters, locations, and objects. Our world model learns to simultaneously: (1) predict changes in the world caused by an agent's actions when representing the world as a knowledge graph; and (2) generate the set of contextually relevant natural language actions required to operate in the world. We frame this task as a Set of Sequences generation problem by exploiting the inherent structure of knowledge graphs and actions and introduce both a transformer-based multi-task architecture and a loss function to train it. A zero-shot ablation study on neverbefore-seen textual worlds shows that our methodology significantly outperforms existing textual world modeling techniques as well as the importance of each of our contributions.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Ammanabrolu_Riedl_Learning Knowledge Graph-based World Models of Textual Environments.pdf}
}

@misc{ammanabroluModelingWorldsText2021,
  title = {Modeling {{Worlds}} in {{Text}}},
  author = {Ammanabrolu, Prithviraj and Riedl, Mark O.},
  year = {2021},
  month = jun,
  number = {arXiv:2106.09578},
  eprint = {2106.09578},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-07-07},
  abstract = {We provide a dataset that enables the creation of learning agents that can build knowledge graph-based world models of interactive narratives.1 Interactive narratives{\textemdash}or text-adventure games{\textemdash}are partially observable environments structured as long puzzles or quests in which an agent perceives and interacts with the world purely through textual natural language. Each individual game typically contains hundreds of locations, characters, and objects{\textemdash}each with their own unique descriptions{\textemdash}providing an opportunity to study the problem of giving language-based agents the structured memory necessary to operate in such worlds. Our dataset provides 24198 mappings between rich natural language observations and: (1) knowledge graphs that reflect the world state in the form of a map; (2) natural language actions that are guaranteed to cause a change in that particular world state. The training data is collected across 27 games in multiple genres and contains a further 7836 heldout instances over 9 additional games in the test set. We further provide baseline models using rules-based, question-answering, and sequence learning approaches in addition to an analysis of the data and corresponding learning tasks.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Ammanabrolu_Riedl_2021_Modeling Worlds in Text.pdf}
}

@misc{ammanabroluPlayingTextAdventureGames2019,
  title = {Playing {{Text-Adventure Games}} with {{Graph-Based Deep Reinforcement Learning}}},
  author = {Ammanabrolu, Prithviraj and Riedl, Mark O.},
  year = {2019},
  month = mar,
  eprint = {1812.01628},
  primaryclass = {cs},
  urldate = {2022-05-25},
  abstract = {Text-based adventure games provide a platform on which to explore reinforcement learning in the context of a combinatorial action space, such as natural language. We present a deep reinforcement learning architecture that represents the game state as a knowledge graph which is learned during exploration. This graph is used to prune the action space, enabling more efficient exploration. The question of which action to take can be reduced to a question-answering task, a form of transfer learning that pre-trains certain parts of our architecture. In experiments using the TextWorld framework, we show that our proposed technique can learn a control policy faster than baseline alternatives. We have also open-sourced our code at https://github.com/rajammanabrolu/KG-DQN.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Ammanabrolu_Riedl_2019_Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning.pdf}
}

@misc{ammanabroluTransferDeepReinforcement2019,
  title = {Transfer in {{Deep Reinforcement Learning}} Using {{Knowledge Graphs}}},
  author = {Ammanabrolu, Prithviraj and Riedl, Mark O.},
  year = {2019},
  month = aug,
  number = {arXiv:1908.06556},
  eprint = {1908.06556},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-07-08},
  abstract = {Text adventure games, in which players must make sense of the world through text descriptions and declare actions through text descriptions, provide a stepping stone toward grounding action in language. Prior work has demonstrated that using a knowledge graph as a state representation and question-answering to pre-train a deep Q-network facilitates faster control policy learning. In this paper, we explore the use of knowledge graphs as a representation for domain knowledge transfer for training text-adventure playing reinforcement learning agents. Our methods are tested across multiple computer generated and human authored games, varying in domain and complexity, and demonstrate that our transfer learning methods let us learn a higher-quality control policy faster.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Ammanabrolu_Riedl_2019_Transfer in Deep Reinforcement Learning using Knowledge Graphs.pdf}
}

@misc{andersonHollywoodHijinx1986,
  title = {Hollywood {{Hijinx}}},
  author = {Anderson, Dave},
  year = {1986}
}

@article{aroyoTruthLieCrowd2015,
  title = {Truth {{Is}} a {{Lie}}: {{Crowd Truth}} and the {{Seven Myths}} of {{Human Annotation}}},
  shorttitle = {Truth {{Is}} a {{Lie}}},
  author = {Aroyo, Lora and Welty, Chris},
  year = {2015},
  month = mar,
  journal = {AI Magazine},
  volume = {36},
  number = {1},
  pages = {15--24},
  issn = {2371-9621, 0738-4602},
  doi = {10.1609/aimag.v36i1.2564},
  urldate = {2022-06-12},
  abstract = {Big data is having a disruptive impact across the sciences. Human annotation of semantic interpretation tasks is a critical part of big data semantics, but it is based on an antiquated ideal of a single correct truth that needs to be similarly disrupted. We expose seven myths about human annotation, most of which derive from that antiquated ideal of truth, and dispell these myths with examples from our research. We propose a new theory of truth, crowd truth, that is based on the intuition that human interpretation is subjective, and that measuring annotations on the same objects of interpretation (in our examples, sentences) across a crowd will provide a useful representation of their subjectivity and the range of reasonable interpretations.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Aroyo_Welty_2015_Truth Is a Lie.pdf}
}

@misc{ArtComputerProgramming,
  title = {Art of {{Computer Programming}}, {{The}}: {{Volume}} 1: {{Fundamental Algorithms}}, 3rd {{Edition}}},
  shorttitle = {Art of {{Computer Programming}}, {{The}}},
  urldate = {2022-05-04},
  abstract = {Art of Computer Programming, The: Volume 1: Fundamental Algorithms, 3rd Edition},
  howpublished = {https://www.pearson.com/content/one-dot-com/one-dot-com/us/en/higher-education/program.html},
  langid = {english},
  file = {/home/morgan/Zotero/storage/2W3IJ4IF/PGM173687.html}
}

@misc{AssociativeCalculusEncyclopedia,
  title = {Associative Calculus - {{Encyclopedia}} of {{Mathematics}}},
  urldate = {2022-04-28},
  howpublished = {https://encyclopediaofmath.org/wiki/Associative\_calculus},
  file = {/home/morgan/Zotero/storage/L3U9LJN5/Associative_calculus.html}
}

@article{atkinsonTextBasedAdventureAI2019,
  title = {The {{Text-Based Adventure AI Competition}}},
  author = {Atkinson, Timothy and Baier, Hendrik and Copplestone, Tara and Devlin, Sam and Swan, Jerry},
  year = {2019},
  month = sep,
  journal = {IEEE Transactions on Games},
  volume = {11},
  number = {3},
  pages = {260--266},
  issn = {2475-1510},
  doi = {10.1109/TG.2019.2896017},
  abstract = {In 2016-2018 at the IEEE Conference on Computational Intelligence in Games, the authors of this paper ran a competition for agents that can play classic text-based adventure games. This competition fills a gap in existing game artificial intelligence (AI) competitions that have typically focused on traditional card/board games or modern video games with graphical interfaces. By providing a platform for evaluating agents in textbased adventures, the competition provides a novel benchmark for game AI with unique challenges for natural language understanding and generation. This paper summarizes the three competitions ran in 2016-2018 (including details of open-source implementations of both the competition framework and our competitors) and presents the results of an improved evaluation of these competitors across 20 games.},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Atkinson et al_2019_The Text-Based Adventure AI Competition.pdf}
}

@incollection{baaderLogicBasedKnowledgeRepresentation1999,
  title = {Logic-{{Based Knowledge Representation}}},
  booktitle = {Artificial {{Intelligence Today}}: {{Recent Trends}} and {{Developments}}},
  author = {Baader, Franz},
  editor = {Wooldridge, Michael J. and Veloso, Manuela},
  year = {1999},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {13--41},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-48317-9_2},
  urldate = {2022-05-25},
  abstract = {After a short analysis of the requirements that a knowledge representation language must satisfy, we introduce Description Logics, Modal Logics, and Nonmonotonic Logics as formalisms for representing terminological knowledge, time-dependent or subjective knowledge, and incomplete knowledge respectively. At the end of each section, we briefly comment on the connection to Logic Programming.},
  isbn = {978-3-540-48317-5},
  langid = {english},
  keywords = {Description Logic,Knowledge Representation,Kripke Structure,Logic Program,Modal Logic},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Baader_1999_Logic-Based Knowledge Representation.pdf}
}

@book{bach_designUNIX_1986,
  title = {The Design of the {{UNIX}}{\textregistered} Operating System},
  author = {Bach, Maurice J},
  year = {1986},
  publisher = {{by Prentice-Hall, Inc.}}
}

@inproceedings{badillaWEFEWordEmbeddings2020,
  title = {{{WEFE}}: {{The Word Embeddings Fairness Evaluation Framework}}},
  shorttitle = {{{WEFE}}},
  booktitle = {Proceedings of the {{Twenty-Ninth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Badilla, Pablo and {Bravo-Marquez}, Felipe and P{\'e}rez, Jorge},
  year = {2020},
  month = jul,
  pages = {430--436},
  publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
  address = {{Yokohama, Japan}},
  doi = {10.24963/ijcai.2020/60},
  urldate = {2021-10-12},
  abstract = {Word embeddings are known to exhibit stereotypical biases towards gender, race, religion, among other criteria. Several fairness metrics have been proposed in order to automatically quantify these biases. Although all metrics have a similar objective, the relationship between them is by no means clear. Two issues that prevent a clean comparison is that they operate with different inputs, and that their outputs are incompatible with each other. In this paper we propose WEFE, the word embeddings fairness evaluation framework, to encapsulate, evaluate and compare fairness metrics. Our framework needs a list of pre-trained embeddings and a set of fairness criteria, and it is based on checking correlations between fairness rankings induced by these criteria. We conduct a case study showing that rankings produced by existing fairness methods tend to correlate when measuring gender bias. This correlation is considerably less for other biases like race or religion. We also compare the fairness rankings with an embedding benchmark showing that there is no clear correlation between fairness and good performance in downstream tasks.},
  isbn = {978-0-9992411-6-5},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Natural Language Processing/Articles/WEFE- The Word Embeddings Fairness Evaluation Framework.pdf}
}

@article{bak-colemanStewardshipGlobalCollective2021,
  title = {Stewardship of Global Collective Behavior},
  author = {{Bak-Coleman}, Joseph B. and Alfano, Mark and Barfuss, Wolfram and Bergstrom, Carl T. and Centeno, Miguel A. and Couzin, Iain D. and Donges, Jonathan F. and Galesic, Mirta and Gersick, Andrew S. and Jacquet, Jennifer and Kao, Albert B. and Moran, Rachel E. and Romanczuk, Pawel and Rubenstein, Daniel I. and Tombak, Kaia J. and Van Bavel, Jay J. and Weber, Elke U.},
  year = {2021},
  month = jul,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {27},
  pages = {e2025764118},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2025764118},
  urldate = {2022-05-27},
  abstract = {Collective behavior provides a framework for understanding how the actions and properties of groups emerge from the way individuals generate and share information. In humans, information flows were initially shaped by natural selection yet are increasingly structured by emerging communication technologies. Our larger, more complex social networks now transfer high-fidelity information over vast distances at low cost. The digital age and the rise of social media have accelerated changes to our social systems, with poorly understood functional consequences. This gap in our knowledge represents a principal challenge to scientific progress, democracy, and actions to address global crises. We argue that the study of collective behavior must rise to a ``crisis discipline'' just as medicine, conservation, and climate science have, with a focus on providing actionable insight to policymakers and regulators for the stewardship of social systems.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Bak-Coleman et al_2021_Stewardship of global collective behavior.pdf}
}

@book{barocasFairnessMachineLearning2019,
  title = {Fairness and {{Machine Learning}}},
  author = {Barocas, Solon and Hardt, Moritz and Narayanan, Arvind},
  year = {2019},
  publisher = {{fairmlbook.org}},
  abstract = {This book gives a perspective on machine learning that treats fairness as a central concern rather than an afterthought. We'll review the practice of machine learning in a way that highlights ethical challenges. We'll then discuss approaches to mitigate these problems. We've aimed to make the book as broadly accessible as we could, while preserving technical rigor and confronting difficult moral questions that arise in algorithmic decision making. This book won't have an all-encompassing formal definition of fairness or a quick technical fix to society's concerns with automated decisions. Addressing issues of fairness requires carefully understanding the scope and limitations of machine learning tools. This book offers a critical take on current practice of machine learning as well as proposed technical fixes for achieving fairness. It doesn't offer any easy answers. Nonetheless, we hope you'll find the book enjoyable and useful in developing a deeper understanding of how to practice machine learning responsibly.},
  keywords = {ethics,machine-learning,textbook}
}

@article{barocasResponsibleComputingCOVID192021,
  title = {Responsible Computing during {{COVID-19}} and Beyond},
  author = {Barocas, Solon and Biega, Asia J. and Boyarskaya, Margarita and Crawford, Kate and Iii, Hal Daum{\'e} and Dud{\'i}k, Miroslav and Fish, Benjamin and Gray, Mary L. and Hecht, Brent and Olteanu, Alexandra and {Poursabzi-Sangdeh}, Forough and Stark, Luke and Vaughan, Jennifer Wortman and Wallach, Hanna and Zepf, Marion},
  year = {2021},
  month = jul,
  journal = {Communications of the ACM},
  volume = {64},
  number = {7},
  pages = {30--32},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3466612},
  urldate = {2022-05-26},
  abstract = {Navigating the ethical and societal impacts of technologies.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Barocas et al_2021_Responsible computing during COVID-19 and beyond.pdf}
}

@misc{barrettWeapon2001,
  title = {The {{Weapon}}},
  author = {Barrett, Sean},
  year = {2001}
}

@misc{barringerDetective1993,
  title = {Detective},
  author = {Barringer, Matt},
  year = {1993}
}

@article{bellemareUnifyingCountBasedExploration2016,
  title = {Unifying {{Count-Based Exploration}} and {{Intrinsic Motivation}}},
  author = {Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  year = {2016},
  pages = {9},
  abstract = {We consider an agent's uncertainty about its environment and the problem of generalizing this uncertainty across states. Specifically, we focus on the problem of exploration in non-tabular reinforcement learning. Drawing inspiration from the intrinsic motivation literature, we use density models to measure uncertainty, and propose a novel algorithm for deriving a pseudo-count from an arbitrary density model. This technique enables us to generalize count-based exploration algorithms to the non-tabular case. We apply our ideas to Atari 2600 games, providing sensible pseudo-counts from raw pixels. We transform these pseudo-counts into exploration bonuses and obtain significantly improved exploration in a number of hard games, including the infamously difficult MONTEZUMA'S REVENGE.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Bellemare et al_Unifying Count-Based Exploration and Intrinsic Motivation.pdf}
}

@inproceedings{bender_dangers_2021,
  title = {On the {{Dangers}} of {{Stochastic Parrots}}: {{Can Language Models Be Too Big}}?},
  shorttitle = {On the {{Dangers}} of {{Stochastic Parrots}}},
  booktitle = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Bender, Emily M. and Gebru, Timnit and {McMillan-Major}, Angelina and Shmitchell, Shmargaret},
  year = {2021},
  month = mar,
  pages = {610--623},
  publisher = {{ACM}},
  address = {{Virtual Event Canada}},
  doi = {10.1145/3442188.3445922},
  urldate = {2021-09-07},
  abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
  isbn = {978-1-4503-8309-7},
  langid = {english},
  keywords = {ethics,machine-learning,natural-language,position-paper},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Bender et al_2021_On the Dangers of Stochastic Parrots.pdf}
}

@inproceedings{benderClimbingNLUMeaning2020,
  title = {Climbing towards {{NLU}}: {{On Meaning}}, {{Form}}, and {{Understanding}} in the {{Age}} of {{Data}}},
  shorttitle = {Climbing towards {{NLU}}},
  booktitle = {Proceedings of the 58th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Bender, Emily M. and Koller, Alexander},
  year = {2020},
  pages = {5185--5198},
  publisher = {{Association for Computational Linguistics}},
  address = {{Online}},
  doi = {10.18653/v1/2020.acl-main.463},
  urldate = {2022-06-15},
  abstract = {The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as ``understanding'' language or capturing ``meaning''. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of ``Taking Stock of Where We've Been and Where We're Going'', we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Bender_Koller_2020_Climbing towards NLU.pdf}
}

@article{benderDataStatementsNatural2018,
  title = {Data {{Statements}} for {{Natural Language Processing}}: {{Toward Mitigating System Bias}} and {{Enabling Better Science}}},
  shorttitle = {Data {{Statements}} for {{Natural Language Processing}}},
  author = {Bender, Emily M. and Friedman, Batya},
  year = {2018},
  month = dec,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {6},
  pages = {587--604},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00041},
  urldate = {2022-06-12},
  abstract = {In this paper, we propose data statements as a design solution and professional practice for natural language processing technologists, in both research and development. Through the adoption and widespread use of data statements, the field can begin to address critical scientific and ethical issues that result from the use of data from certain populations in the development of technology for other populations. We present a form that data statements can take and explore the implications of adopting them as part of regular practice. We argue that data statements will help alleviate issues related to exclusion and bias in language technology, lead to better precision in claims about how natural language processing research can generalize and thus better engineering results, protect companies from public embarrassment, and ultimately lead to language technology that meets its users in their own preferred linguistic style and furthermore does not misrepresent them to others.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Bender_Friedman_2018_Data Statements for Natural Language Processing.pdf}
}

@misc{benderThereResearchThat2019,
  title = {Is There Research That Shouldn't Be Done? {{Is}} There Research That Shouldn't Be Encouraged?},
  shorttitle = {Is There Research That Shouldn't Be Done?},
  author = {Bender, Emily M.},
  year = {2019},
  month = dec,
  journal = {Medium},
  urldate = {2022-06-12},
  abstract = {[Disclaimer: This is not a scholarly piece of writing, but rather a series of thoughts set down in a hurry in the context of an on-going{\ldots}},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Bender_2019_Is there research that shouldnâ€™t be done.pdf;/home/morgan/Zotero/storage/7XAIZPUS/is-there-research-that-shouldnt-be-done-is-there-research-that-shouldn-t-be-encouraged-b1bf7d32.html}
}

@article{bennettWhatPointFairness2020,
  title = {What Is the Point of Fairness? Disability, {{AI}} and the Complexity of Justice},
  shorttitle = {What Is the Point of Fairness?},
  author = {Bennett, Cynthia L. and Keyes, Os},
  year = {2020},
  month = mar,
  journal = {ACM SIGACCESS Accessibility and Computing},
  number = {125},
  pages = {5:1},
  issn = {1558-2337},
  doi = {10.1145/3386296.3386301},
  urldate = {2022-06-01},
  abstract = {Work integrating conversations around AI and Disability is vital and valued, particularly when done through a lens of fairness. Yet at the same time, analysing the ethical implications of AI for disabled people solely through the lens of a singular idea of "fairness" risks reinforcing existing power dynamics, either through reinforcing the position of existing medical gatekeepers, or promoting tools and techniques that benefit otherwise-privileged disabled people while harming those who are rendered outliers in multiple ways. In this paper we present two case studies from within computer vision - a subdiscipline of AI focused on training algorithms that can "see" - of technologies putatively intended to help disabled people but, through failures to consider structural injustices in their design, are likely to result in harms not addressed by a "fairness" framing of ethics. Drawing on disability studies and critical data science, we call on researchers into AI ethics and disability to move beyond simplistic notions of fairness, and towards notions of justice.},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Bennett_Keyes_2020_What is the point of fairness.pdf}
}

@misc{berlynCutthroats1984,
  title = {Cutthroats},
  author = {Berlyn, Michael},
  year = {1984}
}

@misc{berlynInfidel1983,
  title = {Infidel},
  author = {Berlyn, Michael},
  year = {1983}
}

@misc{berntssonTemple2002,
  title = {The {{Temple}}},
  author = {Berntsson, Johan},
  year = {2002}
}

@misc{bhawalResumeDataset,
  title = {Resume {{Dataset}}},
  author = {Bhawal, Snehaan},
  urldate = {2022-11-13},
  abstract = {A collection of Resumes in PDF as well as String format for data extraction.},
  howpublished = {https://www.kaggle.com/datasets/snehaanbhawal/resume-dataset},
  langid = {english},
  file = {/home/morgan/Zotero/storage/Q67Z3BBB/resume-dataset.html}
}

@misc{birhaneAutomatingAmbiguityChallenges2022,
  title = {Automating {{Ambiguity}}: {{Challenges}} and {{Pitfalls}} of {{Artificial Intelligence}}},
  shorttitle = {Automating {{Ambiguity}}},
  author = {Birhane, Abeba},
  year = {2022},
  month = jun,
  number = {arXiv:2206.04179},
  eprint = {2206.04179},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-06-10},
  abstract = {Machine learning (ML) and artificial intelligence (AI) tools increasingly permeate every possible social, political, and economic sphere; sorting, taxonomizing and predicting complex human behaviour and social phenomena. However, from fallacious and naive groundings regarding complex adaptive systems to datasets underlying models, these systems are beset by problems, challenges, and limitations. They remain opaque and unreliable, and fail to consider societal and structural oppressive systems, disproportionately negatively impacting those at the margins of society while benefiting the most powerful. The various challenges, problems and pitfalls of these systems are a hot topic of research in various areas, such as critical data/algorithm studies, science and technology studies (STS), embodied and enactive cognitive science, complexity science, Afro-feminism, and the broadly construed emerging field of Fairness, Accountability, and Transparency (FAccT). Yet, these fields of enquiry often proceed in silos. This thesis weaves together seemingly disparate fields of enquiry to examine core scientific and ethical challenges, pitfalls, and problems of AI. In this thesis I, a) review the historical and cultural ecology from which AI research emerges, b) examine the shaky scientific grounds of machine prediction of complex behaviour illustrating how predicting complex behaviour with precision is impossible in principle, c) audit large scale datasets behind current AI demonstrating how they embed societal historical and structural injustices, d) study the seemingly neutral values of ML research and put forward 67 prominent values underlying ML research, e) examine some of the insidious and worrying applications of computer vision research, and f) put forward a framework for approaching challenges, failures and problems surrounding ML systems as well as alternative ways forward.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computers and Society},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Birhane_2022_Automating Ambiguity.pdf}
}

@misc{birhaneMultimodalDatasetsMisogyny2021,
  title = {Multimodal Datasets: Misogyny, Pornography, and Malignant Stereotypes},
  shorttitle = {Multimodal Datasets},
  author = {Birhane, Abeba and Prabhu, Vinay Uday and Kahembwe, Emmanuel},
  year = {2021},
  month = oct,
  number = {arXiv:2110.01963},
  eprint = {2110.01963},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-05-27},
  abstract = {We have now entered the era of trillion parameter machine learning models trained on billion-sized datasets scraped from the internet. The rise of these gargantuan datasets has given rise to formidable bodies of critical work that has called for caution while generating these large datasets. These address concerns surrounding the dubious curation practices used to generate these datasets, the sordid quality of alt-text data available on the world wide web, the problematic content of the CommonCrawl dataset often used as a source for training large language models, and the entrenched biases in large-scale visio-linguistic models (such as OpenAI's CLIP model) trained on opaque datasets (WebImageText). In the backdrop of these specific calls of caution, we examine the recently released LAION-400M dataset, which is a CLIP-filtered dataset of Image-Alt-text pairs parsed from the Common-Crawl dataset. We found that the dataset contains, troublesome and explicit images and text pairs of rape, pornography, malign stereotypes, racist and ethnic slurs, and other extremely problematic content. We outline numerous implications, concerns and downstream harms regarding the current state of large scale datasets while raising open questions for various stakeholders including the AI community, regulators, policy makers and data subjects.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computers and Society},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Birhane et al_2021_Multimodal datasets.pdf}
}

@inproceedings{birhaneRobotRightsLet2020,
  title = {Robot {{Rights}}? {{Let}}'s {{Talk}} about {{Human Welfare Instead}}},
  shorttitle = {Robot {{Rights}}?},
  booktitle = {Proceedings of the {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Birhane, Abeba and {van Dijk}, Jelle},
  year = {2020},
  month = feb,
  eprint = {2001.05046},
  primaryclass = {cs},
  pages = {207--213},
  doi = {10.1145/3375627.3375855},
  urldate = {2022-05-27},
  abstract = {The `robot rights' debate, and its related question of `robot responsibility', invokes some of the most polarized positions in AI ethics. While some advocate for granting robots rights on a par with human beings, others, in a stark opposition argue that robots are not deserving of rights but are objects that should be our slaves. Grounded in post-Cartesian philosophical foundations, we argue not just to deny robots `rights', but to deny that robots, as artifacts emerging out of and mediating human being, are the kinds of things that could be granted rights in the first place. Once we see robots as mediators of human being, we can understand how the `robot rights' debate is focused on first world problems, at the expense of urgent ethical concerns, such as machine bias, machine elicited human labour exploitation, and erosion of privacy all impacting society's least privileged individuals. We conclude that, if human being is our starting point and human welfare is the primary concern, the negative impacts emerging from machinic systems, as well as the lack of taking responsibility by people designing, selling and deploying such machines, remains the most pressing ethical discussion in AI.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computers and Society},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Birhane_van Dijk_2020_Robot Rights.pdf;/Users/morgan/Dropbox/eBooks/Ethics in Computer Science/Articles/Birhane and van Dijk - 2020 - Robot Rights Let's Talk about Human Welfare Inste.pdf}
}

@misc{blankEnchanter1983,
  title = {Enchanter},
  author = {Blank, Marc},
  year = {1983}
}

@misc{blankZork1980,
  title = {Zork {{I}}},
  author = {Blank, Mark and Lebling, Dave and Daniels, Bruce and Anderson, Tim},
  year = {1980},
  howpublished = {Infocom}
}

@misc{blankZorkUndiscoveredUnderground1997,
  title = {Zork: {{The Undiscovered Underground}}},
  author = {Blank, Marc},
  year = {1997}
}

@inproceedings{blodgettLanguageTechnologyPower2020,
  title = {Language ({{Technology}}) Is {{Power}}: {{A Critical Survey}} of ``{{Bias}}'' in {{NLP}}},
  shorttitle = {Language ({{Technology}}) Is {{Power}}},
  booktitle = {Proceedings of the 58th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Blodgett, Su Lin and Barocas, Solon and Daum{\'e} III, Hal and Wallach, Hanna},
  year = {2020},
  pages = {5454--5476},
  publisher = {{Association for Computational Linguistics}},
  address = {{Online}},
  doi = {10.18653/v1/2020.acl-main.485},
  urldate = {2022-05-26},
  abstract = {We survey 146 papers analyzing ``bias'' in NLP systems, finding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing ``bias'' is an inherently normative process. We further find that these papers' proposed quantitative techniques for measuring or mitigating ``bias'' are poorly matched to their motivations and do not engage with the relevant literature outside of NLP. Based on these findings, we describe the beginnings of a path forward by proposing three recommendations that should guide work analyzing ``bias'' in NLP systems. These recommendations rest on a greater recognition of the relationships between language and social hierarchies, encouraging researchers and practitioners to articulate their conceptualizations of ``bias''{\textemdash}i.e., what kinds of system behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these statements{\textemdash}and to center work around the lived experiences of members of communities affected by NLP systems, while interrogating and reimagining the power relations between technologists and such communities.},
  langid = {english},
  keywords = {anti-racism,bias,ethics,frameworks,natural-language,power dynamics,survey},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Blodgett et al_2020_Language (Technology) is Power.pdf}
}

@inproceedings{blodgettResponsibleLanguageTechnologies2022,
  title = {Responsible {{Language Technologies}}: {{Foreseeing}} and {{Mitigating Harms}}},
  shorttitle = {Responsible {{Language Technologies}}},
  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems Extended Abstracts}}},
  author = {Blodgett, Su Lin and Liao, Q. Vera and Olteanu, Alexandra and Mihalcea, Rada and Muller, Michael and Scheuerman, Morgan Klaus and Tan, Chenhao and Yang, Qian},
  year = {2022},
  month = apr,
  pages = {1--3},
  publisher = {{ACM}},
  address = {{New Orleans LA USA}},
  doi = {10.1145/3491101.3516502},
  urldate = {2022-08-08},
  abstract = {As increasingly powerful natural language generation, representation, and understanding models are developed, made available and deployed across numerous downstream applications, many researchers and practitioners have warned about possible adverse impacts. Harmful impacts include but are not limited to disparities in quality-of-service, unequal distribution of resources, erasure, stereotyping and misrepresentation of groups and individuals, they might limit people's agency or affect their well-being. Given that language tasks are often complex, open-ended, and incorporated across a diversity of applications; effectively foreseeing and mitigating such harms has remained an elusive goal. Towards this goal, Natural Language Processing (NLP) literature has only recently started to engage with human-centered perspectives and methods{\textemdash}that are often central to HCI research. In this panel, we bring together researchers with expertise in both NLP and HCI, as well as in issues that pertain to the fairness, transparency, justice, and ethics of computational systems. Our main goals are to explore 1) how to leverage HCI perspectives and methodologies to help foresee potential harms of language technologies and inform their mitigation, 2) synergies between the HCI and the responsible NLP research that can help build common ground, and 3) complement existing efforts to facilitate conversations between the HCI and NLP communities.},
  isbn = {978-1-4503-9156-6},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Blodgett et al_2022_Responsible Language Technologies.pdf}
}

@misc{blodgettRisksAIFoundation2021,
  title = {Risks of {{AI Foundation Models}} in {{Education}}},
  author = {Blodgett, Su Lin and Madaio, Michael},
  year = {2021},
  month = oct,
  number = {arXiv:2110.10024},
  eprint = {2110.10024},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-08-08},
  abstract = {If the authors of a recent Stanford report (Bommasani et al., 2021) on the opportunities and risks of "foundation models" are to be believed, these models represent a paradigm shift for AI and for the domains in which they will supposedly be used, including education. Although the name is new (and contested (Field, 2021)), the term describes existing types of algorithmic models that are "trained on broad data at scale" and "fine-tuned" (i.e., adapted) for particular downstream tasks, and is intended to encompass large language models such as BERT or GPT-3 and computer vision models such as CLIP. Such technologies have the potential for harm broadly speaking (e.g., Bender et al., 2021), but their use in the educational domain is particularly fraught, despite the potential benefits for learners claimed by the authors. In section 3.3 of the Stanford report, Malik et al. argue that achieving the goal of providing education for all learners requires more efficient computational approaches that can rapidly scale across educational domains and across educational contexts, for which they argue foundation models are uniquely well-suited. However, evidence suggests that not only are foundation models not likely to achieve the stated benefits for learners, but their use may also introduce new risks for harm.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Blodgett_Madaio_2021_Risks of AI Foundation Models in Education.pdf}
}

@inproceedings{blodgettStereotypingNorwegianSalmon2021,
  title = {Stereotyping {{Norwegian Salmon}}: {{An Inventory}} of {{Pitfalls}} in {{Fairness Benchmark Datasets}}},
  shorttitle = {Stereotyping {{Norwegian Salmon}}},
  booktitle = {Proceedings of the 59th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 11th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  author = {Blodgett, Su Lin and Lopez, Gilsinia and Olteanu, Alexandra and Sim, Robert and Wallach, Hanna},
  year = {2021},
  pages = {1004--1015},
  publisher = {{Association for Computational Linguistics}},
  address = {{Online}},
  doi = {10.18653/v1/2021.acl-long.81},
  urldate = {2022-05-26},
  abstract = {Auditing NLP systems for computational harms like surfacing stereotypes is an elusive goal. Several recent efforts have focused on benchmark datasets consisting of pairs of contrastive sentences, which are often accompanied by metrics that aggregate an NLP system's behavior on these pairs into measurements of harms. We examine four such benchmarks constructed for two NLP tasks: language modeling and coreference resolution. We apply a measurement modeling lens{\textemdash}originating from the social sciences{\textemdash}to inventory a range of pitfalls that threaten these benchmarks' validity as measurement models for stereotyping. We find that these benchmarks frequently lack clear articulations of what is being measured, and we highlight a range of ambiguities and unstated assumptions that affect how these benchmarks conceptualize and operationalize stereotyping.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Blodgett et al_2021_Stereotyping Norwegian Salmon.pdf}
}

@article{bluemkeInfluenceViolentNonviolent2010,
  title = {The Influence of Violent and Nonviolent Computer Games on Implicit Measures of Aggressiveness},
  author = {Bluemke, Matthias and Friedrich, Monika and Zumbach, Joerg},
  year = {2010},
  month = jan,
  journal = {Aggressive Behavior},
  volume = {36},
  number = {1},
  pages = {1--13},
  issn = {0096140X, 10982337},
  doi = {10.1002/ab.20329},
  urldate = {2021-12-21},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Natural Language Processing/Articles/Aggressive Behavior - 2009 - Bluemke - The influence of violent and nonviolent computer games on implicit measures of.pdf}
}

@misc{bolukbasiManComputerProgrammer2016,
  title = {Man Is to {{Computer Programmer}} as {{Woman}} Is to {{Homemaker}}? {{Debiasing Word Embeddings}}},
  author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James and Saligrama, Venkatesh and Kalai, Adam},
  year = {2016},
  file = {/home/morgan/Dropbox/eBooks/Articles/EmbeddingsPaper/Bolukbasi et al. - 2016 - Man is to Computer Programmer as Woman is to Homem.pdf}
}

@misc{bovaJewelKnowledge1999,
  title = {The {{Jewel}} of {{Knowledge}}},
  author = {Bova, Francesco},
  year = {1999}
}

@misc{briggsPlunderedHearts1987,
  title = {Plundered {{Hearts}}},
  author = {Briggs, Amy},
  year = {1987}
}

@article{brunetUnderstandingOriginsBias2019,
  title = {Understanding the {{Origins}} of {{Bias}} in {{Word Embeddings}}},
  author = {Brunet, Marc-Etienne and {Alkalay-Houlihan}, Colleen and Anderson, Ashton and Zemel, Richard},
  year = {2019},
  month = jun,
  journal = {arXiv:1810.03611 [cs, stat]},
  eprint = {1810.03611},
  primaryclass = {cs, stat},
  urldate = {2021-10-10},
  abstract = {Popular word embedding algorithms exhibit stereotypical biases, such as gender bias. The widespread use of these algorithms in machine learning systems can thus amplify stereotypes in important contexts. Although some methods have been developed to mitigate this problem, how word embedding biases arise during training is poorly understood. In this work, we develop a technique to address this question. Given a word embedding, our method reveals how perturbing the training corpus would affect the resulting embedding bias. By tracing the origins of word embedding bias back to the original training documents, one can identify subsets of documents whose removal would most reduce bias. We demonstrate our methodology on Wikipedia and New York Times corpora, and find it to be very accurate.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Natural Language Processing/Articles/Understanding the Origins of Bias in Words.pdf}
}

@article{brunetUnderstandingOriginsBias2019a,
  title = {Understanding the {{Origins}} of {{Bias}} in {{Word Embeddings}}},
  author = {Brunet, Marc-Etienne and {Alkalay-Houlihan}, Colleen and Anderson, Ashton and Zemel, Richard},
  year = {2019},
  month = jun,
  journal = {arXiv:1810.03611 [cs, stat]},
  eprint = {1810.03611},
  primaryclass = {cs, stat},
  urldate = {2021-10-10},
  abstract = {Popular word embedding algorithms exhibit stereotypical biases, such as gender bias. The widespread use of these algorithms in machine learning systems can thus amplify stereotypes in important contexts. Although some methods have been developed to mitigate this problem, how word embedding biases arise during training is poorly understood. In this work, we develop a technique to address this question. Given a word embedding, our method reveals how perturbing the training corpus would affect the resulting embedding bias. By tracing the origins of word embedding bias back to the original training documents, one can identify subsets of documents whose removal would most reduce bias. We demonstrate our methodology on Wikipedia and New York Times corpora, and find it to be very accurate.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@misc{bulldogSnackTime2008,
  title = {Snack {{Time}}!},
  author = {the Bulldog, Hardy},
  year = {2008}
}

@article{caliskanSemanticsDerivedAutomatically2017,
  title = {Semantics Derived Automatically from Language Corpora Contain Human-like Biases},
  author = {Caliskan, Aylin and Bryson, Joanna J. and Narayanan, Arvind},
  year = {2017},
  month = apr,
  journal = {Science},
  volume = {356},
  number = {6334},
  pages = {183--186},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aal4230},
  urldate = {2021-10-11},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Natural Language Processing/Articles/CaliskanEtAl_authors_full.pdf}
}

@article{caliskanSemanticsDerivedAutomatically2017a,
  title = {Semantics Derived Automatically from Language Corpora Contain Human-like Biases},
  author = {Caliskan, Aylin and Bryson, Joanna J. and Narayanan, Arvind},
  year = {2017},
  month = apr,
  journal = {Science},
  volume = {356},
  number = {6334},
  pages = {183--186},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aal4230},
  urldate = {2021-10-11},
  langid = {english}
}

@misc{callaciMotherLoose1998,
  title = {Mother {{Loose}}},
  author = {Callaci, Irene},
  year = {1998}
}

@inproceedings{chenInvestigatingImpactGender2018,
  title = {Investigating the {{Impact}} of {{Gender}} on {{Rank}} in {{Resume Search Engines}}},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Chen, Le and Ma, Ruijun and Hann{\'a}k, Anik{\'o} and Wilson, Christo},
  year = {2018},
  month = apr,
  pages = {1--14},
  publisher = {{ACM}},
  address = {{Montreal QC Canada}},
  doi = {10.1145/3173574.3174225},
  urldate = {2022-05-29},
  abstract = {In this work we investigate gender-based inequalities in the context of resume search engines, which are tools that allow recruiters to proactively search for candidates based on keywords and filters. If these ranking algorithms take demographic features into account (directly or indirectly), they may produce rankings that disadvantage some candidates. We collect search results from Indeed, Monster, and CareerBuilder based on 35 job titles in 20 U. S. cities, resulting in data on 855K job candidates. Using statistical tests, we examine whether these search engines produce rankings that exhibit two types of indirect discrimination: individual and group unfairness. Furthermore, we use controlled experiments to show that these websites do not use inferred gender of candidates as explicit features in their ranking algorithms.},
  isbn = {978-1-4503-5620-6},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Chen et al_2018_Investigating the Impact of Gender on Rank in Resume Search Engines.pdf}
}

@misc{chmielinskiDatasetNutritionLabel2022,
  title = {The {{Dataset Nutrition Label}} (2nd {{Gen}}): {{Leveraging Context}} to {{Mitigate Harms}} in {{Artificial Intelligence}}},
  shorttitle = {The {{Dataset Nutrition Label}} (2nd {{Gen}})},
  author = {Chmielinski, Kasia S. and Newman, Sarah and Taylor, Matt and Joseph, Josh and Thomas, Kemi and Yurkofsky, Jessica and Qiu, Yue Chelsea},
  year = {2022},
  month = mar,
  number = {arXiv:2201.03954},
  eprint = {2201.03954},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-06-12},
  abstract = {As the production of and reliance on datasets to produce automated decisionmaking systems (ADS) increases, so does the need for processes for evaluating and interrogating the underlying data. After launching the Dataset Nutrition Label in 2018, the Data Nutrition Project has made significant updates to the design and purpose of the Label, and is launching an updated Label in late 2020, which is previewed in this paper. The new Label includes context-specific Use Cases \& Alerts presented through an updated design and user interface targeted towards the data scientist profile. This paper discusses the harm and bias from underlying training data that the Label is intended to mitigate, the current state of the work including new datasets being labeled, new and existing challenges, and further directions of the work, as well as Figures previewing the new label.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Chmielinski et al_2022_The Dataset Nutrition Label (2nd Gen).pdf}
}

@misc{choPropertiesNeuralMachine2014,
  title = {On the {{Properties}} of {{Neural Machine Translation}}: {{Encoder-Decoder Approaches}}},
  shorttitle = {On the {{Properties}} of {{Neural Machine Translation}}},
  author = {Cho, Kyunghyun and {van Merrienboer}, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
  year = {2014},
  month = oct,
  number = {arXiv:1409.1259},
  eprint = {1409.1259},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-07-07},
  abstract = {Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder{\textendash}Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Statistics - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Cho et al_2014_On the Properties of Neural Machine Translation.pdf}
}

@inproceedings{coteTextWorldLearningEnvironment2019,
  title = {{{TextWorld}}: {{A Learning Environment}} for {{Text-Based Games}}},
  shorttitle = {{{TextWorld}}},
  booktitle = {Computer {{Games}}},
  author = {C{\^o}t{\'e}, Marc-Alexandre and K{\'a}d{\'a}r, {\'A}kos and Yuan, Xingdi and Kybartas, Ben and Barnes, Tavian and Fine, Emery and Moore, James and Hausknecht, Matthew and El Asri, Layla and Adada, Mahmoud and Tay, Wendy and Trischler, Adam},
  editor = {Cazenave, Tristan and Saffidine, Abdallah and Sturtevant, Nathan},
  year = {2019},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {41--75},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-24337-1_3},
  abstract = {We introduce TextWorld, a sandbox learning environment for the training and evaluation of RL agents on text-based games. TextWorld is a Python library that handles interactive play-through of text games, as well as backend functions like state tracking and reward assignment. It comes with a curated list of games whose features and challenges we have analyzed. More significantly, it enables users to handcraft or automatically generate new games. Its generative mechanisms give precise control over the difficulty, scope, and language of constructed games, and can be used to relax challenges inherent to commercial text games like partial observability and sparse rewards. By generating sets of varied but similar games, TextWorld can also be used to study generalization and transfer learning. We cast text-based games in the Reinforcement Learning formalism, use our framework to develop a set of benchmark games, and evaluate several baseline agents on this set and the curated list.},
  isbn = {978-3-030-24337-1},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/CÃ´tÃ© et al_2019_TextWorld.pdf}
}

@misc{CreationCapitalismTwine2013,
  title = {Creation {{Under Capitalism}} and the {{Twine Revolution}} | {{Nightmare Mode}}},
  year = {2013},
  month = aug,
  urldate = {2022-08-13},
  howpublished = {https://web.archive.org/web/20130805084824/http://nightmaremode.net/2012/11/creation-under-capitalism-23422/},
  file = {/home/morgan/Zotero/storage/M5V4G6JW/creation-under-capitalism-23422.html}
}

@misc{crowtherAdventure1976,
  title = {Adventure},
  author = {Crowther, William and Woods, Donald},
  year = {1976}
}

@article{Curses2022,
  title = {Curses},
  year = {2022},
  month = apr,
  journal = {Wikipedia},
  urldate = {2022-05-19},
  abstract = {Curses is an interactive fiction computer game created by Graham Nelson in 1993. Appearing in the beginning of the non-commercial era of interactive fiction, it is considered one of the milestones of the genre. Writing for The New York Times, Edward Rothstein described the game as "acclaimed."},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1082604883},
  file = {/home/morgan/Zotero/storage/DZVJT3K3/Curses_(video_game).html}
}

@article{dambekodiPlayingTextBasedGames2020,
  title = {Playing {{Text-Based Games}} with {{Common Sense}}},
  author = {Dambekodi, Sahith and Frazier, Spencer and Ammanabrolu, Prithviraj and Riedl, Mark O.},
  year = {2020},
  month = dec,
  journal = {arXiv:2012.02757 [cs]},
  eprint = {2012.02757},
  primaryclass = {cs},
  urldate = {2022-04-14},
  abstract = {Text based games are simulations in which an agent interacts with the world purely through natural language. They typically consist of a number of puzzles interspersed with interactions with common everyday objects and locations. Deep reinforcement learning agents can learn to solve these puzzles. However, the everyday interactions with the environment, while trivial for human players, present as additional puzzles to agents. We explore two techniques for incorporating commonsense knowledge into agents. Inferring possibly hidden aspects of the world state with either a commonsense inference model COMET, or a language model BERT. Biasing an agents exploration according to common patterns recognized by a language model. We test our technique in the 9to05 game, which is an extreme version of a text based game that requires numerous interactions with common, everyday objects in common, everyday scenarios. We conclude that agents that augment their beliefs about the world state with commonsense inferences are more robust to observational errors and omissions of common elements from text descriptions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Dambekodi et al_2020_Playing Text-Based Games with Common Sense.pdf}
}

@inproceedings{deshpandeMitigatingDemographicBias2020,
  title = {Mitigating {{Demographic Bias}} in {{AI-based Resume Filtering}}},
  booktitle = {Adjunct {{Publication}} of the 28th {{ACM Conference}} on {{User Modeling}}, {{Adaptation}} and {{Personalization}}},
  author = {Deshpande, Ketki V. and Pan, Shimei and Foulds, James R.},
  year = {2020},
  month = jul,
  pages = {268--275},
  publisher = {{ACM}},
  address = {{Genoa Italy}},
  doi = {10.1145/3386392.3399569},
  urldate = {2022-11-01},
  abstract = {With increasing diversity in the labor market as well as the work force, employers receive resumes from an increasingly diverse population. However, studies and field experiments have confirmed the presence of bias in the labor market based on gender, race, and ethnicity. Many employers use automated resume screening to filter the many possible matches. Depending on how the automated screening algorithm is trained it can potentially exhibit bias towards a particular population by favoring certain socio-linguistic characteristics. The resume writing style and socio-linguistics are a potential source of bias as they correlate with protected characteristics such as ethnicity. A biased dataset is often translated into biased AI algorithms and de-biasing algorithms are being contemplated. In this work, we study the effects of socio-linguistic bias on resume to job description matching algorithms. We develop a simple technique, called fair-tf-idf, to match resumes with job descriptions in a fair way by mitigating the socio-linguistic bias.},
  isbn = {978-1-4503-7950-2},
  langid = {english},
  file = {/home/morgan/Dropbox/eBooks/Articles/EmbeddingsPaper/Deshpande et al. - 2020 - Mitigating Demographic Bias in AI-based Resume Fil.pdf}
}

@misc{desiletsEnterpriseIncidents2002,
  title = {The {{Enterprise Incidents}}},
  author = {Desilets, Brian},
  year = {2002}
}

@article{didierAcknowledgingAIDark2015,
  title = {Acknowledging {{AI}}'s Dark Side},
  author = {Didier, Christelle and Duan, Weiwen and Dupuy, Jean-Pierre and Guston, David H. and Liu, Yongmou and Cerezo, Jos{\'e} Antonio L{\'o}pez and Michelfelder, Diane and Mitcham, Carl and Sarewitz, Daniel and Stilgoe, Jack and Stirling, Andrew and Vallor, Shannon and Wang, Guoyu and Wilsdon, James and Woodhouse, Edward J.},
  year = {2015},
  month = sep,
  journal = {Science},
  volume = {349},
  number = {6252},
  pages = {1064--1064},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.349.6252.1064-c},
  urldate = {2022-06-12},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Didier et al_2015_Acknowledging AI's dark side.pdf}
}

@book{diestel_graphTheory_2017,
  title = {Graph {{Theory}}},
  author = {Diestel, Reinhard},
  year = {2017},
  series = {Graduate {{Texts}} in {{Mathematics}}},
  volume = {173},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-53622-3},
  urldate = {2023-05-07},
  isbn = {978-3-662-53621-6 978-3-662-53622-3},
  langid = {english},
  keywords = {Combinatorics,Discrete mathematics,Finite and infinite Graphs,Graph,Graph Minors,Graph theory,Matching},
  file = {/home/morgan/Zotero/storage/I3AHMRHH/Diestel - 2017 - Graph Theory.pdf}
}

@inproceedings{dixonMeasuringMitigatingUnintended2018,
  title = {Measuring and {{Mitigating Unintended Bias}} in {{Text Classification}}},
  booktitle = {Proceedings of the 2018 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Dixon, Lucas and Li, John and Sorensen, Jeffrey and Thain, Nithum and Vasserman, Lucy},
  year = {2018},
  month = dec,
  pages = {67--73},
  publisher = {{ACM}},
  address = {{New Orleans LA USA}},
  doi = {10.1145/3278721.3278729},
  urldate = {2022-06-12},
  abstract = {We introduce and illustrate a new approach to measuring and mitigating unintended bias in machine learning models. Our definition of unintended bias is parameterized by a test set and a subset of input features. We illustrate how this can be used to evaluate text classifiers using a synthetic test set and a public corpus of comments annotated for toxicity from Wikipedia Talk pages. We also demonstrate how imbalances in training data can lead to unintended bias in the resulting models, and therefore potentially unfair applications. We use a set of common demographic identity terms as the subset of input features on which we measure bias. This technique permits analysis in the common scenario where demographic information on authors and readers is unavailable, so that bias mitigation must focus on the content of the text itself. The mitigation method we introduce is an unsupervised approach based on balancing the training dataset. We demonstrate that this approach reduces the unintended bias without compromising overall model quality.},
  isbn = {978-1-4503-6012-8},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Dixon et al_2018_Measuring and Mitigating Unintended Bias in Text Classification.pdf}
}

@book{dmytrykFilmEditingIntroduction1984,
  title = {On {{Film Editing}}: {{An Introduction}} to the {{Art}} of {{Film Construction}}},
  shorttitle = {On {{Film Editing}}},
  author = {Dmytryk, Edward},
  year = {1984},
  month = nov,
  publisher = {{Focal Press}},
  address = {{Boston ; London}},
  isbn = {978-0-240-51738-4},
  langid = {english}
}

@misc{duttaResumeDataset,
  title = {Resume {{Dataset}}},
  author = {Dutta, Guarav},
  urldate = {2022-11-14},
  abstract = {Kaggle is the world's largest data science community with powerful tools and resources to help you achieve your data science goals.},
  howpublished = {https://www.kaggle.com/datasets/gauravduttakiit/resume-dataset},
  langid = {english},
  file = {/home/morgan/Zotero/storage/58KW5NMR/resume-dataset.html}
}

@incollection{dydewalleChapter16Film1998,
  title = {Chapter 16 - {{Film Perception}}: {{The Processing}} of {{Film Cuts}}},
  shorttitle = {Chapter 16 - {{Film Perception}}},
  booktitle = {Eye {{Guidance}} in {{Reading}} and {{Scene Perception}}},
  author = {{d'Ydewalle}, G{\'e}ry and Desmet, Geert and Van Rensbergen, Johan},
  editor = {Underwood, Geoffrey},
  year = {1998},
  month = jan,
  pages = {357--367},
  publisher = {{Elsevier Science Ltd}},
  address = {{Amsterdam}},
  doi = {10.1016/B978-008043361-5/50017-1},
  urldate = {2022-05-11},
  abstract = {The chapter describes three levels of editing errors. Editing errors of the first order refer either to small displacements of the camera position or to small changes of the image size, disturbing the perception of apparent movement, and leading to the impression of jumping. Editing rules of the second order are based on the ability of the perceiver to construe a spatial-cognitive schema of the displayed scene. An editing error implies a switch in the left{\textendash}right location of the objects in the scene. Third order editing rules are meant to reinforce the narrative continuity of the story, in other words the maintenance/steadiness of ``visual momentum''. The viewer is unaware that much processing is going on to produce a smooth perception of a large sequence of discontinuous events. The viewer's perception of a movie is typically experienced as a continuous one. This is achieved by the principle that ``successive shots should try to minimize perceptually disruptive transitions''. Effects of these disruptive transitions are deliberately introduced in this chapter and eye movements of the perceivers (test subjects) are recorded to analyze collected data.},
  isbn = {978-0-08-043361-5},
  langid = {english},
  file = {/home/morgan/Zotero/storage/I87DQ65J/B9780080433615500171.html}
}

@misc{eganAfflicted2008,
  title = {Afflicted},
  author = {Egan, Doug},
  year = {2008}
}

@misc{ethridgeOMNIQuest1988,
  title = {{{OMNIQuest}}},
  author = {Ethridge, Chris Barden and {Chris}},
  year = {1988}
}

@misc{fieldSurveyRaceRacism2021,
  title = {A {{Survey}} of {{Race}}, {{Racism}}, and {{Anti-Racism}} in {{NLP}}},
  author = {Field, Anjalie and Blodgett, Su Lin and Waseem, Zeerak and Tsvetkov, Yulia},
  year = {2021},
  month = jul,
  number = {arXiv:2106.11410},
  eprint = {2106.11410},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-05-26},
  abstract = {Despite inextricable ties between race and language, little work has considered race in NLP research and development. In this work, we survey 79 papers from the ACL anthology that mention race. These papers reveal various types of race-related bias in all stages of NLP model development, highlighting the need for proactive consideration of how NLP systems can uphold racial hierarchies. However, persistent gaps in research on race and NLP remain: race has been siloed as a niche topic and remains ignored in many NLP tasks; most work operationalizes race as a fixed singledimensional variable with a ground-truth label, which risks reinforcing differences produced by historical racism; and the voices of historically marginalized people are nearly absent in NLP literature. By identifying where and how NLP literature has and has not considered race, especially in comparison to related fields, our work calls for inclusion and racial justice in NLP research practices.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Field et al_2021_A Survey of Race, Racism, and Anti-Racism in NLP.pdf}
}

@misc{fieldSurveyRaceRacism2021a,
  title = {A {{Survey}} of {{Race}}, {{Racism}}, and {{Anti-Racism}} in {{NLP}}},
  author = {Field, Anjalie and Blodgett, Su Lin and Waseem, Zeerak and Tsvetkov, Yulia},
  year = {2021},
  month = jul,
  number = {arXiv:2106.11410},
  eprint = {2106.11410},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-08-08},
  abstract = {Despite inextricable ties between race and language, little work has considered race in NLP research and development. In this work, we survey 79 papers from the ACL anthology that mention race. These papers reveal various types of race-related bias in all stages of NLP model development, highlighting the need for proactive consideration of how NLP systems can uphold racial hierarchies. However, persistent gaps in research on race and NLP remain: race has been siloed as a niche topic and remains ignored in many NLP tasks; most work operationalizes race as a fixed singledimensional variable with a ground-truth label, which risks reinforcing differences produced by historical racism; and the voices of historically marginalized people are nearly absent in NLP literature. By identifying where and how NLP literature has and has not considered race, especially in comparison to related fields, our work calls for inclusion and racial justice in NLP research practices.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Field et al_2021_A Survey of Race, Racism, and Anti-Racism in NLP2.pdf}
}

@misc{flambeauResumeCorpus2022,
  title = {Resume\_corpus},
  author = {FLAMBEAU, JIECHIEU KAMENI FLORENTIN},
  year = {2022},
  month = oct,
  urldate = {2022-11-13},
  abstract = {multi-labeled dataset of resumes}
}

@misc{fos1ParserComp20222022,
  title = {{{ParserComp}} 2022},
  author = {{fos1} and Merriner, Christopher},
  year = {2022},
  journal = {itch.io},
  urldate = {2022-07-06},
  abstract = {A game jam from 2022-04-30 to 2022-07-30 hosted by fos1 \& ChristopherMerriner. ParserComp is the annual Interactive Fiction /Text Adventure competition for parser games (text games controlled by text input and output). TIMETABLE...},
  howpublished = {https://itch.io/jam/parsercomp-2022},
  langid = {english},
  file = {/home/morgan/Zotero/storage/F48KNTTM/parsercomp-2022.html}
}

@misc{fredman_Fibonacci_,
  title = {Fibonacci Heaps and Their Uses in Improved Network Optimization Algorithms | {{Journal}} of the {{ACM}}},
  author = {Fredman, Michael and Tarjan, Robert},
  urldate = {2023-04-26},
  howpublished = {https://dl.acm.org/doi/abs/10.1145/28869.28874},
  file = {/home/morgan/Zotero/storage/LJD4LRBA/28869.html}
}

@misc{fuldaWhatCanYou2017,
  title = {What Can You Do with a Rock? {{Affordance}} Extraction via Word Embeddings},
  shorttitle = {What Can You Do with a Rock?},
  author = {Fulda, Nancy and Ricks, Daniel and Murdoch, Ben and Wingate, David},
  year = {2017},
  month = mar,
  number = {arXiv:1703.03429},
  eprint = {1703.03429},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-05-25},
  abstract = {Autonomous agents must often detect affordances: the set of behaviors enabled by a situation. Affordance detection is particularly helpful in domains with large action spaces, allowing the agent to prune its search space by avoiding futile behaviors. This paper presents a method for affordance extraction via word embeddings trained on a Wikipedia corpus. The resulting word vectors are treated as a common knowledge database which can be queried using linear algebra. We apply this method to a reinforcement learning agent in a text-only environment and show that affordancebased action selection improves performance most of the time. Our method increases the computational complexity of each learning step but significantly reduces the total number of steps needed. In addition, the agent's action selections begin to resemble those a human would choose.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Fulda et al_2017_What can you do with a rock.pdf}
}

@misc{galleySeastalker1984,
  title = {Seastalker},
  author = {Galley, Stu},
  year = {1984}
}

@inproceedings{gardnerMakingReadingComprehension2019,
  title = {On {{Making Reading Comprehension More Comprehensive}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Machine Reading}} for {{Question Answering}}},
  author = {Gardner, Matt and Berant, Jonathan and Hajishirzi, Hannaneh and Talmor, Alon and Min, Sewon},
  year = {2019},
  pages = {105--112},
  publisher = {{Association for Computational Linguistics}},
  address = {{Hong Kong, China}},
  doi = {10.18653/v1/D19-5815},
  urldate = {2022-06-12},
  abstract = {Machine reading comprehension, the task of evaluating a machine's ability to comprehend a passage of text, has seen a surge in popularity in recent years. There are many datasets that are targeted at reading comprehension, and many systems that perform as well as humans on some of these datasets. Despite all of this interest, there is no work that systematically defines what reading comprehension is. In this work, we justify a question answering approach to reading comprehension and describe the various kinds of questions one might use to more fully test a system's comprehension of a passage, moving beyond questions that only probe local predicate-argument structures. The main pitfall of this approach is that questions can easily have surface cues or other biases that allow a model to shortcut the intended reasoning process. We discuss ways proposed in current literature to mitigate these shortcuts, and we conclude with recommendations for future dataset collection efforts.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Gardner et al_2019_On Making Reading Comprehension More Comprehensive.pdf}
}

@misc{gawthorpeEscapeStarshipZenon2000,
  title = {Escape from the {{Starship Zenon}}},
  author = {Gawthorpe, Andrew},
  year = {2000}
}

@misc{gebruDatasheetsDatasets2021,
  title = {Datasheets for {{Datasets}}},
  author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Daum{\'e} III, Hal and Crawford, Kate},
  year = {2021},
  month = dec,
  number = {arXiv:1803.09010},
  eprint = {1803.09010},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-06-12},
  abstract = {The machine learning community currently has no standardized process for documenting datasets, which can lead to severe consequences in high-stakes domains. To address this gap, we propose datasheets for datasets. In the electronics industry, every component, no matter how simple or complex, is accompanied with a datasheet that describes its operating characteristics, test results, recommended uses, and other information. By analogy, we propose that every dataset be accompanied with a datasheet that documents its motivation, composition, collection process, recommended uses, and so on. Datasheets for datasets will facilitate better communication between dataset creators and dataset consumers, and encourage the machine learning community to prioritize transparency and accountability.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Databases,Computer Science - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Gebru et al_2021_Datasheets for Datasets.pdf}
}

@inproceedings{geigerGarbageGarbageOut2020,
  title = {Garbage in, Garbage out?: Do Machine Learning Application Papers in Social Computing Report Where Human-Labeled Training Data Comes From?},
  shorttitle = {Garbage in, Garbage Out?},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Geiger, R. Stuart and Yu, Kevin and Yang, Yanlai and Dai, Mindy and Qiu, Jie and Tang, Rebekah and Huang, Jenny},
  year = {2020},
  month = jan,
  pages = {325--336},
  publisher = {{ACM}},
  address = {{Barcelona Spain}},
  doi = {10.1145/3351095.3372862},
  urldate = {2022-06-12},
  abstract = {Many machine learning projects for new application areas involve teams of humans who label data for a particular purpose, from hiring crowdworkers to the paper's authors labeling the data themselves. Such a task is quite similar to (or a form of) structured content analysis, which is a longstanding methodology in the social sciences and humanities, with many established best practices. In this paper, we investigate to what extent a sample of machine learning application papers in social computing {\textemdash} specifically papers from ArXiv and traditional publications performing an ML classification task on Twitter data {\textemdash} give specific details about whether such best practices were followed. Our team conducted multiple rounds of structured content analysis of each paper, making determinations such as: Does the paper report who the labelers were, what their qualifications were, whether they independently labeled the same items, whether inter-rater reliability metrics were disclosed, what level of training and/or instructions were given to labelers, whether compensation for crowdworkers is disclosed, and if the training data is publicly available. We find a wide divergence in whether such practices were followed and documented. Much of machine learning research and education focuses on what is done once a ``gold standard'' of training data is available, but we discuss issues around the equally-important aspect of whether such data is reliable in the first place.},
  isbn = {978-1-4503-6936-7},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Geiger et al_2020_Garbage in, garbage out.pdf}
}

@article{geirhosShortcutLearningDeep2020,
  title = {Shortcut Learning in Deep Neural Networks},
  author = {Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A.},
  year = {2020},
  month = nov,
  journal = {Nature Machine Intelligence},
  volume = {2},
  number = {11},
  pages = {665--673},
  issn = {2522-5839},
  doi = {10.1038/s42256-020-00257-z},
  urldate = {2022-06-12},
  abstract = {Deep learning has triggered the current rise of artificial intelligence and is the workhorse of today's machine intelligence. Numerous success stories have rapidly spread all over science, industry and society, but its limitations have only recently come into focus. In this perspective we seek to distil how many of deep learning's problem can be seen as different symptoms of the same underlying problem: shortcut learning. Shortcuts are decision rules that perform well on standard benchmarks but fail to transfer to more challenging testing conditions, such as real-world scenarios. Related issues are known in Comparative Psychology, Education and Linguistics, suggesting that shortcut learning may be a common characteristic of learning systems, biological and artificial alike. Based on these observations, we develop a set of recommendations for model interpretation and benchmarking, highlighting recent advances in machine learning to improve robustness and transferability from the lab to real-world applications.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Geirhos et al_2020_Shortcut learning in deep neural networks.pdf}
}

@misc{gentryAnchorhead1998,
  title = {Anchorhead},
  author = {Gentry, Michael},
  year = {1998}
}

@misc{gevaAreWeModeling2019,
  title = {Are {{We Modeling}} the {{Task}} or the {{Annotator}}? {{An Investigation}} of {{Annotator Bias}} in {{Natural Language Understanding Datasets}}},
  shorttitle = {Are {{We Modeling}} the {{Task}} or the {{Annotator}}?},
  author = {Geva, Mor and Goldberg, Yoav and Berant, Jonathan},
  year = {2019},
  month = aug,
  number = {arXiv:1908.07898},
  eprint = {1908.07898},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-06-12},
  abstract = {Crowdsourcing has been the prevalent paradigm for creating natural language understanding datasets in recent years. A common crowdsourcing practice is to recruit a small number of high-quality workers, and have them massively generate examples. Having only a few workers generate the majority of examples raises concerns about data diversity, especially when workers freely generate sentences. In this paper, we perform a series of experiments showing these concerns are evident in three recent NLP datasets. We show that model performance improves when training with annotator identifiers as features, and that models are able to recognize the most productive annotators. Moreover, we show that often models do not generalize well to examples from annotators that did not contribute to the training set. Our findings suggest that annotator bias should be monitored during dataset creation, and that test set annotators should be disjoint from training set annotators.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Geva et al_2019_Are We Modeling the Task or the Annotator.pdf}
}

@article{giannatosSuggestingNewPlot2011,
  title = {Suggesting {{New Plot Elements}} for an {{Interactive Story}}},
  author = {Giannatos, Spyridon and Nelson, Mark J and Cheong, Yun-Gyung and Yannakakis, Georgios N},
  year = {2011},
  pages = {6},
  abstract = {We present a system that uses evolutionary optimization to suggest new story-world events that, if added to an existing interactive story, would most improve the average interactive experience, according to author-supplied criteria. In doing so, we aim to apply some of the ideas from drama-managed storytelling, such as authorial aesthetic control, in an unguided setting more akin to emergent storytelling: rather than guiding or directing a player towards an experience in line with an author's aesthetic goals, the storyworld is augmented with new content in a way that will tend to align with an author's goals, even if the player is not guided. In this paper, we present an offline system, and demonstrate its robustness to a number of variations in authorial criteria and player-model assumptions. This is intended to lay the groundwork for a future system that would generate new content online, allowing for interactive stories larger than those explicitly written by the author.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Giannatos et al_Suggesting New Plot Elements for an Interactive Story.pdf}
}

@misc{glasserReverberations1996,
  title = {Reverberations},
  author = {Glasser, Russell},
  year = {1996}
}

@misc{GlkGlulxBlorb2022,
  title = {Glk, {{Glulx}}, and {{Blorb Specifications}}},
  year = {2022},
  month = jun,
  urldate = {2022-07-07},
  abstract = {Specification documents for the Glk, Glulx, and Blorb standards},
  howpublished = {Interactive Fiction Technology Foundation}
}

@article{gonenLipstickPigDebiasing2019,
  title = {Lipstick on a {{Pig}}: {{Debiasing Methods Cover}} up {{Systematic Gender Biases}} in {{Word Embeddings But}} Do Not {{Remove Them}}},
  shorttitle = {Lipstick on a {{Pig}}},
  author = {Gonen, Hila and Goldberg, Yoav},
  year = {2019},
  month = sep,
  journal = {arXiv:1903.03862 [cs]},
  eprint = {1903.03862},
  primaryclass = {cs},
  urldate = {2021-10-11},
  abstract = {Word embeddings are widely used in NLP for a vast range of tasks. It was shown that word embeddings derived from text corpora reflect gender biases in society. This phenomenon is pervasive and consistent across different word embedding models, causing serious concern. Several recent works tackle this problem, and propose methods for significantly reducing this gender bias in word embeddings, demonstrating convincing results. However, we argue that this removal is superficial. While the bias is indeed substantially reduced according to the provided bias definition, the actual effect is mostly hiding the bias, not removing it. The gender bias information is still reflected in the distances between ``gender-neutralized'' words in the debiased embeddings, and can be recovered from them. We present a series of experiments to support this claim, for two debiasing methods. We conclude that existing bias removal techniques are insufficient, and should not be trusted for providing gender-neutral modeling.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Gonen_Goldberg_2019_Lipstick on a Pig.pdf}
}

@misc{gonenLipstickPigDebiasing2019a,
  title = {Lipstick on a {{Pig}}: {{Debiasing Methods Cover}} up {{Systematic Gender Biases}} in {{Word Embeddings But}} Do Not {{Remove Them}}},
  shorttitle = {Lipstick on a {{Pig}}},
  author = {Gonen, Hila and Goldberg, Yoav},
  year = {2019},
  month = sep,
  number = {arXiv:1903.03862},
  eprint = {1903.03862},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-10-25},
  abstract = {Word embeddings are widely used in NLP for a vast range of tasks. It was shown that word embeddings derived from text corpora reflect gender biases in society. This phenomenon is pervasive and consistent across different word embedding models, causing serious concern. Several recent works tackle this problem, and propose methods for significantly reducing this gender bias in word embeddings, demonstrating convincing results. However, we argue that this removal is superficial. While the bias is indeed substantially reduced according to the provided bias definition, the actual effect is mostly hiding the bias, not removing it. The gender bias information is still reflected in the distances between ``gender-neutralized'' words in the debiased embeddings, and can be recovered from them. We present a series of experiments to support this claim, for two debiasing methods. We conclude that existing bias removal techniques are insufficient, and should not be trusted for providing gender-neutral modeling.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/home/morgan/Dropbox/eBooks/Articles/EmbeddingsPaper/Gonen and Goldberg - 2019 - Lipstick on a Pig Debiasing Methods Cover up Syst.pdf}
}

@article{gordonANARCHISMPOLITICSTECHNOLOGY2009,
  title = {{{ANARCHISM AND THE POLITICS OF TECHNOLOGY}}},
  author = {Gordon, Uri},
  year = {2009},
  month = sep,
  journal = {WorkingUSA},
  volume = {12},
  number = {3},
  pages = {489--503},
  issn = {10897011, 17434580},
  doi = {10.1111/j.1743-4580.2009.00250.x},
  urldate = {2022-06-01},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Gordon_2009_ANARCHISM AND THE POLITICS OF TECHNOLOGY.pdf}
}

@misc{guestGoldilocksFOX2002,
  title = {Goldilocks Is a {{FOX}}!},
  author = {Guest, J. J.},
  year = {2002}
}

@misc{guoInteractiveFictionGame2020,
  title = {Interactive {{Fiction Game Playing}} as {{Multi-Paragraph Reading Comprehension}} with {{Reinforcement Learning}}},
  author = {Guo, Xiaoxiao and Yu, Mo and Gao, Yupeng and Gan, Chuang and Campbell, Murray and Chang, Shiyu},
  year = {2020},
  month = oct,
  eprint = {2010.02386},
  primaryclass = {cs},
  urldate = {2022-05-25},
  abstract = {Interactive Fiction (IF) games with real human-written natural language texts provide a new natural evaluation for language understanding techniques. In contrast to previous text games with mostly synthetic texts, IF games pose language understanding challenges on the human-written textual descriptions of diverse and sophisticated game worlds and language generation challenges on the action command generation from less restricted combinatorial space. We take a novel perspective of IF game solving and re-formulate it as Multi-Passage Reading Comprehension (MPRC) tasks. Our approaches utilize the context-query attention mechanisms and the structured prediction in MPRC to efficiently generate and evaluate action outputs and apply an object-centric historical observation retrieval strategy to mitigate the partial observability of the textual observations. Extensive experiments on the recent IF benchmark (Jericho) demonstrate clear advantages of our approaches achieving high winning rates and low data requirements compared to all previous approaches. Our source code is available at: https://github.com/XiaoxiaoGuo/rcdqn.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Guo et al_2020_Interactive Fiction Game Playing as Multi-Paragraph Reading Comprehension with.pdf}
}

@inproceedings{guRevisitingRolesText2022,
  title = {Revisiting the {{Roles}} of ``{{Text}}'' in {{Text Games}}},
  booktitle = {{{ACL Workshop}} on {{Learning}} with {{Natural Language Supervision}}},
  author = {Gu, Yi and Yao, Shunyu and Gan, Chuang and Tenenbaum, Joshua B. and Yu, Mo},
  year = {2022},
  month = mar,
  urldate = {2022-05-25},
  abstract = {We find combining semantic and non-semantic representations can be complementary for different RL challenges in text games, while each alone works worse.},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Gu et al_2022_Revisiting the Roles of â€œTextâ€ in Text Games.pdf}
}

@inproceedings{gururanganAnnotationArtifactsNatural2018,
  title = {Annotation {{Artifacts}} in {{Natural Language Inference Data}}},
  booktitle = {Proceedings of the 2018 {{Conference}} of the {{North American Chapter}} of           the {{Association}} for {{Computational Linguistics}}: {{Human Language}}           {{Technologies}}, {{Volume}} 2 ({{Short Papers}})},
  author = {Gururangan, Suchin and Swayamdipta, Swabha and Levy, Omer and Schwartz, Roy and Bowman, Samuel and Smith, Noah A.},
  year = {2018},
  pages = {107--112},
  publisher = {{Association for Computational Linguistics}},
  address = {{New Orleans, Louisiana}},
  doi = {10.18653/v1/N18-2017},
  urldate = {2022-06-12},
  abstract = {Large-scale datasets for natural language inference are created by presenting crowd workers with a sentence (premise), and asking them to generate three new sentences (hypotheses) that it entails, contradicts, or is logically neutral with respect to. We show that, in a significant portion of such data, this protocol leaves clues that make it possible to identify the label by looking only at the hypothesis, without observing the premise. Specifically, we show that a simple text categorization model can correctly classify the hypothesis alone in about 67\% of SNLI (Bowman et al., 2015) and 53\% of MultiNLI (Williams et al., 2018). Our analysis reveals that specific linguistic phenomena such as negation and vagueness are highly correlated with certain inference classes. Our findings suggest that the success of natural language inference models to date has been overestimated, and that the task remains a hard open problem.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Gururangan et al_2018_Annotation Artifacts in Natural Language Inference Data.pdf}
}

@book{hallinanDataProtectionPrivacy2020,
  title = {Data {{Protection}} and {{Privacy}}: {{Data Protection}} and {{Democracy}}},
  shorttitle = {Data {{Protection}} and {{Privacy}}},
  editor = {Hallinan, Dara and Leenes, Ronald and Gutwirth, Serge and De Hert, Paul},
  year = {2020},
  publisher = {{Hart Publishing}},
  doi = {10.5040/9781509932771},
  urldate = {2022-06-12},
  abstract = {Artificial intelligence (AI) systems built on incomplete or biased data will often exhibit problematic outcomes. Current methods of data analysis, particularly before model development, are costly and not standardized. The Dataset Nutrition Label1 (the Label) is a diagnostic framework that lowers the barrier to standardized data analysis by providing a distilled yet comprehensive overview of dataset ``ingredients'' before AI model development. Building a Label that can be applied across domains and data types requires that the framework itself be flexible and adaptable; as such, the Label is comprised of diverse qualitative and quantitative modules generated through multiple statistical and probabilistic modelling backends, but displayed in a standardized format. To demonstrate and advance this concept, we generated and published an open source prototype2 with seven sample modules on the ProPublica Dollars for Docs dataset. The benefits of the Label are manyfold. For data specialists, the Label will drive more robust data analysis practices, provide an efficient way to select the best dataset for their purposes, and increase the overall quality of AI models as a result of more robust training datasets and the ability to check for issues at the time of model development. For those building and publishing datasets, the Label creates an expectation of explanation, which will drive better data collection practices. We also explore the limitations of the Label, including the challenges of generalizing across diverse datasets, and the risk of using ``ground truth'' data as a comparison dataset. We discuss ways to move forward given the limitations identified. Lastly, we lay out future directions for the Dataset Nutrition Label project, including research and public policy agendas to further advance consideration of the concept.},
  isbn = {978-1-5099-3274-0 978-1-5099-3276-4 978-1-5099-3275-7 978-1-5099-3277-1},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Hallinan et al_2020_Data Protection and Privacy.pdf}
}

@article{haoHowAIIndustry2022,
  title = {How the {{AI}} Industry Profits from Catastrophe},
  author = {Hao, Karen and Paola Hern{\'a}ndez, Andrea},
  year = {2022},
  month = apr,
  journal = {MIT Technology Review},
  urldate = {2022-05-28},
  abstract = {As the demand for data labeling exploded, an economic catastrophe turned Venezuela into ground zero for a new model of labor exploitation.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Hao_Paola HernÃ¡ndez_2022_How the AI industry profits from catastrophe.pdf;/home/morgan/Zotero/storage/EKI7EERA/ai-industry-appen-scale-data-labels.html}
}

@article{haroushLearningHowNot2018,
  title = {Learning {{How Not}} to {{Act}} in {{Text-based Games}}},
  author = {Haroush, Matan and Zahavy, Tom and Mankowitz, Daniel J. and Mannor, Shie},
  year = {2018},
  month = feb,
  urldate = {2022-04-17},
  abstract = {A DRL agent that learns to eliminate actions in order to solve text-based games with large action spaces},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Haroush et al_2018_Learning How Not to Act in Text-based Games.pdf}
}

@misc{hausknechtInteractiveFictionGames2020,
  title = {Interactive {{Fiction Games}}: {{A Colossal Adventure}}},
  shorttitle = {Interactive {{Fiction Games}}},
  author = {Hausknecht, Matthew and Ammanabrolu, Prithviraj and C{\^o}t{\'e}, Marc-Alexandre and Yuan, Xingdi},
  year = {2020},
  month = feb,
  number = {arXiv:1909.05398},
  eprint = {1909.05398},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-07-07},
  abstract = {A hallmark of human intelligence is the ability to understand and communicate with language. Interactive Fiction games are fully text-based simulation environments where a player issues text commands to effect change in the environment and progress through the story. We argue that IF games are an excellent testbed for studying language-based autonomous agents. In particular, IF games combine challenges of combinatorial action spaces, language understanding, and commonsense reasoning. To facilitate rapid development of language-based agents, we introduce Jericho, a learning environment for man-made IF games and conduct a comprehensive study of text-agents across a rich set of games, highlighting directions in which agents can improve.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Hausknecht et al_2020_Interactive Fiction Games2.pdf}
}

@article{hausknechtInteractiveFictionGames2020a,
  title = {Interactive {{Fiction Games}}: {{A Colossal Adventure}}},
  shorttitle = {Interactive {{Fiction Games}}},
  author = {Hausknecht, Matthew and Ammanabrolu, Prithviraj and C{\^o}t{\'e}, Marc-Alexandre and Yuan, Xingdi},
  year = {2020},
  month = apr,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {34},
  number = {05},
  pages = {7903--7910},
  issn = {2374-3468},
  doi = {10.1609/aaai.v34i05.6297},
  urldate = {2022-05-01},
  abstract = {A hallmark of human intelligence is the ability to understand and communicate with language. Interactive Fiction games are fully text-based simulation environments where a player issues text commands to effect change in the environment and progress through the story. We argue that IF games are an excellent testbed for studying language-based autonomous agents. In particular, IF games combine challenges of combinatorial action spaces, language understanding, and commonsense reasoning. To facilitate rapid development of language-based agents, we introduce Jericho, a learning environment for man-made IF games and conduct a comprehensive study of text-agents across a rich set of games, highlighting directions in which agents can improve.},
  copyright = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Hausknecht et al_2020_Interactive Fiction Games.pdf}
}

@article{hausknechtNAILGeneralInteractive2019,
  title = {{{NAIL}}: {{A General Interactive Fiction Agent}}},
  shorttitle = {{{NAIL}}},
  author = {Hausknecht, Matthew and Loynd, Ricky and Yang, Greg and Swaminathan, Adith and Williams, Jason D.},
  year = {2019},
  month = feb,
  doi = {10.48550/arXiv.1902.04259},
  urldate = {2022-05-02},
  abstract = {Interactive Fiction (IF) games are complex textual decision making problems. This paper introduces NAIL, an autonomous agent for general parser-based IF games. NAIL won the 2018 Text Adventure AI Competition, where it was evaluated on twenty unseen games. This paper describes the architecture, development, and insights underpinning NAIL's performance.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Hausknecht et al_2019_NAIL.pdf;/home/morgan/Zotero/storage/SA48R4WV/1902.html}
}

@misc{heDeepReinforcementLearning2016,
  title = {Deep {{Reinforcement Learning}} with a {{Natural Language Action Space}}},
  author = {He, Ji and Chen, Jianshu and He, Xiaodong and Gao, Jianfeng and Li, Lihong and Deng, Li and Ostendorf, Mari},
  year = {2016},
  month = jun,
  number = {arXiv:1511.04636},
  eprint = {1511.04636},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-05-25},
  abstract = {This paper introduces a novel architecture for reinforcement learning with deep neural networks designed to handle state and action spaces characterized by natural language, as found in text-based games. Termed a deep reinforcement relevance network (DRRN), the architecture represents action and state spaces with separate embedding vectors, which are combined with an interaction function to approximate the Q-function in reinforcement learning. We evaluate the DRRN on two popular text games, showing superior performance over other deep Qlearning architectures. Experiments with paraphrased action descriptions show that the model is extracting meaning rather than simply memorizing strings of text.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/He et al_2016_Deep Reinforcement Learning with a Natural Language Action Space.pdf}
}

@misc{hendersonLudicorpMystery2006,
  title = {The {{Ludicorp Mystery}}},
  author = {Henderson, Cal "Bees"},
  year = {2006}
}

@techreport{highlevelexpertgrouponaiEthicsGuidelinesTrustworthy2019,
  title = {Ethics Guidelines for Trustworthy {{AI}} | {{Shaping Europe}}'s Digital Future},
  author = {{High Level Expert Group on AI}},
  year = {2019},
  month = apr,
  institution = {{European Commission}},
  urldate = {2022-05-27},
  abstract = {On 8 April 2019, the High-Level Expert Group on AI presented Ethics Guidelines for Trustworthy Artificial Intelligence. This followed the publication of the guidelines' first draft in December 2018 on which more than 500 comments were received through an open consultation.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/High Level Expert Group on AI_2019_Ethics guidelines for trustworthy AI Shaping Europeâ€™s digital future.pdf;/home/morgan/Zotero/storage/EDVITIM4/ethics-guidelines-trustworthy-ai.html}
}

@article{hoffmannTermsInclusionData2021,
  title = {Terms of Inclusion: {{Data}}, Discourse, Violence},
  shorttitle = {Terms of Inclusion},
  author = {Hoffmann, Anna Lauren},
  year = {2021},
  month = dec,
  journal = {New Media \& Society},
  volume = {23},
  number = {12},
  pages = {3539--3556},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/1461444820958725},
  urldate = {2022-06-12},
  abstract = {Inclusion has emerged as an early cornerstone value for the emerging domain of ``data ethics.'' On the surface, appeals to inclusion appear to address the threat that biased data technologies making decisions or misrepresenting people in ways that reproduce longer standing patterns of oppression and violence. Far from a panacea for the threats of pervasive data collection and surveillance, however, these emerging discourses of inclusion merit critical consideration. Here, I use the lens of discursive violence to better theorize the relationship between inclusion and the violent potentials of data science and technology. In doing so, I aim to articulate the problematic and often perverse power relationships implicit in ideals of ``inclusion'' broadly, which{\textemdash}if not accompanied by dramatic upheavals in existing hierarchical power structures{\textemdash}too often work to diffuse the radical potential of difference and normalize otherwise oppressive structural conditions.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Hoffmann_2021_Terms of inclusion.pdf}
}

@article{hoffmannWhereFairnessFails2019,
  title = {Where Fairness Fails: Data, Algorithms, and the Limits of Antidiscrimination Discourse},
  shorttitle = {Where Fairness Fails},
  author = {Hoffmann, Anna Lauren},
  year = {2019},
  month = jun,
  journal = {Information, Communication \& Society},
  volume = {22},
  number = {7},
  pages = {900--915},
  issn = {1369-118X, 1468-4462},
  doi = {10.1080/1369118X.2019.1573912},
  urldate = {2022-05-29},
  abstract = {Problems of bias and fairness are central to data justice, as they speak directly to the threat that `big data' and algorithmic decision-making may worsen already existing injustices. In the United States, grappling with these problems has found clearest expression through liberal discourses of rights, due process, and antidiscrimination. Work in this area, however, has tended to overlook certain established limits of antidiscrimination discourses for bringing about the change demanded by social justice. In this paper, I engage three of these limits: 1) an overemphasis on discrete `bad actors', 2) single-axis thinking that centers disadvantage, and 3) an inordinate focus on a limited set of goods. I show that, in mirroring some of antidiscrimination discourse's most problematic tendencies, efforts to achieve fairness and combat algorithmic discrimination fail to address the very hierarchical logic that produces advantaged and disadvantaged subjects in the first place. Finally, I conclude by sketching three paths for future work to better account for the structural conditions against which we come to understand problems of data and unjust discrimination in the first place.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Hoffmann_2019_Where fairness fails.pdf}
}

@inproceedings{hongPredictionExtractionDiscretion2022,
  title = {Prediction as {{Extraction}} of {{Discretion}}},
  booktitle = {2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Hong, Sun-ha},
  year = {2022},
  month = jun,
  pages = {925--934},
  publisher = {{ACM}},
  address = {{Seoul Republic of Korea}},
  doi = {10.1145/3531146.3533155},
  urldate = {2022-07-07},
  abstract = {I argue that data-driven predictions work primarily as instruments for systematic extraction of discretionary power {\textendash} the practical capacity to make everyday decisions and define one's situation. This extractive relation reprises a long historical pattern, in which new methods of producing knowledge generate a redistribution of epistemic power: who declares what kind of truth about me, to count for what kinds of decisions? I argue that prediction as extraction of discretion is normal and fundamental to the technology, rather than isolated cases of bias or error. Synthesising critical observations across anthropology, history of technology and critical data studies, the paper demonstrates this dynamic in two contemporary domains: (1) crime and policing demonstrates how predictive systems are extractive by design. Rather than neutral models led astray by garbage data, pre-existing interests thoroughly shape how prediction conceives of its object, its measures, and most importantly, what it does not measure and in doing so devalues. (2) I then examine the prediction of productivity in the long tradition of extracting discretion as a means to extract labour power. Making human behaviour more predictable for the client of prediction (the manager, the corporation, the police officer) often means making life and work more unpredictable for the target of prediction (the employee, the applicant, the citizen).},
  isbn = {978-1-4503-9352-2},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Hong_2022_Prediction as Extraction of Discretion.pdf}
}

@misc{hornsMeteorStoneLong1996,
  title = {The {{Meteor}}, the {{Stone}} and a {{Long Glass}} of {{Sherbet}}},
  author = {Horns), Graham Nelson (as Angela M.},
  year = {1996}
}

@inproceedings{hutchinsonAccountabilityMachineLearning2021,
  title = {Towards {{Accountability}} for {{Machine Learning Datasets}}: {{Practices}} from {{Software Engineering}} and {{Infrastructure}}},
  shorttitle = {Towards {{Accountability}} for {{Machine Learning Datasets}}},
  booktitle = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Hutchinson, Ben and Smart, Andrew and Hanna, Alex and Denton, Emily and Greer, Christina and Kjartansson, Oddur and Barnes, Parker and Mitchell, Margaret},
  year = {2021},
  month = mar,
  pages = {560--575},
  publisher = {{ACM}},
  address = {{Virtual Event Canada}},
  doi = {10.1145/3442188.3445918},
  urldate = {2022-06-12},
  abstract = {Datasets that power machine learning are often used, shared, and reused with little visibility into the processes of deliberation that led to their creation. As artificial intelligence systems are increasingly used in high-stakes tasks, system development and deployment practices must be adapted to address the very real consequences of how model development data is constructed and used in practice. This includes greater transparency about data, and accountability for decisions made when developing it. In this paper, we introduce a rigorous framework for dataset development transparency that supports decision-making and accountability. The framework uses the cyclical, infrastructural and engineering nature of dataset development to draw on best practices from the software development lifecycle. Each stage of the data development lifecycle yields documents that facilitate improved communication and decisionmaking, as well as drawing attention to the value and necessity of careful data work. The proposed framework makes visible the often overlooked work and decisions that go into dataset creation, a critical step in closing the accountability gap in artificial intelligence and a critical/necessary resource aligned with recent work on auditing processes.},
  isbn = {978-1-4503-8309-7},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Hutchinson et al_2021_Towards Accountability for Machine Learning Datasets.pdf}
}

@misc{iftf_glulx,
  title = {Glulx: {{A}} 32-{{Bit Virtual Machine}} for {{IF}}},
  author = {Interactive Fiction Technology Foundation},
  urldate = {2022-08-10},
  howpublished = {https://www.eblong.com/zarf/glulx/Glulx-Spec.html\#intro},
  file = {/home/morgan/Zotero/storage/XN29YLV2/Glulx-Spec.html}
}

@misc{IFWikiInteractiveFiction,
  title = {{{IFWiki}}: {{Interactive}} Fiction},
  urldate = {2022-08-12},
  howpublished = {https://www.ifwiki.org/Interactive\_fiction},
  file = {/home/morgan/Zotero/storage/QBZIELHZ/Interactive_fiction.html}
}

@misc{IfYouRe2020,
  title = {If {{You}}'re {{De-Biasing The Model}}, {{It}}'s {{Too Late}} - {{Scale}}},
  year = {2020},
  month = aug,
  journal = {ScaleAI},
  urldate = {2022-06-12},
  abstract = {Scale AI's platform can help mitigate bias before training a model.},
  howpublished = {https://scale.com/blog/if-youre-de-biasing-the-model-its-too-late},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/2020_If Youâ€™re De-Biasing The Model, Itâ€™s Too Late - Scale.pdf;/home/morgan/Zotero/storage/LDD5I529/if-youre-de-biasing-the-model-its-too-late.html}
}

@misc{inform,
  title = {Inform - {{Welcome}} - {{Introduction}}},
  author = {Nelson, Graham},
  year = {2002},
  month = mar,
  urldate = {2022-08-11},
  howpublished = {https://inform-fiction.org/introduction/index.html},
  file = {/home/morgan/Zotero/storage/EVPYLPP6/index.html}
}

@misc{inkle,
  title = {Inklewriter},
  author = {Humfrey, Joseph and Ingold, Jon},
  urldate = {2022-09-01},
  howpublished = {https://www.inklestudios.com/inklewriter/},
  file = {/home/morgan/Zotero/storage/CPSIH5HD/inklewriter.html}
}

@misc{instead,
  title = {{{INSTEAD}}},
  author = {Kosih, Petr},
  year = {2021},
  month = sep,
  urldate = {2022-07-03},
  abstract = {Development platform and interpreter for Russian language text-based games},
  howpublished = {https://instead.hugeping.ru/}
}

@misc{interactivefictiontechnologyfoundationInteractiveFictionDatabase,
  title = {The {{Interactive Fiction Database}} - {{IF}} and {{Text Adventures}}},
  shorttitle = {{{IFDB}}},
  author = {Interactive Fiction Technology Foundation},
  urldate = {2022-05-02},
  abstract = {The Interactive Fiction Database is an IF game catalog and recommendation engine. IFDB is a Wiki-style community project: members can add new game listings, write reviews, exchange game recommendations, and more.},
  howpublished = {https://ifdb.org/},
  file = {/home/morgan/Zotero/storage/QC48LNH5/ifdb.org.html}
}

@article{israelRoleLogicKnowledge1983,
  title = {The {{Role}} of {{Logic}} in {{Knowledge Representation}}},
  author = {{Israel}},
  year = {1983},
  month = oct,
  journal = {Computer},
  volume = {16},
  number = {10},
  pages = {37--41},
  issn = {0018-9162},
  doi = {10.1109/MC.1983.1654195},
  urldate = {2022-05-25},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Israel_1983_The Role of Logic in Knowledge Representation.pdf}
}

@article{jainAlgorithmicImprovementsDeep2020,
  title = {Algorithmic {{Improvements}} for {{Deep Reinforcement Learning Applied}} to {{Interactive Fiction}}},
  author = {Jain, Vishal and Fedus, William and Larochelle, Hugo and Precup, Doina and Bellemare, Marc G.},
  year = {2020},
  month = apr,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {34},
  number = {04},
  pages = {4328--4336},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v34i04.5857},
  urldate = {2022-05-25},
  abstract = {Text-based games are a natural challenge domain for deep reinforcement learning algorithms. Their state and action spaces are combinatorially large, their reward function is sparse, and they are partially observable: the agent is informed of the consequences of its actions through textual feedback. In this paper we emphasize this latter point and consider the design of a deep reinforcement learning agent that can play from feedback alone. Our design recognizes and takes advantage of the structural characteristics of textbased games. We first propose a contextualisation mechanism, based on accumulated reward, which simplifies the learning problem and mitigates partial observability. We then study different methods that rely on the notion that most actions are ineffectual in any given situation, following Zahavy et al.'s idea of an admissible action. We evaluate these techniques in a series of text-based games of increasing difficulty based on the TextWorld framework, as well as the iconic game ZORK. Empirically, we find that these techniques improve the performance of a baseline deep reinforcement learning agent applied to text-based games.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Jain et al_2020_Algorithmic Improvements for Deep Reinforcement Learning Applied to Interactive.pdf}
}

@misc{jansenSystematicSurveyText2021,
  title = {A {{Systematic Survey}} of {{Text Worlds}} as {{Embodied Natural Language Environments}}},
  author = {Jansen, Peter A.},
  year = {2021},
  month = jul,
  number = {arXiv:2107.04132},
  eprint = {2107.04132},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-05-25},
  abstract = {Text Worlds are virtual environments for embodied agents that, unlike 2D or 3D environments, are rendered exclusively using textual descriptions. These environments offer an alternative to higher-fidelity 3D environments due to their low barrier to entry, providing the ability to study semantics, compositional inference, and other high-level tasks with rich highlevel action spaces while controlling for perceptual input. This systematic survey outlines recent developments in tooling, environments, and agent modeling for Text Worlds, while examining recent trends in knowledge graphs, common sense reasoning, transfer learning of Text World performance to higher-fidelity environments, as well as near-term development targets that, once achieved, make Text Worlds an attractive general research paradigm for natural language processing.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Jansen_2021_A Systematic Survey of Text Worlds as Embodied Natural Language Environments.pdf}
}

@article{jiechieuSkillsPredictionBased2021,
  title = {Skills Prediction Based on Multi-Label Resume Classification Using {{CNN}} with Model Predictions Explanation},
  author = {Jiechieu, Kameni Florentin Flambeau and Tsopze, Norbert},
  year = {2021},
  month = may,
  journal = {Neural Computing and Applications},
  volume = {33},
  number = {10},
  pages = {5069--5087},
  issn = {0941-0643, 1433-3058},
  doi = {10.1007/s00521-020-05302-x},
  urldate = {2022-11-01},
  abstract = {Skills extraction is a critical task when creating job recommender systems. It is also useful for building skills profiles and skills knowledge bases for organizations. The aim of skills extraction is to identify the skills expressed in documents such as resumes or job postings. Several methods have been proposed to tackle this problem. These methods already perform well when it comes to extracting explicitly mentioned skills from resumes. But skills have different levels of abstraction: high-level skills can be determined by low-level ones. Instead of just extracting skill-related terms, we propose a multilabel classification architecture model based on convolutional neural networks to predict high-level skills from resumes even if they are not explicitly mentioned in these resumes. Experiments carried out on a set of anonymous IT resumes collected from the Internet have shown the effectiveness of our method reaching 98.79\% of recall and 91.34\% of precision. In addition, features (terms) detected by convolutional filters are projected on the input resumes in order to present to the user, the terms which contributed to the model decision.},
  langid = {english},
  annotation = {https://github.com/florex/resume\_corpus},
  file = {/home/morgan/Dropbox/eBooks/Articles/EmbeddingsPaper/Jiechieu and Tsopze - 2021 - Skills prediction based on multi-label resume clas.pdf}
}

@article{johnsonGhostMachineHas2022,
  title = {The {{Ghost}} in the {{Machine}} Has an {{American}} Accent: Value Conflict in {{GPT-3}}.},
  author = {Johnson, Rebecca L and Panai, Enrico and Pistilli, Giada and Kalpokiene, Julija and {Men{\'e}dez-Gonz{\'a}lez}, Natalia and Bertulfo, Donald Jay and Duran, Leslye Denisse Dias},
  year = {2022},
  month = mar,
  pages = {15},
  abstract = {The alignment problem in the context of large language models must consider the plurality of human values in our world. Whilst there are many resonant and overlapping values amongst the world's cultures, there are also many conflicting, yet equally valid, values. It is important to observe which cultural values a model exhibits, particularly when there is a value conflict between input prompts and generated outputs. We discuss how the cocreation of language and cultural value impacts large language models (LLMs). We explore the constitution of the training data for GPT-3 and compare that to the world's language and internet access demographics, as well as to reported statistical profiles of dominant values in some Nation-states. We stress tested GPT-3 with a range of value-rich texts representing several languages and nations; including some with values orthogonal to dominant US public opinion as reported by the World Values Survey. We observed when values embedded in the input text were mutated in the generated outputs and noted when these conflicting values were more aligned with reported dominant US values. Our discussion of these results uses a moral value pluralism (MVP) lens to better understand these value mutations. Finally, we provide recommendations for how our work may contribute to other current work in the field.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Johnson et al_2022_The Ghost in the Machine has an American accent.pdf}
}

@inproceedings{joLessonsArchivesStrategies2020,
  title = {Lessons from Archives: Strategies for Collecting Sociocultural Data in Machine Learning},
  shorttitle = {Lessons from Archives},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Jo, Eun Seo and Gebru, Timnit},
  year = {2020},
  month = jan,
  pages = {306--316},
  publisher = {{ACM}},
  address = {{Barcelona Spain}},
  doi = {10.1145/3351095.3372829},
  urldate = {2022-06-12},
  abstract = {A growing body of work shows that many problems in fairness, accountability, transparency, and ethics in machine learning systems are rooted in decisions surrounding the data collection and annotation process. In spite of its fundamental nature however, data collection remains an overlooked part of the machine learning (ML) pipeline. In this paper, we argue that a new specialization should be formed within ML that is focused on methodologies for data collection and annotation: efforts that require institutional frameworks and procedures. Specifically for sociocultural data, parallels can be drawn from archives and libraries. Archives are the longest standing communal effort to gather human information and archive scholars have already developed the language and procedures to address and discuss many challenges pertaining to data collection such as consent, power, inclusivity, transparency, and ethics \& privacy. We discuss these five key approaches in document collection practices in archives that can inform data collection in sociocultural ML. By showing data collection practices from another field, we encourage ML research to be more cognizant and systematic in data collection and draw from interdisciplinary expertise.},
  isbn = {978-1-4503-6936-7},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Jo_Gebru_2020_Lessons from archives.pdf}
}

@misc{jotaLostPig2007,
  title = {Lost {{Pig}}},
  author = {Jota, Adam},
  year = {2007}
}

@incollection{jurafskyVectorSemanticsEmbeddings2021,
  title = {Vector {{Semantics}} and {{Embeddings}}},
  booktitle = {Speech and {{Language Processing}}},
  author = {Jurafsky, Dan and Martin, James H.},
  year = {2021},
  month = dec,
  edition = {3rd edition draft},
  urldate = {2022-10-28},
  file = {/home/morgan/Zotero/storage/65HHBEXH/slp3.html}
}

@incollection{karp_reducibilityCombinatorial_2010,
  title = {Reducibility {{Among Combinatorial Problems}}},
  booktitle = {50 {{Years}} of {{Integer Programming}} 1958-2008: {{From}} the {{Early Years}} to the {{State-of-the-Art}}},
  author = {Karp, Richard M.},
  editor = {J{\"u}nger, Michael and Liebling, Thomas M. and Naddef, Denis and Nemhauser, George L. and Pulleyblank, William R. and Reinelt, Gerhard and Rinaldi, Giovanni and Wolsey, Laurence A.},
  year = {2010},
  pages = {219--241},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-68279-0_8},
  urldate = {2023-05-07},
  abstract = {Throughout the 1960s I worked on combinatorial optimization problems including logic circuit design with Paul Roth and assembly line balancing and the traveling salesman problem with Mike Held. These experiences made me aware that seemingly simple discrete optimization problems could hold the seeds of combinatorial explosions. The work of Dantzig, Fulkerson, Hoffman, Edmonds, Lawler and other pioneers on network flows, matching and matroids acquainted me with the elegant and efficient algorithms that were sometimes possible. Jack Edmonds' papers and a few key discussions with him drew my attention to the crucial distinction between polynomial-time and superpolynomial-time solvability. I was also influenced by Jack's emphasis on min-max theorems as a tool for fast verification of optimal solutions, which foreshadowed Steve Cook's definition of the complexity class NP. Another influence was George Dantzig's suggestion that integer programming could serve as a universal format for combinatorial optimization problems.},
  isbn = {978-3-540-68279-0},
  langid = {english},
  file = {/home/morgan/Zotero/storage/G9BVLJ9N/Karp - 2010 - Reducibility Among Combinatorial Problems.pdf}
}

@inproceedings{kaushikHowMuchReading2018,
  title = {How {{Much Reading Does Reading Comprehension Require}}? {{A Critical Investigation}} of {{Popular Benchmarks}}},
  shorttitle = {How {{Much Reading Does Reading Comprehension Require}}?},
  booktitle = {Proceedings of the 2018 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Kaushik, Divyansh and Lipton, Zachary C.},
  year = {2018},
  pages = {5010--5015},
  publisher = {{Association for Computational Linguistics}},
  address = {{Brussels, Belgium}},
  doi = {10.18653/v1/D18-1546},
  urldate = {2022-06-12},
  abstract = {Many recent papers address reading comprehension, where examples consist of (question, passage, answer) tuples. Presumably, a model must combine information from both questions and passages to predict corresponding answers. However, despite intense interest in the topic, with hundreds of published papers vying for leaderboard dominance, basic questions about the difficulty of many popular benchmarks remain unanswered. In this paper, we establish sensible baselines for the bAbI, SQuAD, CBT, CNN, and Whodid-What datasets, finding that question- and passage-only models often perform surprisingly well. On 14 out of 20 bAbI tasks, passage-only models achieve greater than 50\% accuracy, sometimes matching the full model. Interestingly, while CBT provides 20-sentence stories only the last is needed for comparably accurate prediction. By comparison, SQuAD and CNN appear better-constructed.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Kaushik_Lipton_2018_How Much Reading Does Reading Comprehension Require.pdf}
}

@inproceedings{keyesHumanComputerInsurrectionNotes2019,
  title = {Human-{{Computer Insurrection}}: {{Notes}} on an {{Anarchist HCI}}},
  shorttitle = {Human-{{Computer Insurrection}}},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Keyes, Os and Hoy, Josephine and Drouhard, Margaret},
  year = {2019},
  month = may,
  pages = {1--13},
  publisher = {{ACM}},
  address = {{Glasgow Scotland Uk}},
  doi = {10.1145/3290605.3300569},
  urldate = {2022-06-01},
  isbn = {978-1-4503-5970-2},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Keyes et al_2019_Human-Computer Insurrection.pdf}
}

@article{keyesTruthMachineArtificial2021,
  title = {Truth from the Machine: Artificial Intelligence and the Materialization of Identity},
  shorttitle = {Truth from the Machine},
  author = {Keyes, Os and Hitzig, Zo{\"e} and Blell, Mwenza},
  year = {2021},
  month = apr,
  journal = {Interdisciplinary Science Reviews},
  volume = {46},
  number = {1-2},
  pages = {158--175},
  issn = {0308-0188, 1743-2790},
  doi = {10.1080/03080188.2020.1840224},
  urldate = {2022-06-01},
  abstract = {Critics now articulate their worries about the technologies, social practices and mythologies that comprise Artificial Intelligence (AI) in many domains. In this paper, we investigate the intersection of two domains of criticism: identity and scientific knowledge. On one hand, critics of AI in public policy emphasise its potential to discriminate on the basis of identity. On the other hand, critics of AI in scientific realms worry about how it may reorient or disorient research practices and the progression of scientific inquiry. We link the two sets of concerns{\textemdash}around identity and around knowledge{\textemdash}through a series of case studies. In our case studies, about autism and homosexuality, AI figures as part of scientific attempts to find, and fix, forms of identity. Our case studies are instructive: they show that when AI is deployed in scientific research about identity and personality, it can naturalise and reinforce biases. The identity-based and epistemic concerns about AI are not distinct. When AI is seen as a source of truth and scientific knowledge, it may lend public legitimacy to harmful ideas about identity.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Keyes et al_2021_Truth from the machine.pdf}
}

@article{khanAmazonAntitrustParadox2017,
  title = {Amazon's {{Antitrust Paradox}}},
  author = {Khan, Lina M},
  year = {2017},
  month = jan,
  journal = {the yale law journal},
  pages = {96},
  langid = {english},
  keywords = {amazon,ethics},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Khan_2017_Amazonâ€™s Antitrust Paradox.pdf}
}

@inproceedings{kiritchenkoExaminingGenderRace2018,
  title = {Examining {{Gender}} and {{Race Bias}} in {{Two Hundred Sentiment Analysis Systems}}},
  booktitle = {Proceedings of the {{Seventh Joint Conference}} on {{Lexical}} and           {{Computational Semantics}}},
  author = {Kiritchenko, Svetlana and Mohammad, Saif},
  year = {2018},
  pages = {43--53},
  publisher = {{Association for Computational Linguistics}},
  address = {{New Orleans, Louisiana}},
  doi = {10.18653/v1/S18-2005},
  urldate = {2022-11-01},
  abstract = {Automatic machine learning systems can inadvertently accentuate and perpetuate inappropriate human biases. Past work on examining inappropriate biases has largely focused on just individual systems. Further, there is no benchmark dataset for examining inappropriate biases in systems. Here for the first time, we present the Equity Evaluation Corpus (EEC), which consists of 8,640 English sentences carefully chosen to tease out biases towards certain races and genders. We use the dataset to examine 219 automatic sentiment analysis systems that took part in a recent shared task, SemEval-2018 Task 1 `Affect in Tweets'. We find that several of the systems show statistically significant bias; that is, they consistently provide slightly higher sentiment intensity predictions for one race or one gender. We make the EEC freely available.},
  langid = {english},
  file = {/home/morgan/Dropbox/eBooks/Articles/EmbeddingsPaper/Kiritchenko and Mohammad - 2018 - Examining Gender and Race Bias in Two Hundred Sent.pdf}
}

@incollection{knuthAlgorithms1997,
  title = {1.1 {{Algorithms}}},
  booktitle = {The {{Art}} of {{Computer Programming}}, {{Vol}}. 1: {{Fundamental Algorithms}}, 3rd {{Edition}}},
  author = {Knuth, Donald},
  year = {1997},
  month = jul,
  edition = {3rd edition},
  publisher = {{Addison-Wesley Professional}},
  address = {{Reading, Mass}},
  isbn = {978-0-201-89683-1},
  langid = {english}
}

@inproceedings{kostka2017text,
  title = {Text-Based Adventures of the Golovin {{AI}} Agent},
  booktitle = {2017 {{IEEE}} Conference on Computational Intelligence and Games ({{CIG}})},
  author = {Kostka, Bartosz and Kwiecieli, Jaroslaw and Kowalski, Jakub and Rychlikowski, Pawel},
  year = {2017},
  pages = {181--188},
  organization = {{IEEE}}
}

@misc{kosyhMETEL2021,
  title = {{{\cyrchar\CYRM}{\cyrchar\CYRE}{\cyrchar\CYRT}{\cyrchar\CYRE}{\cyrchar\CYRL}{\cyrchar\CYRSFTSN}}},
  author = {{\cyrchar\CYRK}{\cyrchar\cyro}{\cyrchar\cyrs}{\cyrchar\cyrery}{\cyrchar\cyrh}, {\cyrchar\CYRP}{\cyrchar\cyre}{\cyrchar\cyrt}{\cyrchar\cyrr}},
  year = {2021},
  month = may,
  urldate = {2022-07-03},
  abstract = {interactive fiction game (in Russian)},
  langid = {russian}
}

@misc{kudoSentencePieceSimpleLanguage2018,
  title = {{{SentencePiece}}: {{A}} Simple and Language Independent Subword Tokenizer and Detokenizer for {{Neural Text Processing}}},
  shorttitle = {{{SentencePiece}}},
  author = {Kudo, Taku and Richardson, John},
  year = {2018},
  month = aug,
  number = {arXiv:1808.06226},
  eprint = {1808.06226},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-07-07},
  abstract = {This paper describes SentencePiece, a language-independent subword tokenizer and detokenizer designed for Neural-based text processing, including Neural Machine Translation. It provides open-source C++ and Python implementations for subword units. While existing subword segmentation tools assume that the input is pre-tokenized into word sequences, SentencePiece can train subword models directly from raw sentences, which allows us to make a purely end-to-end and language independent system. We perform a validation experiment of NMT on English-Japanese machine translation, and find that it is possible to achieve comparable accuracy to direct subword training from raw sentences. We also compare the performance of subword training and segmentation with various configurations. SentencePiece is available under the Apache 2 license at https://github.com/google/ sentencepiece.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Kudo_Richardson_2018_SentencePiece.pdf}
}

@article{kushnerMarkov1999,
  title = {Markov's Constructive Analysis; a Participant's View},
  author = {Kushner, Boris A},
  year = {1999},
  journal = {Theoretical Computer Science},
  volume = {219},
  number = {1-2},
  pages = {267--285},
  publisher = {{Elsevier}}
}

@misc{leblingLurkingHorror1987,
  title = {The {{Lurking Horror}}},
  author = {Lebling, Dave},
  year = {1987}
}

@misc{leblingSpellbreaker1985,
  title = {Spellbreaker},
  author = {Lebling, Dave},
  year = {1985}
}

@misc{leblingZorkII1981,
  title = {Zork {{II}}},
  author = {Lebling, Dave},
  year = {1981}
}

@misc{leeMoonlitTower2002,
  title = {The {{Moonlit Tower}}},
  author = {Lee, Yoon Ha},
  year = {2002}
}

@misc{leinonenRaisingFlagMount2010,
  title = {Raising the {{Flag}} on {{Mount Yo Momma}}},
  author = {Leinonen, Juhana},
  year = {2010}
}

@inproceedings{li_quantifyingCost_2007,
  title = {Quantifying the Cost of Context Switch},
  booktitle = {Proceedings of the 2007 Workshop on {{Experimental}} Computer Science},
  author = {Li, Chuanpeng and Ding, Chen and Shen, Kai},
  year = {2007},
  month = jun,
  pages = {2},
  publisher = {{ACM}},
  address = {{San Diego California}},
  doi = {10.1145/1281700.1281702},
  urldate = {2023-04-28},
  isbn = {978-1-59593-751-3},
  langid = {english},
  file = {/home/morgan/Zotero/storage/DTKQ6XD9/Li et al. - 2007 - Quantifying the cost of context switch.pdf}
}

@inproceedings{linehanNeverMindBollocks2014,
  title = {Never Mind the Bollocks, i Wanna Be {{anarCHI}}: A Manifesto for Punk {{HCI}}},
  shorttitle = {Never Mind the Bollocks, i Wanna Be {{anarCHI}}},
  booktitle = {{{CHI}} '14 {{Extended Abstracts}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Linehan, Conor and Kirman, Ben},
  year = {2014},
  month = apr,
  pages = {741--748},
  publisher = {{ACM}},
  address = {{Toronto Ontario Canada}},
  doi = {10.1145/2559206.2578880},
  urldate = {2022-06-01},
  isbn = {978-1-4503-2474-8},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Linehan_Kirman_2014_Never mind the bollocks, i wanna be anarCHI.pdf}
}

@misc{liuAskingKnowledgeTraining2022,
  title = {Asking for {{Knowledge}}: {{Training RL Agents}} to {{Query External Knowledge Using Language}}},
  shorttitle = {Asking for {{Knowledge}}},
  author = {Liu, Iou-Jen and Yuan, Xingdi and C{\^o}t{\'e}, Marc-Alexandre and Oudeyer, Pierre-Yves and Schwing, Alexander G.},
  year = {2022},
  month = may,
  eprint = {2205.06111},
  primaryclass = {cs},
  urldate = {2022-05-25},
  abstract = {To solve difficult tasks, humans ask questions to acquire knowledge from external sources. In contrast, classical reinforcement learning agents lack such an ability and often resort to exploratory behavior. This is exacerbated as few present-day environments support querying for knowledge. In order to study how agents can be taught to query external knowledge via language, we first introduce two new environments: the grid-world-based Q-BabyAI and the text-based Q-TextWorld. In addition to physical interactions, an agent can query an external knowledge source specialized for these environments to gather information. Second, we propose the "Asking for Knowledge" (AFK) agent, which learns to generate language commands to query for meaningful knowledge that helps solve the tasks. AFK leverages a non-parametric memory, a pointer mechanism and an episodic exploration bonus to tackle (1) a large query language space, (2) irrelevant information, (3) delayed reward for making meaningful queries. Extensive experiments demonstrate that the AFK agent outperforms recent baselines on the challenging Q-BabyAI and Q-TextWorld environments.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Liu et al_2022_Asking for Knowledge.pdf}
}

@inproceedings{liuExaminingResponsibilityDeliberation2022,
  title = {Examining {{Responsibility}} and {{Deliberation}} in {{AI Impact Statements}} and {{Ethics Reviews}}},
  booktitle = {Proceedings of the 2022 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Liu, David and Nanayakkara, Priyanka and Sakha, Sarah Ariyan and Abuhamad, Grace and Blodgett, Su Lin and Diakopoulos, Nicholas and Hullman, Jessica R. and {Eliassi-Rad}, Tina},
  year = {2022},
  month = jul,
  pages = {424--435},
  publisher = {{ACM}},
  address = {{Oxford United Kingdom}},
  doi = {10.1145/3514094.3534155},
  urldate = {2022-08-08},
  abstract = {The artificial intelligence research community is continuing to grapple with the ethics of its work by encouraging researchers to discuss potential positive and negative consequences. Neural Information Processing Systems (NeurIPS), a top-tier conference for machine learning and artificial intelligence research, first required a statement of broader impact in 2020. In 2021, NeurIPS updated their call for papers such that 1) the impact statement focused on negative societal impacts and was not required but encouraged, 2) a paper checklist and ethics guidelines were provided to authors, and 3) papers underwent ethics reviews and could be rejected on ethical grounds. In light of these changes, we contribute a qualitative analysis of 231 impact statements and all publicly-available ethics reviews. We describe themes arising around the ways in which authors express agency (or lack thereof) in identifying or mitigating negative consequences and assign responsibility for mitigating negative societal impacts. We also characterize ethics reviews in terms of the types of issues raised by ethics reviewers (falling into categories of policy-oriented and non-policy-oriented), recommendations ethics reviewers make to authors (e.g., in terms of adding or removing content), and interaction between authors, ethics reviewers, and original reviewers (e.g., consistency between issues flagged by original reviewers and those discussed by ethics reviewers). Finally, based on our analysis we make recommendations for how authors can be further supported in engaging with the ethical implications of their work.},
  isbn = {978-1-4503-9247-1},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Liu et al_2022_Examining Responsibility and Deliberation in AI Impact Statements and Ethics.pdf}
}

@misc{LongTatSuLong,
  title = {ç«œ {{TatSu}} {\textemdash} ç«œ {{TatSu}} 5.7.0 Documentation},
  urldate = {2022-05-20},
  howpublished = {https://tatsu.readthedocs.io/en/stable/},
  file = {/home/morgan/Zotero/storage/NEKUM7YF/stable.html}
}

@article{markovImpossibleAlgorithms1952,
  title = {{\cyrchar\CYRO} {\cyrchar\CYRN}{\cyrchar\cyre}{\cyrchar\cyrr}{\cyrchar\cyra}{\cyrchar\cyrz}{\cyrchar\cyrr}{\cyrchar\cyre}{\cyrchar\cyrsh}{\cyrchar\cyri}{\cyrchar\cyrm}{\cyrchar\cyrery}{\cyrchar\cyrh} {\cyrchar\CYRA}{\cyrchar\cyrl}{\cyrchar\cyrg}{\cyrchar\cyro}{\cyrchar\cyrr}{\cyrchar\cyri}{\cyrchar\cyrf}{\cyrchar\cyrm}{\cyrchar\cyri}{\cyrchar\cyrch}{\cyrchar\cyre}{\cyrchar\cyrs}{\cyrchar\cyrk}{\cyrchar\cyri}{\cyrchar\cyrh} {\cyrchar\CYRP}{\cyrchar\cyrr}{\cyrchar\cyro}{\cyrchar\cyrb}{\cyrchar\cyrl}{\cyrchar\cyre}{\cyrchar\cyrm}{\cyrchar\cyra}{\cyrchar\cyrh}},
  author = {{\cyrchar\CYRM}{\cyrchar\cyra}{\cyrchar\cyrr}{\cyrchar\cyrk}{\cyrchar\cyro}{\cyrchar\cyrv}, {\cyrchar\CYRA}{\cyrchar\cyrn}{\cyrchar\cyrd}{\cyrchar\cyrr}{\cyrchar\cyre}{\cyrchar\cyrishrt} {\cyrchar\CYRA}{\cyrchar\cyrn}{\cyrchar\cyrd}{\cyrchar\cyrr}{\cyrchar\cyre}{\cyrchar\cyre}{\cyrchar\cyrv}{\cyrchar\cyri}{\cyrchar\cyrch}},
  year = {1952},
  journal = {{\cyrchar\CYRM}{\cyrchar\cyra}{\cyrchar\cyrt}{\cyrchar\cyre}{\cyrchar\cyrm}{\cyrchar\cyra}{\cyrchar\cyrt}{\cyrchar\cyri}{\cyrchar\cyrch}{\cyrchar\cyre}{\cyrchar\cyrs}{\cyrchar\cyrk}{\cyrchar\cyri}{\cyrchar\cyrishrt} {\cyrchar\cyrs}{\cyrchar\cyrb}{\cyrchar\cyro}{\cyrchar\cyrr}{\cyrchar\cyrn}{\cyrchar\cyri}{\cyrchar\cyrk}},
  volume = {31},
  number = {1},
  pages = {34--42},
  publisher = {{{\cyrchar\CYRR}{\cyrchar\cyro}{\cyrchar\cyrs}{\cyrchar\cyrs}{\cyrchar\cyri}{\cyrchar\cyrishrt}{\cyrchar\cyrs}{\cyrchar\cyrk}{\cyrchar\cyra}{\cyrchar\cyrya} {\cyrchar\cyra}{\cyrchar\cyrk}{\cyrchar\cyra}{\cyrchar\cyrd}{\cyrchar\cyre}{\cyrchar\cyrm}{\cyrchar\cyri}{\cyrchar\cyrya} {\cyrchar\cyrn}{\cyrchar\cyra}{\cyrchar\cyru}{\cyrchar\cyrk}, {\cyrchar\CYRM}{\cyrchar\cyra}{\cyrchar\cyrt}{\cyrchar\cyre}{\cyrchar\cyrm}{\cyrchar\cyra}{\cyrchar\cyrt}{\cyrchar\cyri}{\cyrchar\cyrch}{\cyrchar\cyre}{\cyrchar\cyrs}{\cyrchar\cyrk}{\cyrchar\cyri}{\cyrchar\cyrishrt} {\cyrchar\cyri}{\cyrchar\cyrn}{\cyrchar\cyrs}{\cyrchar\cyrt}{\cyrchar\cyri}{\cyrchar\cyrt}{\cyrchar\cyru}{\cyrchar\cyrt} {\cyrchar\cyri}{\cyrchar\cyrm}. {\cyrchar\CYRV}{\cyrchar\CYRA} {\cyrchar\CYRS}{\cyrchar\cyrt}{\cyrchar\cyre}{\cyrchar\cyrk}{\cyrchar\cyrl}{\cyrchar\cyro}{\cyrchar\cyrv}{\cyrchar\cyra} {\cyrchar\CYRR}{\cyrchar\cyro}{\cyrchar\cyrs}{\cyrchar\cyrs}{\cyrchar\cyri}{\cyrchar\cyrishrt}{\cyrchar\cyrs}{\cyrchar\cyrk}{\cyrchar\cyro}{\cyrchar\cyrishrt} {\ldots}}}
}

@incollection{markovIntroduction1984,
  title = {{\cyrchar\CYRP}{\cyrchar\cyrr}{\cyrchar\cyre}{\cyrchar\cyrd}{\cyrchar\cyri}{\cyrchar\cyrs}{\cyrchar\cyrl}{\cyrchar\cyro}{\cyrchar\cyrv}{\cyrchar\cyri}{\cyrchar\cyre}},
  booktitle = {{\cyrchar\CYRT}{\cyrchar\cyre}{\cyrchar\cyro}{\cyrchar\cyrr}{\cyrchar\cyri}{\cyrchar\cyrya} {\cyrchar\CYRA}{\cyrchar\cyrl}{\cyrchar\cyrg}{\cyrchar\cyro}{\cyrchar\cyrr}{\cyrchar\cyri}{\cyrchar\cyrf}{\cyrchar\cyrm}{\cyrchar\cyro}{\cyrchar\cyrv}},
  author = {{\cyrchar\CYRM}{\cyrchar\cyra}{\cyrchar\cyrr}{\cyrchar\cyrk}{\cyrchar\cyro}{\cyrchar\cyrv}, {\cyrchar\CYRA}{\cyrchar\cyrn}{\cyrchar\cyrd}{\cyrchar\cyrr}{\cyrchar\cyre}{\cyrchar\cyrishrt} {\cyrchar\CYRA}{\cyrchar\cyrn}{\cyrchar\cyrd}{\cyrchar\cyrr}{\cyrchar\cyre}{\cyrchar\cyre}{\cyrchar\cyrv}{\cyrchar\cyri}{\cyrchar\cyrch} and {\cyrchar\CYRN}{\cyrchar\cyra}{\cyrchar\cyrg}{\cyrchar\cyro}{\cyrchar\cyrr}{\cyrchar\cyrn}{\cyrchar\cyrery}{\cyrchar\cyrishrt}, {\cyrchar\CYRN}{\cyrchar\cyri}{\cyrchar\cyrk}{\cyrchar\cyro}{\cyrchar\cyrl}{\cyrchar\cyra}{\cyrchar\cyrishrt} {\cyrchar\CYRM}{\cyrchar\cyra}{\cyrchar\cyrk}{\cyrchar\cyra}{\cyrchar\cyrr}{\cyrchar\cyro}{\cyrchar\cyrv}{\cyrchar\cyri}{\cyrchar\cyrch}},
  year = {1984},
  publisher = {{{\cyrchar\CYRN}{\cyrchar\cyra}{\cyrchar\cyru}{\cyrchar\cyrk}{\cyrchar\cyra}}},
  address = {{{\cyrchar\CYRM}{\cyrchar\cyro}{\cyrchar\cyrs}{\cyrchar\cyrk}{\cyrchar\cyrv}{\cyrchar\cyra}}}
}

@article{markovTheoryAlgorithms1951,
  title = {{\cyrchar\CYRT}{\cyrchar\cyre}{\cyrchar\cyro}{\cyrchar\cyrr}{\cyrchar\cyri}{\cyrchar\cyrya} {\cyrchar\CYRA}{\cyrchar\cyrl}{\cyrchar\cyrg}{\cyrchar\cyro}{\cyrchar\cyrr}{\cyrchar\cyri}{\cyrchar\cyrf}{\cyrchar\cyrm}{\cyrchar\cyro}{\cyrchar\cyrv}},
  author = {{\cyrchar\CYRM}{\cyrchar\cyra}{\cyrchar\cyrr}{\cyrchar\cyrk}{\cyrchar\cyro}{\cyrchar\cyrv}, {\cyrchar\CYRA}{\cyrchar\cyrn}{\cyrchar\cyrd}{\cyrchar\cyrr}{\cyrchar\cyre}{\cyrchar\cyrishrt} {\cyrchar\CYRA}{\cyrchar\cyrn}{\cyrchar\cyrd}{\cyrchar\cyrr}{\cyrchar\cyre}{\cyrchar\cyre}{\cyrchar\cyrv}{\cyrchar\cyri}{\cyrchar\cyrch}},
  year = {1951},
  journal = {{\cyrchar\CYRT}{\cyrchar\cyrr}{\cyrchar\cyru}{\cyrchar\cyrd}{\cyrchar\cyrery} {\cyrchar\CYRM}{\cyrchar\cyra}{\cyrchar\cyrt}{\cyrchar\cyre}{\cyrchar\cyrm}{\cyrchar\cyra}{\cyrchar\cyrt}{\cyrchar\cyri}{\cyrchar\cyrch}{\cyrchar\cyre}{\cyrchar\cyrs}{\cyrchar\cyrk}{\cyrchar\cyro}{\cyrchar\cyrg}{\cyrchar\cyro} {\cyrchar\cyri}{\cyrchar\cyrn}{\cyrchar\cyrs}{\cyrchar\cyrt}{\cyrchar\cyri}{\cyrchar\cyrt}{\cyrchar\cyru}{\cyrchar\cyrt}{\cyrchar\cyra} {\cyrchar\cyri}{\cyrchar\cyrm}{\cyrchar\cyre}{\cyrchar\cyrn}{\cyrchar\cyri} {\cyrchar\CYRV}{\cyrchar\CYRA} {\cyrchar\CYRS}{\cyrchar\cyrt}{\cyrchar\cyre}{\cyrchar\cyrk}{\cyrchar\cyrl}{\cyrchar\cyro}{\cyrchar\cyrv}{\cyrchar\cyra}},
  volume = {38},
  number = {0},
  pages = {176--189},
  publisher = {{{\cyrchar\CYRR}{\cyrchar\cyro}{\cyrchar\cyrs}{\cyrchar\cyrs}{\cyrchar\cyri}{\cyrchar\cyrishrt}{\cyrchar\cyrs}{\cyrchar\cyrk}{\cyrchar\cyra}{\cyrchar\cyrya} {\cyrchar\cyra}{\cyrchar\cyrk}{\cyrchar\cyra}{\cyrchar\cyrd}{\cyrchar\cyre}{\cyrchar\cyrm}{\cyrchar\cyri}{\cyrchar\cyrya} {\cyrchar\cyrn}{\cyrchar\cyra}{\cyrchar\cyru}{\cyrchar\cyrk}, {\cyrchar\CYRM}{\cyrchar\cyra}{\cyrchar\cyrt}{\cyrchar\cyre}{\cyrchar\cyrm}{\cyrchar\cyra}{\cyrchar\cyrt}{\cyrchar\cyri}{\cyrchar\cyrch}{\cyrchar\cyre}{\cyrchar\cyrs}{\cyrchar\cyrk}{\cyrchar\cyri}{\cyrchar\cyrishrt} {\cyrchar\cyri}{\cyrchar\cyrn}{\cyrchar\cyrs}{\cyrchar\cyrt}{\cyrchar\cyri}{\cyrchar\cyrt}{\cyrchar\cyru}{\cyrchar\cyrt} {\cyrchar\cyri}{\cyrchar\cyrm}. {\cyrchar\CYRV}{\cyrchar\CYRA} {\cyrchar\CYRS}{\cyrchar\cyrt}{\cyrchar\cyre}{\cyrchar\cyrk}{\cyrchar\cyrl}{\cyrchar\cyro}{\cyrchar\cyrv}{\cyrchar\cyra} {\cyrchar\CYRR}{\cyrchar\cyro}{\cyrchar\cyrs}{\cyrchar\cyrs}{\cyrchar\cyri}{\cyrchar\cyrishrt}{\cyrchar\cyrs}{\cyrchar\cyrk}{\cyrchar\cyro}{\cyrchar\cyrishrt} {\ldots}}}
}

@article{markovTheoryAlgorithms1954,
  title = {The Theory of Algorithms},
  author = {Markov, Andrei Andreevich},
  year = {1954},
  journal = {Trudy Matematicheskogo Instituta Imeni VA Steklova},
  volume = {42},
  pages = {3--375},
  publisher = {{Russian Academy of Sciences, Steklov Mathematical Institute of Russian {\ldots}}}
}

@misc{mathesonAwakening1998,
  title = {The {{Awakening}}},
  author = {Matheson, Dennis},
  year = {1998}
}

@incollection{mccarthyArtificialIntelligenceLogic1989,
  title = {Artificial {{Intelligence}}, {{Logic}} and {{Formalizing Common Sense}}},
  booktitle = {Philosophical {{Logic}} and {{Artificial Intelligence}}},
  author = {McCarthy, John},
  editor = {Thomason, Richmond H.},
  year = {1989},
  pages = {161--190},
  publisher = {{Springer Netherlands}},
  address = {{Dordrecht}},
  doi = {10.1007/978-94-009-2448-2_6},
  urldate = {2022-05-25},
  isbn = {978-94-010-7604-3 978-94-009-2448-2},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/McCarthy_1989_Artificial Intelligence, Logic and Formalizing Common Sense.pdf}
}

@article{mckay_practicalGraph_1981,
  title = {Practical {{Graph Isomorphism}}},
  author = {McKay, Brendan},
  year = {1981},
  month = jul,
  langid = {english},
  file = {/home/morgan/Zotero/storage/ZMCMES25/McKay - Practical Graph Isomorphism.pdf}
}

@inproceedings{mendelsHybridAcousticLexicalDeep2017,
  title = {Hybrid {{Acoustic-Lexical Deep Learning Approach}} for {{Deception Detection}}},
  booktitle = {Interspeech 2017},
  author = {Mendels, Gideon and Levitan, Sarah Ita and Lee, Kai-Zhan and Hirschberg, Julia},
  year = {2017},
  month = aug,
  pages = {1472--1476},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2017-1723},
  urldate = {2022-06-12},
  abstract = {Automatic deception detection is an important problem with far-reaching implications for many disciplines. We present a series of experiments aimed at automatically detecting deception from speech. We use the Columbia X-Cultural Deception (CXD) Corpus, a large-scale corpus of within-subject deceptive and non-deceptive speech, for training and evaluating our models. We compare the use of spectral, acoustic-prosodic, and lexical feature sets, using different machine learning models. Finally, we design a single hybrid deep model with both acoustic and lexical features trained jointly that achieves state-of-the-art results on the CXD corpus.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Mendels et al_2017_Hybrid Acoustic-Lexical Deep Learning Approach for Deception Detection.pdf}
}

@misc{meretzkyPlanetfall1983,
  title = {Planetfall},
  author = {Meretzky, Steve},
  year = {1983}
}

@misc{meretzkySorcerer1984,
  title = {Sorcerer},
  author = {Meretzky, Steve},
  year = {1984}
}

@article{miceliSubjectivityImpositionPower2020,
  title = {Between {{Subjectivity}} and {{Imposition}}: {{Power Dynamics}} in {{Data Annotation}} for {{Computer Vision}}},
  shorttitle = {Between {{Subjectivity}} and {{Imposition}}},
  author = {Miceli, Milagros and Schuessler, Martin and Yang, Tianling},
  year = {2020},
  month = oct,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {4},
  number = {CSCW2},
  pages = {1--25},
  issn = {2573-0142},
  doi = {10.1145/3415186},
  urldate = {2022-06-12},
  abstract = {MILAGROS MICELI, Technische Universit{\"a}t Berlin, Weizenbaum Institut, Germany MARTIN SCHUESSLER, Technische Universit{\"a}t Berlin, Weizenbaum Institut, Germany TIANLING YANG, Technische Universit{\"a}t Berlin, Weizenbaum Institut, Germany The interpretation of data is fundamental to machine learning. This paper investigates practices of image data annotation as performed in industrial contexts. We define data annotation as a sense-making practice, where annotators assign meaning to data through the use of labels. Previous human-centered investigations have largely focused on annotators' subjectivity as a major cause of biased labels. We propose a wider view on this issue: guided by constructivist grounded theory, we conducted several weeks of fieldwork at two annotation companies. We analyzed which structures, power relations, and naturalized impositions shape the interpretation of data. Our results show that the work of annotators is profoundly informed by the interests, values, and priorities of other actors above their station. Arbitrary classifications are vertically imposed on annotators, and through them, on data. This imposition is largely naturalized. Assigning meaning to data is often presented as a technical matter. This paper shows it is, in fact, an exercise of power with multiple implications for individuals and society. CCS Concepts: {\textbullet} Human-centered computing {\textrightarrow} Empirical studies in collaborative and social computing; {\textbullet} Social and professional topics {\textrightarrow} Employment issues; {\textbullet} Computing methodologies {\textrightarrow} Supervised learning by classification.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Miceli et al_2020_Between Subjectivity and Imposition.pdf}
}

@misc{mierzejewskaNightComputerCenter1996,
  title = {Night at the {{Computer Center}}},
  author = {{mierzejewska}, bonni},
  year = {1996}
}

@misc{mikolovEfficientEstimationWord2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  year = {2013},
  month = sep,
  number = {arXiv:1301.3781},
  eprint = {1301.3781},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-07-08},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Mikolov et al_2013_Efficient Estimation of Word Representations in Vector Space.pdf}
}

@article{mitchellAlgorithmicFairnessChoices2021,
  title = {Algorithmic {{Fairness}}: {{Choices}}, {{Assumptions}}, and {{Definitions}}},
  shorttitle = {Algorithmic {{Fairness}}},
  author = {Mitchell, Shira and Potash, Eric and Barocas, Solon and D'Amour, Alexander and Lum, Kristian},
  year = {2021},
  month = mar,
  journal = {Annual Review of Statistics and Its Application},
  volume = {8},
  number = {1},
  pages = {141--163},
  issn = {2326-8298, 2326-831X},
  doi = {10.1146/annurev-statistics-042720-125902},
  urldate = {2022-05-26},
  abstract = {A recent wave of research has attempted to define fairness quantitatively. In particular, this work has explored what fairness might mean in the context of decisions based on the predictions of statistical and machine learning models. The rapid growth of this new field has led to wildly inconsistent motivations, terminology, and notation, presenting a serious challenge for cataloging and comparing definitions. This article attempts to bring much-needed order. First, we explicate the various choices and assumptions made{\textemdash}often implicitly{\textemdash}to justify the use of prediction-based decision-making. Next, we show how such choices and assumptions can raise fairness concerns and we present a notationally consistent catalog of fairness definitions from the literature. In doing so, we offer a concise reference for thinking through the choices, assumptions, and fairness considerations of prediction-based decision-making.},
  langid = {english},
  keywords = {bias,case studies,ethics,fairness,frameworks,mathematical models,review},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Mitchell et al_2021_Algorithmic Fairness.pdf}
}

@misc{mitchellSherlock1985,
  title = {Sherlock},
  author = {Mitchell, Philip},
  year = {1985}
}

@article{mnihHumanlevelControlDeep2015,
  title = {Human-Level Control through Deep Reinforcement Learning},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  year = {2015},
  month = feb,
  journal = {Nature},
  volume = {518},
  number = {7540},
  pages = {529--533},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature14236},
  urldate = {2022-07-06},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Mnih et al_2015_Human-level control through deep reinforcement learning.pdf}
}

@book{montfortTwistyLittlePassages2005,
  title = {Twisty {{Little Passages}}: {{An Approach}} to {{Interactive Fiction}}},
  shorttitle = {Twisty {{Little Passages}}},
  author = {Montfort, Nick},
  year = {2005},
  month = feb,
  publisher = {{The MIT Press}},
  langid = {english}
}

@book{moore1982role,
  title = {The Role of Logic in Knowledge Representation and Commonsense Reasoning},
  author = {Moore, Robert C},
  year = {1982},
  publisher = {{SRI International. Artificial Intelligence Center}},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Moore_1982_The role of logic in knowledge representation and commonsense reasoning.pdf}
}

@misc{moriartyTrinity1986,
  title = {Trinity},
  author = {Moriarty, Brian},
  year = {1986}
}

@misc{moriartyWishbringer1985,
  title = {Wishbringer},
  author = {Moriarty, Brian},
  year = {1985}
}

@techreport{mta_2022NYCT_2022,
  title = {2022 {{NYCT Bus Ridership Data}}},
  author = {{MTA}},
  year = {2022},
  institution = {{Metropolitan Transportation Authority}},
  urldate = {2023-12-23},
  langid = {english},
  file = {/home/morgan/Zotero/storage/X6XD3ZT8/subway-bus-ridership-2022.html}
}

@misc{muLearningTwoStepHybrid2022,
  title = {Learning {{Two-Step Hybrid Policy}} for {{Graph-Based Interpretable Reinforcement Learning}}},
  author = {Mu, Tongzhou and Lin, Kaixiang and Niu, Feiyang and Thattai, Govind},
  year = {2022},
  month = jan,
  eprint = {2201.08520},
  primaryclass = {cs},
  urldate = {2022-05-25},
  abstract = {We present a two-step hybrid reinforcement learning (RL) policy that is designed to generate interpretable and robust hierarchical policies on the RL problem with graph-based input. Unlike prior deep reinforcement learning policies parameterized by an end-to-end black-box graph neural network, our approach disentangles the decision-making process into two steps. The first step is a simplified classification problem that maps the graph input to an action group where all actions share a similar semantic meaning. The second step implements a sophisticated rule-miner that conducts explicit one-hop reasoning over the graph and identifies decisive edges in the graph input without the necessity of heavy domain knowledge. This two-step hybrid policy presents human-friendly interpretations and achieves better performance in terms of generalization and robustness. Extensive experimental studies on four levels of complex text-based games have demonstrated the superiority of the proposed method compared to the state-of-the-art.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Mu et al_2022_Learning Two-Step Hybrid Policy for Graph-Based Interpretable Reinforcement.pdf}
}

@misc{murchisonAcornCourt1997,
  title = {The {{Acorn Court}}},
  author = {Murchison, Todd S.},
  year = {1997}
}

@misc{murugesanTextbasedRLAgents2020,
  title = {Text-Based {{RL Agents}} with {{Commonsense Knowledge}}: {{New Challenges}}, {{Environments}} and {{Baselines}}},
  shorttitle = {Text-Based {{RL Agents}} with {{Commonsense Knowledge}}},
  author = {Murugesan, Keerthiram and Atzeni, Mattia and Kapanipathi, Pavan and Shukla, Pushkar and Kumaravel, Sadhana and Tesauro, Gerald and Talamadupula, Kartik and Sachan, Mrinmaya and Campbell, Murray},
  year = {2020},
  month = oct,
  number = {arXiv:2010.03790},
  eprint = {2010.03790},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-05-25},
  abstract = {Text-based games have emerged as an important test-bed for Reinforcement Learning (RL) research, requiring RL agents to combine grounded language understanding with sequential decision making. In this paper, we examine the problem of infusing RL agents with commonsense knowledge. Such knowledge would allow agents to efficiently act in the world by pruning out implausible actions, and to perform look-ahead planning to determine how current actions might affect future world states. We design a new text-based gaming environment called TextWorld Commonsense (TWC) for training and evaluating RL agents with a specific kind of commonsense knowledge about objects, their attributes, and affordances. We also introduce several baseline RL agents which track the sequential context and dynamically retrieve the relevant commonsense knowledge from ConceptNet. We show that agents which incorporate commonsense knowledge in TWC perform better, while acting more efficiently. We conduct user-studies to estimate human performance on TWC and show that there is ample room for future improvement.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Murugesan et al_2020_Text-based RL Agents with Commonsense Knowledge.pdf}
}

@misc{narasimhanLanguageUnderstandingTextbased2015,
  title = {Language {{Understanding}} for {{Text-based Games Using Deep Reinforcement Learning}}},
  author = {Narasimhan, Karthik and Kulkarni, Tejas and Barzilay, Regina},
  year = {2015},
  month = sep,
  number = {arXiv:1506.08941},
  eprint = {1506.08941},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-05-25},
  abstract = {In this paper, we consider the task of learning control policies for text-based games. In these games, all interactions in the virtual world are through text and the underlying state is not observed. The resulting language barrier makes such environments challenging for automatic game players. We employ a deep reinforcement learning framework to jointly learn state representations and action policies using game rewards as feedback. This framework enables us to map text descriptions into vector representations that capture the semantics of the game states. We evaluate our approach on two game worlds, comparing against baselines using bag-of-words and bag-of-bigrams for state representations. Our algorithm outperforms the baselines on both worlds demonstrating the importance of learning expressive representations.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Narasimhan et al_2015_Language Understanding for Text-based Games Using Deep Reinforcement Learning.pdf}
}

@misc{NavigatorScenes,
  title = {Navigator {$>$} {{Scenes}}},
  howpublished = {https://manuals.finaldraft.com/articles/\#!final-draft-12-user-guide-mac/navigator-scenes-mac}
}

@misc{nelsonBalances1994,
  title = {Balances},
  author = {Nelson, Graham},
  year = {1994}
}

@misc{nelsonCurses1993,
  title = {Curses},
  author = {Nelson, Graham},
  year = {1993}
}

@article{nilssonLogicArtificialIntelligence1991,
  title = {Logic and Artificial Intelligence},
  author = {Nilsson, Nils J.},
  year = {1991},
  month = jan,
  journal = {Artificial Intelligence},
  volume = {47},
  number = {1},
  pages = {31--56},
  issn = {0004-3702},
  doi = {10.1016/0004-3702(91)90049-P},
  urldate = {2022-05-25},
  abstract = {The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Nilsson_1991_Logic and artificial intelligence.pdf}
}

@inproceedings{nivenProbingNeuralNetwork2019,
  title = {Probing {{Neural Network Comprehension}} of {{Natural Language Arguments}}},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Niven, Timothy and Kao, Hung-Yu},
  year = {2019},
  pages = {4658--4664},
  publisher = {{Association for Computational Linguistics}},
  address = {{Florence, Italy}},
  doi = {10.18653/v1/P19-1459},
  urldate = {2022-06-12},
  abstract = {We are surprised to find that BERT's peak performance of 77\% on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Niven_Kao_2019_Probing Neural Network Comprehension of Natural Language Arguments.pdf}
}

@misc{NorthNorthwest1959,
  title = {North by {{Northwest}} (1959) - {{IMDb}}},
  abstract = {North by Northwest (1959) Goofs on IMDb: Mistakes, Errors in geography, Spoilers and more...},
  howpublished = {http://www.imdb.com/title/tt0053125/goofs},
  file = {/home/morgan/Zotero/storage/2635IS9T/goofs.html}
}

@misc{oneillBallyhoo1985,
  title = {Ballyhoo},
  author = {O'Neill, Jeff},
  year = {1985}
}

@inproceedings{papakyriakopoulosBiasWordEmbeddings2020,
  title = {Bias in Word Embeddings},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Papakyriakopoulos, Orestis and Hegelich, Simon and Serrano, Juan Carlos Medina and Marco, Fabienne},
  year = {2020},
  month = jan,
  pages = {446--457},
  publisher = {{ACM}},
  address = {{Barcelona Spain}},
  doi = {10.1145/3351095.3372843},
  urldate = {2022-10-25},
  abstract = {Word embeddings are a widely used set of natural language processing techniques that map words to vectors of real numbers. These vectors are used to improve the quality of generative and predictive models. Recent studies demonstrate that word embeddings contain and amplify biases present in data, such as stereotypes and prejudice. In this study, we provide a complete overview of bias in word embeddings. We develop a new technique for bias detection for gendered languages and use it to compare bias in embeddings trained on Wikipedia and on political social media data. We investigate bias diffusion and prove that existing biases are transferred to further machine learning models. We test two techniques for bias mitigation and show that the generally proposed methodology for debiasing models at the embeddings level is insufficient. Finally, we employ biased word embeddings and illustrate that they can be used for the detection of similar biases in new data. Given that word embeddings are widely used by commercial companies, we discuss the challenges and required actions towards fair algorithmic implementations and applications.},
  isbn = {978-1-4503-6936-7},
  langid = {english},
  file = {/home/morgan/Dropbox/eBooks/Articles/EmbeddingsPaper/Papakyriakopoulos et al. - 2020 - Bias in word embeddings.pdf}
}

@inproceedings{parkReducingGenderBias2018,
  title = {Reducing {{Gender Bias}} in {{Abusive Language Detection}}},
  booktitle = {Proceedings of the 2018 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Park, Ji Ho and Shin, Jamin and Fung, Pascale},
  year = {2018},
  pages = {2799--2804},
  publisher = {{Association for Computational Linguistics}},
  address = {{Brussels, Belgium}},
  doi = {10.18653/v1/D18-1302},
  urldate = {2022-06-12},
  abstract = {Abusive language detection models tend to have a problem of being biased toward identity words of a certain group of people because of imbalanced training datasets. For example, ``You are a good woman'' was considered ``sexist'' when trained on an existing dataset. Such model bias is an obstacle for models to be robust enough for practical use. In this work, we measure gender biases on models trained with different abusive language datasets, while analyzing the effect of different pre-trained word embeddings and model architectures. We also experiment with three bias mitigation methods: (1) debiased word embeddings, (2) gender swap data augmentation, and (3) fine-tuning with a larger corpus. These methods can effectively reduce gender bias by 90-98\% and can be extended to correct model bias in other scenarios.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Park et al_2018_Reducing Gender Bias in Abusive Language Detection.pdf}
}

@misc{partingtonMonstersMurdac1982,
  title = {Monsters of {{Murdac}}},
  author = {Partington, Jonathan},
  year = {1982}
}

@inproceedings{pathakCuriositydrivenExplorationSelfsupervised2017,
  title = {Curiosity-Driven {{Exploration}} by {{Self-supervised Prediction}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Machine Learning}}},
  author = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A. and Darrell, Trevor},
  year = {2017},
  month = jul,
  pages = {2778--2787},
  publisher = {{PMLR}},
  urldate = {2022-05-25},
  abstract = {In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent's ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difficulties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efficiently; and 3) generalization to unseen scenarios (e.g. new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Pathak et al_2017_Curiosity-driven Exploration by Self-supervised Prediction.pdf}
}

@inproceedings{pathakCuriosityDrivenExplorationSelfSupervised2017,
  title = {Curiosity-{{Driven Exploration}} by {{Self-Supervised Prediction}}},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPRW}})},
  author = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A. and Darrell, Trevor},
  year = {2017},
  month = jul,
  pages = {488--489},
  publisher = {{IEEE}},
  address = {{Honolulu, HI, USA}},
  doi = {10.1109/CVPRW.2017.70},
  urldate = {2022-07-08},
  abstract = {In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent's ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difficulties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efficiently; and 3) generalization to unseen scenarios (e.g. new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch.},
  isbn = {978-1-5386-0733-6},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Pathak et al_2017_Curiosity-Driven Exploration by Self-Supervised Prediction2.pdf}
}

@article{paulladaDataItsDis2021,
  title = {Data and Its (Dis)Contents: {{A}} Survey of Dataset Development and Use in Machine Learning Research},
  shorttitle = {Data and Its (Dis)Contents},
  author = {Paullada, Amandalynne and Raji, Inioluwa Deborah and Bender, Emily M. and Denton, Emily and Hanna, Alex},
  year = {2021},
  month = nov,
  journal = {Patterns},
  volume = {2},
  number = {11},
  pages = {100336},
  issn = {26663899},
  doi = {10.1016/j.patter.2021.100336},
  urldate = {2022-05-26},
  abstract = {In this work, we survey a breadth of literature that has revealed the limitations of predominant practices for dataset collection and use in the field of machine learning. We cover studies that critically review the design and development of datasets with a focus on negative societal impacts and poor outcomes for system performance. We also cover approaches to filtering and augmenting data and modeling techniques aimed at mitigating the impact of bias in datasets. Finally, we discuss works that have studied data practices, cultures, and disciplinary norms and discuss implications for the legal, ethical, and functional challenges the field continues to face. Based on these findings, we advocate for the use of both qualitative and quantitative approaches to more carefully document and analyze datasets during the creation and usage phases.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Paullada et al_2021_Data and its (dis)contents.pdf}
}

@inproceedings{penningtonGloVeGlobalVectors2014,
  title = {{{GloVe}}: {{Global Vectors}} for {{Word Representation}}},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  year = {2014},
  month = oct,
  pages = {1532--1543},
  publisher = {{Association for Computational Linguistics}},
  address = {{Doha, Qatar}},
  doi = {10.3115/v1/D14-1162}
}

@article{petreskiWordEmbeddingsAre2022,
  title = {Word Embeddings Are Biased. {{But}} Whose Bias Are They Reflecting?},
  author = {Petreski, Davor and Hashim, Ibrahim C.},
  year = {2022},
  month = may,
  journal = {AI \& SOCIETY},
  issn = {0951-5666, 1435-5655},
  doi = {10.1007/s00146-022-01443-w},
  urldate = {2022-10-25},
  abstract = {From Curriculum Vitae parsing to web search and recommendation systems, Word2Vec and other word embedding techniques have an increasing presence in everyday interactions in human society. Biases, such as gender bias, have been thoroughly researched and evidenced to be present in word embeddings. Most of the research focuses on discovering and mitigating gender bias within the frames of the vector space itself. Nevertheless, whose bias is reflected in word embeddings has not yet been investigated. Besides discovering and mitigating gender bias, it is also important to examine whether a feminine or a masculine-centric view is represented in the biases of word embeddings. This way, we will not only gain more insight into the origins of the before mentioned biases, but also present a novel approach to investigating biases in Natural Language Processing systems. Based on previous research in the social sciences and gender studies, we hypothesize that masculine-centric, otherwise known as androcentric, biases are dominant in word embeddings. To test this hypothesis we used the largest English word association test data set publicly available. We compare the distance of the responses of male and female participants to cue words in a word embedding vector space. We found that the word embedding is biased towards a masculine-centric viewpoint, predominantly reflecting the worldviews of the male participants in the word association test data set. Therefore, by conducting this research, we aimed to unravel another layer of bias to be considered when examining fairness in algorithms.},
  langid = {english},
  file = {/home/morgan/Dropbox/eBooks/Articles/EmbeddingsPaper/Petreski and Hashim - 2022 - Word embeddings are biased. But whose bias are the.pdf}
}

@misc{phillipsAllQuietLibrary1995,
  title = {All {{Quiet}} on the {{Library Front}}},
  author = {Phillips, Michael S.},
  year = {1995}
}

@article{pistilliWhatLiesAGI2022,
  title = {What Lies behind {{AGI}}: Ethical Concerns Related to {{LLMs}}},
  author = {Pistilli, Giada},
  year = {2022},
  month = mar,
  pages = {8},
  abstract = {This paper opens the philosophical debate around the notion of Artificial General Intelligence (AGI) and its application in Large Language Models (LLMs). Through the lens of moral philosophy, the paper raises questions about these AI systems' capabilities and goals, the treatment of humans behind them, and the risk of perpetuating a monoculture through language.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Pistilli_2022_What lies behind AGI.pdf}
}

@misc{plotkinHunterDarkness1999,
  title = {Hunter, in {{Darkness}}},
  author = {Plotkin, Andrew},
  year = {1999}
}

@misc{plotkinInhumane1985,
  title = {Inhumane},
  author = {Plotkin, Andrew},
  year = {1985}
}

@misc{plotkinSpiderWeb1998,
  title = {Spider and {{Web}}},
  author = {Plotkin, Andrew},
  year = {1998}
}

@inproceedings{poliakHypothesisOnlyBaselines2018,
  title = {Hypothesis {{Only Baselines}} in {{Natural Language Inference}}},
  booktitle = {Proceedings of the {{Seventh Joint Conference}} on {{Lexical}} and           {{Computational Semantics}}},
  author = {Poliak, Adam and Naradowsky, Jason and Haldar, Aparajita and Rudinger, Rachel and Van Durme, Benjamin},
  year = {2018},
  pages = {180--191},
  publisher = {{Association for Computational Linguistics}},
  address = {{New Orleans, Louisiana}},
  doi = {10.18653/v1/S18-2023},
  urldate = {2022-06-12},
  abstract = {We propose a hypothesis only baseline for diagnosing Natural Language Inference (NLI). Especially when an NLI dataset assumes inference is occurring based purely on the relationship between a context and a hypothesis, it follows that assessing entailment relations while ignoring the provided context is a degenerate solution. Yet, through experiments on ten distinct NLI datasets, we find that this approach, which we refer to as a hypothesis-only model, is able to significantly outperform a majorityclass baseline across a number of NLI datasets. Our analysis suggests that statistical irregularities may allow a model to perform NLI in some datasets beyond what should be achievable without access to the context.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Poliak et al_2018_Hypothesis Only Baselines in Natural Language Inference.pdf}
}

@inproceedings{raghavanMitigatingBiasAlgorithmic2020,
  title = {Mitigating {{Bias}} in {{Algorithmic Hiring}}: {{Evaluating Claims}} and {{Practices}}},
  shorttitle = {Mitigating {{Bias}} in {{Algorithmic Hiring}}},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Raghavan, Manish and Barocas, Solon and Kleinberg, Jon and Levy, Karen},
  year = {2020},
  month = jan,
  eprint = {1906.09208},
  primaryclass = {cs},
  pages = {469--481},
  doi = {10.1145/3351095.3372828},
  urldate = {2022-05-26},
  abstract = {There has been rapidly growing interest in the use of algorithms in hiring, especially as a means to address or mitigate bias. Yet, to date, little is known about how these methods are used in practice. How are algorithmic assessments built, validated, and examined for bias? In this work, we document and analyze the claims and practices of companies offering algorithms for employment assessment. In particular, we identify vendors of algorithmic pre-employment assessments (i.e., algorithms to screen candidates), document what they have disclosed about their development and validation procedures, and evaluate their practices, focusing particularly on efforts to detect and mitigate bias. Our analysis considers both technical and legal perspectives. Technically, we consider the various choices vendors make regarding data collection and prediction targets, and explore the risks and trade-offs that these choices pose. We also discuss how algorithmic de-biasing techniques interface with, and create challenges for, antidiscrimination law.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Raghavan et al_2020_Mitigating Bias in Algorithmic Hiring.pdf}
}

@inproceedings{rajiActionableAuditingInvestigating2019,
  title = {Actionable {{Auditing}}: {{Investigating}} the {{Impact}} of {{Publicly Naming Biased Performance Results}} of {{Commercial AI Products}}},
  shorttitle = {Actionable {{Auditing}}},
  booktitle = {Proceedings of the 2019 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Raji, Inioluwa Deborah and Buolamwini, Joy},
  year = {2019},
  month = jan,
  pages = {429--435},
  publisher = {{ACM}},
  address = {{Honolulu HI USA}},
  doi = {10.1145/3306618.3314244},
  urldate = {2022-05-27},
  abstract = {Although algorithmic auditing has emerged as a key strategy to expose systematic biases embedded in software platforms, we struggle to understand the realworld impact of these audits, as scholarship on the impact of algorithmic audits on increasing algorithmic fairness and transparency in commercial systems is nascent. To analyze the impact of publicly naming and disclosing performance results of biased AI systems, we investigate the commercial impact of Gender Shades, the first algorithmic audit of gender and skin type performance disparities in commercial facial analysis models. This paper 1) outlines the audit design and structured disclosure procedure used in the Gender Shades study, 2) presents new performance metrics from targeted companies IBM, Microsoft and Megvii (Face++) on the Pilot Parliaments Benchmark (PPB) as of August 2018, 3) provides performance results on PPB by non-target companies Amazon and Kairos and, 4) explores differences in company responses as shared through corporate communications that contextualize differences in performance on PPB. Within 7 months of the original audit, we find that all three targets released new API versions. All targets reduced accuracy disparities between males and females and darker and lighter-skinned subgroups, with the most significant update occurring for the darker-skinned female subgroup, that underwent a 17.7\% - 30.4\% reduction in error between audit periods. Minimizing these disparities led to a 5.72\% to 8.3\% reduction in overall error on the Pilot Parliaments Benchmark (PPB) for target corporation APIs. The overall performance of non-targets Amazon and Kairos lags significantly behind that of the targets, with error rates of 8.66\% and 6.60\% overall, and error rates of 31.37\% and 22.50\% for the darker female subgroup, respectively.},
  isbn = {978-1-4503-6324-2},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Raji_Buolamwini_2019_Actionable Auditing.pdf}
}

@article{rajiAIEverythingWhole2021,
  title = {{{AI}} and the {{Everything}} in the {{Whole Wide World Benchmark}}},
  author = {Raji, Inioluwa Deborah and Bender, Emily M and Paullada, Amandalynne and Denton, Emily and Hanna, Alex},
  year = {2021},
  month = nov,
  pages = {17},
  abstract = {There is a tendency across different subfields in AI to valorize a small collection of influential benchmarks. These benchmarks operate as stand-ins for a range of anointed common problems that are frequently framed as foundational milestones on the path towards flexible and generalizable AI systems. State-of-the-art performance on these benchmarks is widely understood as indicative of progress towards these long-term goals. In this position paper, we explore the limits of such benchmarks in order to reveal the construct validity issues in their framing as the functionally ``general'' broad measures of progress they are set up to be.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Raji et al_2021_AI and the Everything in the Whole Wide World Benchmark.pdf}
}

@misc{reed2012HowlingDogs2021,
  type = {Substack Newsletter},
  title = {2012: {{Howling Dogs}}},
  shorttitle = {2012},
  author = {Reed, Aaron A.},
  year = {2021},
  month = nov,
  journal = {50 Years of Text Games},
  urldate = {2022-08-13},
  abstract = {A revolution of text games powered by blue links and radical prose: Twine and the rise of Porpentine.},
  file = {/home/morgan/Zotero/storage/HNEQ64AR/2012-howling-dogs.html}
}

@misc{reevesPartyFoul2010,
  title = {Party {{Foul}}},
  author = {Reeves, Brooks},
  year = {2010}
}

@misc{Refal5l,
  title = {{\cyrchar\CYRR}{\cyrchar\cyre}{\cyrchar\cyrf}{\cyrchar\cyra}{\cyrchar\cyrl}-5{$\lambda$}},
  journal = {{\cyrchar\CYRR}{\cyrchar\cyre}{\cyrchar\cyrf}{\cyrchar\cyra}{\cyrchar\cyrl}-5{$\lambda$}},
  urldate = {2022-04-27},
  abstract = {{\cyrchar\CYRK}{\cyrchar\cyro}{\cyrchar\cyrm}{\cyrchar\cyrp}{\cyrchar\cyri}{\cyrchar\cyrl}{\cyrchar\cyrya}{\cyrchar\cyrt}{\cyrchar\cyro}{\cyrchar\cyrr} {\cyrchar\CYRR}{\cyrchar\cyre}{\cyrchar\cyrf}{\cyrchar\cyra}{\cyrchar\cyrl}{\cyrchar\cyra}-5{$\lambda$}},
  howpublished = {http://bmstu-iu9.github.io/refal-5-lambda/},
  langid = {american},
  file = {/home/morgan/Zotero/storage/MB3N8ERB/refal-5-lambda.html}
}

@misc{ricksBYUAgent20162019,
  title = {{{BYU-Agent-2016}}},
  author = {Ricks, Daniel},
  year = {2019},
  month = aug,
  urldate = {2022-05-02},
  abstract = {IEEE CIG 2016 Winning agent}
}

@misc{robertsT3VirtualMachine,
  title = {T3 {{Virtual Machine Technical Documentation}}},
  author = {Roberts, Michael},
  urldate = {2022-07-05},
  howpublished = {https://www.tads.org/t3doc/doc/techman/t3spec.htm},
  file = {/home/morgan/Zotero/storage/MDAITQDH/t3spec.html}
}

@book{russell_artificialIntelligence_2020,
  title = {Artificial {{Intelligence}}: {{A Modern Approach}}},
  shorttitle = {Artificial {{Intelligence}}},
  author = {Russell, Stuart and Norvig, Peter},
  year = {2020},
  month = apr,
  edition = {4th edition},
  publisher = {{Pearson}},
  address = {{Hoboken}},
  isbn = {978-0-13-461099-3},
  langid = {english}
}

@inproceedings{ryuFireBurnsSword2022,
  title = {Fire {{Burns}}, {{Sword Cuts}}: {{Commonsense Inductive Bias}} for {{Exploration}} in {{Text-based Games}}},
  shorttitle = {Fire {{Burns}}, {{Sword Cuts}}},
  booktitle = {{{ACL}} 2022},
  author = {Ryu, Dongwon and Shareghi, Ehsan and Fang, Meng and Xu, Yunqiu and Pan, Shirui and Haf, Reza},
  year = {2022},
  month = may,
  pages = {515--522},
  publisher = {{Association for Computational Linguistics}},
  address = {{Dublin, Ireland}},
  urldate = {2022-05-25},
  abstract = {Text-based games (TGs) are exciting testbeds for developing deep reinforcement learning techniques due to their partially observed environments and large action spaces. In these games, the agent learns to explore the environment via natural language interactions with the game simulator. A fundamental challenge in TGs is the efficient exploration of the large action space when the agent has not yet acquired enough knowledge about the environment. We propose CommExpl, an exploration technique that injects external commonsense knowledge, via a pretrained language model (LM), into the agent during training when the agent is the most uncertain about its next action. Our method exhibits improvement on the collected game scores during the training in four out of nine games from Jericho. Additionally, the produced trajectory of actions exhibit lower perplexity, when tested with a pretrained LM, indicating better closeness to human language.},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Ryu et al_2022_Fire Burns, Sword Cuts.pdf}
}

@misc{sandhausevanNewYorkTimes2008,
  title = {The {{New York Times Annotated Corpus}}},
  author = {Sandhaus, Evan},
  year = {2008},
  month = oct,
  pages = {3250585 KB},
  publisher = {{Linguistic Data Consortium}},
  doi = {10.35111/77BA-9X74},
  urldate = {2021-10-18},
  abstract = {{$<$}h3{$>$}Introduction{$<$}/h3{$><$}br{$>$}  {$<$}p{$>$}The New York Times Annotated Corpus contains over 1.8 million articles written and published by the New York Times between January 1, 1987 and June 19, 2007 with article metadata provided by the New York Times Newsroom, the New York Times Indexing Service and the online production staff at nytimes.com. The corpus includes:{$<$}/p{$><$}br{$>$}  {$<$}ul{$><$}br{$>$}  {$<$}li{$>$}Over 1.8 million articles (excluding wire services articles that appeared during the covered period).{$<$}/li{$><$}br{$>$}  {$<$}li{$>$}Over 650,000 article summaries written by library scientists.{$<$}/li{$><$}br{$>$}  {$<$}li{$>$}Over 1,500,000 articles manually tagged by library scientists with tags drawn from a normalized indexing vocabulary of people, organizations, locations and topic descriptors.{$<$}/li{$><$}br{$>$}  {$<$}li{$>$}Over 275,000 algorithmically-tagged articles that have been hand verified by the online production staff at nytimes.com.{$<$}/li{$><$}br{$>$}  {$<$}li{$>$}Java tools for parsing corpus documents from .xml into a memory resident object.{$<$}/li{$><$}br{$>$}  {$<$}/ul{$><$}br{$>$}  {$<$}p{$>$}As part of the New York Times' indexing procedures, most articles are manually summarized and tagged by a staff of library scientists. This collection contains over 650,000 article-summary pairs which may prove to be useful in the development and evaluation of algorithms for automated document summarization. Also, over 1.5 million documents have at least one tag. Articles are tagged for persons, places, organizations, titles and topics using a controlled vocabulary that is applied consistently across articles. For instance if one article mentions "Bill Clinton" and another refers to "President William Jefferson Clinton", both articles will be tagged with "CLINTON, BILL".{$<$}/p{$><$}br{$>$}  {$<$}p{$>$}The New York Times has established a community website for researchers working on the data set at {$<$}a href="http://groups.google.com/group/nytnlp" rel="nofollow"{$>$}http://groups.google.com/group/nytnlp{$<$}/a{$>$} and encourages feedback and discussion about the corpus.{$<$}/p{$><$}br{$>$}  {$<$}h3{$>$}Data{$<$}/h3{$><$}br{$>$}  {$<$}p{$>$}The text in this corpus is formatted in {$<$}a href="http://www.nitf.org" rel="nofollow"{$>$}News Industry Text Format (NITF){$<$}/a{$>$} developed by the International Press Telecommunications Council, an independent association of news agencies and publishers. NITF is an XML specification that provides a standardized representation for the content and structure of discrete news articles. NITF encompasses structural markup such as bylines, headlines and paragraphs. The format also provides management attributes for categorizing articles into topics, summarization usage restrictions and revision histories. The goals of NITF are to answer the essential questions inherent in news articles: Who, What, When, Where and Why.{$<$}/p{$><$}br{$>$}  {$<$}ul{$><$}br{$>$}  {$<$}li{$><$}strong{$>$}Who: {$<$}/strong{$>$}Who owns the copyright, who has rights to republish the article and who the article is about.{$<$}/li{$><$}br{$>$}  {$<$}li{$><$}strong{$>$}What: {$<$}/strong{$>$}The subjects reported, the named entities inside the article and the events it describes.{$<$}/li{$><$}br{$>$}  {$<$}li{$><$}strong{$>$}When: {$<$}/strong{$>$}When the article was written, when it was issued and when it was revised.{$<$}/li{$><$}br{$>$}  {$<$}li{$><$}strong{$>$}Where: {$<$}/strong{$>$}Where the article was written, where the events took place and where it was delivered.{$<$}/li{$><$}br{$>$}  {$<$}li{$><$}strong{$>$}Why: {$<$}/strong{$>$}The metadata describing the newsworthiness of the article.{$<$}/li{$><$}br{$>$}  {$<$}/ul{$><$}br{$>$}  {$<$}h3{$>$}Samples{$<$}/h3{$><$}br{$>$}  {$<$}p{$>$}Please view the following {$<$}a href="desc/addenda/LDC2008T19\_large.jpg"{$>$}sample{$<$}/a{$>$}.{$<$}/p{$><$}br{$>$}  {$<$}h3{$>$}Updates{$<$}/h3{$><$}br{$>$}  {$<$}p{$>$}A {$<$}a href="../../../docs/LDC2008T19/new\_york\_times\_annotated\_corpus.pdf" rel="nofollow"{$>$}revised manual{$<$}/a{$>$} is now available.{$<$}/p{$><$}/br{$>$}  Portions {\textcopyright} 1987-2008 New York Times, {\textcopyright} 2008 Trustees of the University of Pennsylvania}
}

@article{schlegelLeaderboardsSurveyMethods2020,
  title = {Beyond {{Leaderboards}}: {{A}} Survey of Methods for Revealing Weaknesses in {{Natural Language Inference}} Data and Models},
  author = {Schlegel, Viktor and Nenadic, Goran and {Batista-Navarro}, Riza},
  year = {2020},
  month = may,
  pages = {23},
  abstract = {Recent years have seen a growing number of publications that analyse Natural Language Inference (NLI) datasets for superficial cues, whether they undermine the complexity of the tasks underlying those datasets and how they impact those models that are optimised and evaluated on this data. This structured survey provides an overview of the evolving research area by categorising reported weaknesses in models and datasets and the methods proposed to reveal and alleviate those weaknesses for the English language. We summarise and discuss the findings and conclude with a set of recommendations for possible future research directions. We hope it will be a useful resource for researchers who propose new datasets, to have a set of tools to assess the suitability and quality of their data to evaluate various phenomena of interest, as well as those who develop novel architectures, to further understand the implications of their improvements with respect to their model's acquired capabilities.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Schlegel et al_Beyond Leaderboards.pdf}
}

@misc{schroderEvaluatingMetricsBias2021,
  title = {Evaluating {{Metrics}} for {{Bias}} in {{Word Embeddings}}},
  author = {Schr{\"o}der, Sarah and Schulz, Alexander and Kenneweg, Philip and Feldhans, Robert and Hinder, Fabian and Hammer, Barbara},
  year = {2021},
  month = nov,
  number = {arXiv:2111.07864},
  eprint = {2111.07864},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-10-25},
  abstract = {Over the last years, word and sentence embeddings have established as text preprocessing for all kinds of NLP tasks and improved the performances significantly. Unfortunately, it has also been shown that these embeddings inherit various kinds of biases from the training data and thereby pass on biases present in society to NLP solutions.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/home/morgan/Dropbox/eBooks/Articles/EmbeddingsPaper/SchrÃ¶der et al. - 2021 - Evaluating Metrics for Bias in Word Embeddings.pdf}
}

@misc{ScriptESystems,
  title = {{{ScriptE Systems}}},
  journal = {ScriptE Systems},
  abstract = {Software that's built by people in the film and television industry. Just like you.},
  howpublished = {https://scriptesystems.weebly.com/},
  langid = {english},
  file = {/home/morgan/Zotero/storage/ZNJ5D8GQ/scriptesystems.weebly.com.html}
}

@inproceedings{senTurkersScholarsArafat2015,
  title = {Turkers, {{Scholars}}, "{{Arafat}}" and "{{Peace}}": {{Cultural Communities}} and {{Algorithmic Gold Standards}}},
  shorttitle = {Turkers, {{Scholars}}, "{{Arafat}}" and "{{Peace}}"},
  booktitle = {Proceedings of the 18th {{ACM Conference}} on {{Computer Supported Cooperative Work}} \& {{Social Computing}}},
  author = {Sen, Shilad and Giesel, Margaret E. and Gold, Rebecca and Hillmann, Benjamin and Lesicko, Matt and Naden, Samuel and Russell, Jesse and Wang, Zixiao (Ken) and Hecht, Brent},
  year = {2015},
  month = feb,
  pages = {826--838},
  publisher = {{ACM}},
  address = {{Vancouver BC Canada}},
  doi = {10.1145/2675133.2675285},
  urldate = {2022-06-12},
  abstract = {In just a few years, crowdsourcing markets like Mechanical Turk have become the dominant mechanism for for building ``gold standard'' datasets in areas of computer science ranging from natural language processing to audio transcription. The assumption behind this sea change {\textemdash} an assumption that is central to the approaches taken in hundreds of research projects {\textemdash} is that crowdsourced markets can accurately replicate the judgments of the general population for knowledgeoriented tasks. Focusing on the important domain of semantic relatedness algorithms and leveraging Clark's theory of common ground as a framework, we demonstrate that this assumption can be highly problematic. Using 7,921 semantic relatedness judgements from 72 scholars and 39 crowdworkers, we show that crowdworkers on Mechanical Turk produce significantly different semantic relatedness gold standard judgements than people from other communities. We also show that algorithms that perform well against Mechanical Turk gold standard datasets do significantly worse when evaluated against other communities' gold standards. Our results call into question the broad use of Mechanical Turk for the development of gold standard datasets and demonstrate the importance of understanding these datasets from a human-centered point-of-view. More generally, our findings problematize the notion that a universal gold standard dataset exists for all knowledge tasks.},
  isbn = {978-1-4503-2922-4},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Sen et al_2015_Turkers, Scholars, Arafat and Peace.pdf}
}

@inproceedings{shahSituatingSearch2022,
  title = {Situating {{Search}}},
  booktitle = {{{ACM SIGIR Conference}} on {{Human Information Interaction}} and {{Retrieval}}},
  author = {Shah, Chirag and Bender, Emily M.},
  year = {2022},
  month = mar,
  pages = {221--232},
  publisher = {{ACM}},
  address = {{Regensburg Germany}},
  doi = {10.1145/3498366.3505816},
  urldate = {2022-05-26},
  abstract = {Search systems, like many other applications of machine learning, have become increasingly complex and opaque. The notions of relevance, usefulness, and trustworthiness with respect to information were already overloaded and often difficult to articulate, study, or implement. Newly surfaced proposals that aim to use large language models to generate relevant information for a user's needs pose even greater threat to transparency, provenance, and user interactions in a search system. In this perspective paper we revisit the problem of search in the larger context of information seeking and argue that removing or reducing interactions in an effort to retrieve presumably more relevant information can be detrimental to many fundamental aspects of search, including information verification, information literacy, and serendipity. In addition to providing suggestions for counteracting some of the potential problems posed by such models, we present a vision for search systems that are intelligent and effective, while also providing greater transparency and accountability.},
  isbn = {978-1-4503-9186-3},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Shah_Bender_2022_Situating Search.pdf}
}

@incollection{sheldonross_varianceReduction_2006,
  title = {Variance {{Reduction Techniques}}},
  booktitle = {Simulation},
  author = {{Sheldon Ross}},
  year = {2006},
  edition = {Fourth Edition},
  pages = {137--207},
  publisher = {{Elsevier Academic Press}}
}

@misc{shermanPentari1998,
  title = {Pentari},
  author = {Sherman, Howard A.},
  year = {1998}
}

@misc{shortBronze2006,
  title = {Bronze},
  author = {Short, Emily},
  year = {2006}
}

@misc{shortCounterfeitMonkey2012,
  title = {Counterfeit {{Monkey}}},
  author = {Short, Emily},
  year = {2012},
  month = dec
}

@article{smal_explanationTree_2008,
  title = {Explanation for `{{Tree}} Isomorphism' Talk},
  author = {Smal, Alexander},
  year = {2008},
  langid = {english},
  file = {/home/morgan/Zotero/storage/CI8PGEDG/Smal - Explanation for â€˜Tree isomorphismâ€™ talk.pdf}
}

@misc{SodruzhestvoREFAL,
  title = {C{\cyrchar\cyro}{\cyrchar\cyrd}{\cyrchar\cyrr}{\cyrchar\cyru}{\cyrchar\cyrzh}{\cyrchar\cyre}{\cyrchar\cyrs}{\cyrchar\cyrt}{\cyrchar\cyrv}{\cyrchar\cyro} "{{{\cyrchar\CYRR}{\cyrchar\CYRE}{\cyrchar\CYRF}{\cyrchar\CYRA}{\cyrchar\CYRL}}}/{{{\cyrchar\CYRS}{\cyrchar\cyru}{\cyrchar\cyrp}{\cyrchar\cyre}{\cyrchar\cyrr}{\cyrchar\cyrk}{\cyrchar\cyro}{\cyrchar\cyrm}{\cyrchar\cyrp}{\cyrchar\cyri}{\cyrchar\cyrl}{\cyrchar\cyrya}{\cyrchar\cyrc}{\cyrchar\cyri}{\cyrchar\cyrya}}}"},
  urldate = {2022-04-27},
  howpublished = {http://www.refal.net/},
  file = {/home/morgan/Zotero/storage/2YVKHPRY/www.refal.net.html}
}

@misc{SortingScenes,
  title = {Sorting {{Scenes}}},
  urldate = {2022-05-11},
  howpublished = {https://manuals.finaldraft.com/articles/\#!final-draft-12-user-guide-mac/sorting-scenes},
  file = {/home/morgan/Zotero/storage/ILAZTM9L/articles.html}
}

@article{srivastavaRobustnessSpuriousCorrelations2020,
  title = {Robustness to {{Spurious Correlations}} via {{Human Annotations}}},
  author = {Srivastava, Megha and Hashimoto, Tatsunori and Liang, Percy},
  year = {2020},
  pages = {11},
  abstract = {The reliability of machine learning systems critically assumes that the associations between features and labels remain similar between training and test distributions. However, unmeasured variables, such as confounders, break this assumption{\textemdash}useful correlations between features and labels at training time can become useless or even harmful at test time. For example, high obesity is generally predictive for heart disease, but this relation may not hold for smokers who generally have lower rates of obesity and higher rates of heart disease. We present a framework for making models robust to spurious correlations by leveraging humans' common sense knowledge of causality. Specifically, we use human annotation to augment each training example with a potential unmeasured variable (i.e. an underweight patient with heart disease may be a smoker), reducing the problem to a covariate shift problem. We then introduce a new distributionally robust optimization objective over unmeasured variables (UV-DRO) to control the worst-case loss over possible testtime shifts. Empirically, we show improvements of 5{\textendash}10\% on a digit recognition task confounded by rotation, and 1.5{\textendash}5\% on the task of analyzing NYPD Police Stops confounded by location.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Srivastava et al_Robustness to Spurious Correlations via Human Annotations.pdf}
}

@article{starkPhysiognomicArtificialIntelligence2021,
  title = {Physiognomic {{Artificial Intelligence}}},
  author = {Stark, Luke and Hutson, Jevan},
  year = {2021},
  journal = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3927300},
  urldate = {2022-06-01},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Stark_Hutson_2021_Physiognomic Artificial Intelligence.pdf}
}

@article{storksRecentAdvancesNatural2020,
  title = {Recent {{Advances}} in {{Natural Language Inference}}: {{A Survey}} of {{Benchmarks}}, {{Resources}}, and {{Approaches}}},
  author = {Storks, Shane},
  year = {2020},
  month = feb,
  pages = {94},
  abstract = {In the NLP community, recent years have seen a surge of research activities that address machines' ability to perform deep language understanding which goes beyond what is explicitly stated in text, rather relying on reasoning and knowledge of the world. Many benchmark tasks and datasets have been created to support the development and evaluation of such natural language inference ability. As these benchmarks become instrumental and a driving force for the NLP research community, this paper aims to provide an overview of recent benchmarks, relevant knowledge resources, and state-of-the-art learning and inference approaches in order to support a better understanding of this growing field.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Storks_Recent Advances in Natural Language Inference.pdf}
}

@misc{stottDragonAdventure2003,
  title = {Dragon {{Adventure}}},
  author = {Stott, William},
  year = {2003}
}

@inproceedings{strubellEnergyPolicyConsiderations2019,
  title = {Energy and {{Policy Considerations}} for {{Deep Learning}} in {{NLP}}},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  year = {2019},
  pages = {3645--3650},
  publisher = {{Association for Computational Linguistics}},
  address = {{Florence, Italy}},
  doi = {10.18653/v1/P19-1355},
  urldate = {2022-05-27},
  abstract = {Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Strubell et al_2019_Energy and Policy Considerations for Deep Learning in NLP.pdf}
}

@misc{sutskeverSequenceSequenceLearning2014,
  title = {Sequence to {{Sequence Learning}} with {{Neural Networks}}},
  author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
  year = {2014},
  month = dec,
  number = {arXiv:1409.3215},
  eprint = {1409.3215},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-08-08},
  abstract = {Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Sutskever et al_2014_Sequence to Sequence Learning with Neural Networks.pdf}
}

@article{tanakaCommonsenseKnowledgeScene2022,
  title = {Commonsense {{Knowledge}} from {{Scene Graphs}} for {{Textual Environments}}},
  author = {Tanaka, Tsunehiko and Kimura, Daiki and Tatsubori, Michiaki},
  year = {2022},
  pages = {8},
  abstract = {Text-based games are becoming commonly used in reinforcement learning as real-world simulation environments. They are usually imperfect information games, and their interactions are only in the textual modality. To challenge these games, it is effective to complement the missing information by providing knowledge outside the game, such as human common sense. However, such knowledge has only been available from textual information in previous works. In this paper, we investigate the advantage of employing commonsense reasoning obtained from visual datasets such as scene graph datasets. In general, images convey more comprehensive information compared with text for humans. This property enables to extract commonsense relationship knowledge more useful for acting effectively in a game. We compare the statistics of spatial relationships available in Visual Genome (a scene graph dataset) and ConceptNet (a text-based knowledge) to analyze the effectiveness of introducing scene graph datasets. We also conducted experiments on a text-based game task that requires commonsense reasoning. Our experimental results demonstrated that our proposed methods have higher and competitive performance than existing state-ofthe-art methods.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Tanaka et al_Commonsense Knowledge from Scene Graphs for Textual Environments.pdf}
}

@article{tarjan_fibonacciHeaps_1987,
  title = {Fibonacci Heaps and Their Uses in Improved Network Optimization Algorithms},
  author = {Tarjan, Robert Endre and {Michael L. Fredman}},
  year = {1987},
  month = jul,
  journal = {Journal of the ACM},
  volume = {34},
  number = {3},
  pages = {596--615},
  issn = {0004-5411, 1557-735X},
  doi = {10.1145/28869.28874},
  urldate = {2023-04-26},
  langid = {english},
  file = {/home/morgan/Zotero/storage/SRQF6HF5/Fredman and Tarjan - 1987 - Fibonacci heaps and their uses in improved network.pdf}
}

@article{TeoriyaAlgorifmov1951,
  title = {{\cyrchar\CYRT}{\cyrchar\cyre}{\cyrchar\cyro}{\cyrchar\cyrr}{\cyrchar\cyri}{\cyrchar\cyrya} {\cyrchar\CYRA}{\cyrchar\cyrl}{\cyrchar\cyrg}{\cyrchar\cyro}{\cyrchar\cyrr}{\cyrchar\cyri}{\cyrchar\cyrf}{\cyrchar\cyrm}{\cyrchar\cyro}{\cyrchar\cyrv}},
  year = {1951},
  pages = {176--189}
}

@misc{tesslerActionAssemblySparse2020,
  title = {Action {{Assembly}}: {{Sparse Imitation Learning}} for {{Text Based Games}} with {{Combinatorial Action Spaces}}},
  shorttitle = {Action {{Assembly}}},
  author = {Tessler, Chen and Zahavy, Tom and Cohen, Deborah and Mankowitz, Daniel J. and Mannor, Shie},
  year = {2020},
  month = feb,
  number = {arXiv:1905.09700},
  eprint = {1905.09700},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-07-07},
  abstract = {We propose a computationally efficient algorithm that combines compressed sensing with imitation learning to solve text-based games with combinatorial action spaces. Specifically, we introduce a new compressed sensing algorithm, named IK-OMP, which can be seen as an extension to the Orthogonal Matching Pursuit (OMP). We incorporate IK-OMP into a supervised imitation learning setting and show that the combined approach (Sparse Imitation Learning, Sparse-IL) solves the entire text-based game of Zork1 with an action space of approximately 10 million actions given both perfect and noisy demonstrations.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Tessler et al_2020_Action Assembly.pdf}
}

@book{thrunProbabilisticRobotics2005,
  title = {Probabilistic {{Robotics}}},
  author = {Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
  editor = {Arkin, Ronald C.},
  year = {2005},
  month = aug,
  series = {Intelligent {{Robotics}} and {{Autonomous Agents}} Series},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA, USA}},
  abstract = {An introduction to the techniques and algorithms of the newest field in robotics.},
  isbn = {978-0-262-20162-9},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Thrun et al_2005_Probabilistic Robotics.pdf}
}

@article{torresPossibilityRisksArtificial2019,
  title = {The Possibility and Risks of Artificial General Intelligence},
  author = {Torres, Phil},
  year = {2019},
  month = may,
  journal = {Bulletin of the Atomic Scientists},
  volume = {75},
  number = {3},
  pages = {105--108},
  issn = {0096-3402, 1938-3282},
  doi = {10.1080/00963402.2019.1604873},
  urldate = {2022-05-27},
  abstract = {This article offers a survey of why artificial general intelligence (AGI) could pose an unprecedented threat to human survival on Earth. If we fail to get the ``control problem'' right before the first AGI is created, the default outcome could be total human annihilation. It follows that since an AI arms race would almost certainly compromise safety precautions during the AGI research and development phase, an arms race could prove fatal not just to states but for the entire human species. In a phrase, an AI arms race would be profoundly foolish. It could compromise the entire future of humanity.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Torres_2019_The possibility and risks of artificial general intelligence.pdf}
}

@book{truffautHitchcock2017,
  title = {Hitchcock},
  author = {Truffaut, Francois},
  year = {2017},
  month = jan,
  publisher = {{Faber \& Faber}},
  langid = {english}
}

@misc{turchinMetacompilationMetasystemTransitions,
  title = {Metacompilation:{{Metasystem Transitions}} + {{Supercompilation}}},
  author = {Turchin, Valentin},
  urldate = {2022-04-28},
  abstract = {Metacomputation is a computation which involves metasystem transitions(MST for short) from a computing machine M to a metamachine M' which controls, analyzes and imitates the work of M. Semantics-based program transformation, such as partial evaluation and supercompilation (SCP), is metacomputation. Metasystem transitions may be repeated, as when a program transformer gets transformed itsef. In this manner MST hierarchies of any height can be formed. The paper reviews one strain of research which was started in Russia in the late 1960s-early 1970s and became known for the development of supercompilation as a distinct method of program transformation. After a brief description of the history of this research line, the paper concentrates on those results and problems where supercompilation is combined with repeated metasystem transitions.},
  howpublished = {http://www.refal.net/doc/turchin/dag/dag.html},
  file = {/home/morgan/Zotero/storage/KZ8DVLMY/dag.html}
}

@inproceedings{turchinMetacomputation1996,
  title = {Metacomputation: {{Metasystem}} Transitions plus Supercompilation},
  shorttitle = {Metacomputation},
  booktitle = {Partial {{Evaluation}}},
  author = {Turchin, Valentin F.},
  editor = {Danvy, Olivier and Gl{\"u}ck, Robert and Thiemann, Peter},
  year = {1996},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {481--509},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-61580-6_24},
  abstract = {Metacomputation is a computation which involves meta-system transitions(MST for short) from a computing machine M to a metamachine M{${'}$} which controls, analyzes, and imitates the work of M. Semantics-based program transformation, such as partial evaluation and supercompilation (SCP), is metacomputation. Metasystem transitions may be repeated, as when a program transformer gets transformed itsef. In this manner MST hierarchies of any height can be formed.},
  isbn = {978-3-540-70589-5},
  langid = {english},
  keywords = {metacode,metacomputation,metasystem transition,MST-schemes,pattern-matching graphs,program transformation,Refal,self-application,supercompilation}
}

@misc{tuylsMultiStageEpisodicControl2022,
  title = {Multi-{{Stage Episodic Control}} for {{Strategic Exploration}} in {{Text Games}}},
  author = {Tuyls, Jens and Yao, Shunyu and Kakade, Sham and Narasimhan, Karthik},
  year = {2022},
  month = mar,
  eprint = {2201.01251},
  primaryclass = {cs},
  urldate = {2022-05-25},
  abstract = {Text adventure games present unique challenges to reinforcement learning methods due to their combinatorially large action spaces and sparse rewards. The interplay of these two factors is particularly demanding because large action spaces require extensive exploration, while sparse rewards provide limited feedback. This work proposes to tackle the explore-vs-exploit dilemma using a multi-stage approach that explicitly disentangles these two strategies within each episode. Our algorithm, called eXploit-Then-eXplore (XTX), begins each episode using an exploitation policy that imitates a set of promising trajectories from the past, and then switches over to an exploration policy aimed at discovering novel actions that lead to unseen state spaces. This policy decomposition allows us to combine global decisions about which parts of the game space to return to with curiosity-based local exploration in that space, motivated by how a human may approach these games. Our method significantly outperforms prior approaches by 27\% and 11\% average normalized score over 12 games from the Jericho benchmark (Hausknecht et al., 2020) in both deterministic and stochastic settings, respectively. On the game of Zork1, in particular, XTX obtains a score of 103, more than a 2x improvement over prior methods, and pushes past several known bottlenecks in the game that have plagued previous state-of-the-art methods.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Tuyls et al_2022_Multi-Stage Episodic Control for Strategic Exploration in Text Games.pdf}
}

@misc{twine,
  title = {Twine / {{An}} Open-Source Tool for Telling Interactive, Nonlinear Stories},
  author = {Klimas, Chris},
  urldate = {2022-09-01},
  howpublished = {https://twinery.org/},
  file = {/home/morgan/Zotero/storage/EW7BXTB6/twinery.org.html}
}

@misc{TwistyLittlePassages,
  title = {Twisty {{Little Passages}}},
  journal = {MIT Press},
  urldate = {2022-08-12},
  abstract = {A critical approach to interactive fiction, as literature and game.Interactive fiction{\textemdash}the best-known form of which is the text game or text adventure{\textemdash}ha...},
  langid = {american},
  file = {/home/morgan/Zotero/storage/HBBDW2ML/twisty-little-passages.html}
}

@article{umbrelloFutureWarCould2020,
  title = {The Future of War: Could Lethal Autonomous Weapons Make Conflict More Ethical?},
  shorttitle = {The Future of War},
  author = {Umbrello, Steven and Torres, Phil and De Bellis, Angelo F.},
  year = {2020},
  month = mar,
  journal = {AI \& SOCIETY},
  volume = {35},
  number = {1},
  pages = {273--282},
  issn = {0951-5666, 1435-5655},
  doi = {10.1007/s00146-019-00879-x},
  urldate = {2022-05-27},
  abstract = {Lethal Autonomous Weapons (LAWs) are robotic weapon systems, primarily of value to the military, that could engage in offensive or defensive actions without human intervention. This paper assesses and engages the current arguments for and against the use of LAWs through the lens of achieving more ethical warfare. Specific interest is given particularly to ethical LAWs, which are artificially intelligent weapon systems that make decisions within the bounds of their ethics-based code. To ensure that a wide, but not exhaustive, survey of the implications of employing such ethical devices to replace humans in warfare is taken into account, this paper will engage on matters related to current scholarship on the rejection or acceptance of LAWs{\textemdash}including contemporary technological shortcomings of LAWs to differentiate between targets and the behavioral and psychological volatility of humans{\textemdash}and current and proposed regulatory infrastructures for developing and using such devices. After careful consideration of these factors, this paper will conclude that only ethical LAWs should be used to replace human involvement in war, and, by extension of their consistent abilities, should remove humans from war until a more formidable discovery is made in conducting ethical warfare.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Umbrello et al_2020_The future of war.pdf}
}

@book{vallorArtificialIntelligenceEthics2017,
  title = {Artificial {{Intelligence}} and the {{Ethics}} of {{Self-Learning Robots}}},
  author = {Vallor, Shannon and Bekey, George A.},
  year = {2017},
  month = oct,
  volume = {1},
  publisher = {{Oxford University Press}},
  doi = {10.1093/oso/9780190652951.003.0022},
  urldate = {2022-05-27},
  abstract = {The convergence of robotics technology with the science of artificial intelligence is rapidly enabling the development of robots that emulate a wide range of intelligent human behaviors. Recent advances in machine learning techniques have produced artificial agents that can acquire highly complex skills formerly thought to be the exclusive province of human intelligence. These developments raise a host of new ethical concerns about the responsible design, manufacture, and use of robots enabled with artificial intelligence{\textemdash}particularly those equipped with self-learning capacities. While the potential benefits of self-learning robots are immense, their potential dangers are equally serious. While some warn of a future where AI escapes the control of its human creators or even turns against us, this chapter focuses on other, far less cinematic risks of AI that are much nearer to hand, requiring immediate study and action by technologists, lawmakers, and other stakeholders.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Vallor_Bekey_2017_Artificial Intelligence and the Ethics of Self-Learning Robots.pdf}
}

@book{vallorTechnologyVirtuesPhilosophical2016,
  title = {Technology and the Virtues: A Philosophical Guide to a Future Worth Wanting},
  shorttitle = {Technology and the Virtues},
  author = {Vallor, Shannon},
  year = {2016},
  publisher = {{Oxford University Press}},
  address = {{New York, NY}},
  isbn = {978-0-19-049851-1},
  langid = {english},
  lccn = {BJ59 .V34 2016},
  keywords = {Moral and ethical aspects,Technology,Virtues},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Vallor_2016_Technology and the virtues.pdf}
}

@misc{vanditmarschIntroductionLogicsKnowledge2015,
  title = {An {{Introduction}} to {{Logics}} of {{Knowledge}} and {{Belief}}},
  author = {{van Ditmarsch}, Hans and Halpern, Joseph Y. and {van der Hoek}, Wiebe and Kooi, Barteld},
  year = {2015},
  month = mar,
  number = {arXiv:1503.00806},
  eprint = {1503.00806},
  primaryclass = {cs},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.1503.00806},
  urldate = {2022-05-25},
  abstract = {This chapter provides an introduction to some basic concepts of epistemic logic, basic formal languages, their semantics, and proof systems. It also contains an overview of the handbook, and a brief history of epistemic logic and pointers to the literature.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Logic in Computer Science},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/van Ditmarsch et al_2015_An Introduction to Logics of Knowledge and Belief.pdf}
}

@misc{vickAxolotlProject2013,
  title = {The {{Axolotl Project}}},
  author = {Vick, Samantha},
  year = {2013}
}

@article{vuillemin_data_1978,
  title = {A Data Structure for Manipulating Priority Queues},
  author = {Vuillemin, Jean},
  year = {1978},
  month = apr,
  journal = {Communications of the ACM},
  volume = {21},
  number = {4},
  pages = {309--315},
  issn = {0001-0782},
  doi = {10.1145/359460.359478},
  urldate = {2023-04-25},
  abstract = {A data structure is described which can be used for representing a collection of priority queues. The primitive operations are insertion, deletion, union, update, and search for an item of earliest priority.},
  keywords = {binary trees,data structures,implementation of set operations,mergeable heaps,priority queues},
  file = {/home/morgan/Zotero/storage/ERUPD59P/Vuillemin - 1978 - A data structure for manipulating priority queues.pdf}
}

@misc{wangScienceWorldYourAgent2022,
  title = {{{ScienceWorld}}: {{Is}} Your {{Agent Smarter}} than a 5th {{Grader}}?},
  shorttitle = {{{ScienceWorld}}},
  author = {Wang, Ruoyao and Jansen, Peter and C{\^o}t{\'e}, Marc-Alexandre and Ammanabrolu, Prithviraj},
  year = {2022},
  month = mar,
  eprint = {2203.07540},
  primaryclass = {cs},
  urldate = {2022-05-25},
  abstract = {This paper presents a new benchmark, ScienceWorld, to test agents' scientific reasoning abilities in a new interactive text environment at the level of a standard elementary school science curriculum. Despite the recent transformer-based progress seen in adjacent fields such as question-answering, scientific text processing, and the wider area of natural language processing, we find that current state-of-the-art models are unable to reason about or explain learned science concepts in novel contexts. For instance, models can easily answer what the conductivity of a previously seen material is but struggle when asked how they would conduct an experiment in a grounded, interactive environment to find the conductivity of an unknown material. This begs the question of whether current models are simply retrieving answers by way of seeing a large number of similar input examples or if they have learned to reason about concepts in a reusable manner. We hypothesize that agents need to be grounded in interactive environments to achieve such reasoning capabilities. Our experiments provide empirical evidence supporting this hypothesis -- showing that a 1.5 million parameter agent trained interactively for 100k steps outperforms a 11 billion parameter model statically trained for scientific question-answering and reasoning via millions of expert demonstrations.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Wang et al_2022_ScienceWorld.pdf}
}

@article{whittakerSteepCostCapture2021,
  title = {The Steep Cost of Capture},
  author = {Whittaker, Meredith},
  year = {2021},
  month = nov,
  journal = {Interactions},
  volume = {28},
  number = {6},
  pages = {50--55},
  issn = {1072-5520, 1558-3449},
  doi = {10.1145/3488666},
  urldate = {2022-06-12},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Whittaker_2021_The steep cost of capture.pdf}
}

@misc{wigfullReturnKarn1996,
  title = {Return to {{Karn}}},
  author = {Wigfull, Patrick},
  year = {1996}
}

@inproceedings{wiren_comparisonRuleInvocation_1987,
  title = {A {{Comparison}} of {{Rule-Invocation Strategies}} in {{Context-Free Chart Parsing}}},
  booktitle = {Third {{Conference}} of the {{European Chapter}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Wiren, Mats},
  year = {1987},
  month = apr,
  publisher = {{Association for Computational Linguistics}},
  address = {{Copenhagen, Denmark}},
  urldate = {2023-05-05},
  file = {/home/morgan/Zotero/storage/W2NTAY2C/Wiren - 1987 - A Comparison of Rule-Invocation Strategies in Cont.pdf}
}

@misc{wiseDeephomeTelleenAdventure1999,
  title = {Deephome: {{A Telleen Adventure}}},
  author = {Wise, Joshua},
  year = {1999}
}

@unpublished{wortmanvaughanHumancenteredAgendaIntelligible2022,
  title = {A Human-Centered Agenda for Intelligible Machine Learning},
  author = {Wortman Vaughan, Jennifer and Wallach, Hanna},
  year = {2022},
  month = may,
  abstract = {To build machine learning systems that are reliable, trustworthy, and fair, we must be able to provide relevant stakeholders with an understanding of how these systems work. Yet what makes a system ``intelligible'' is difficult to pin down. Intelligibility is a fundamentally human-centered concept that lacks a one-size-fits-all solution. Although many intelligibility techniques have been proposed in the machine learning literature, there are many more open questions about how best to provide stakeholders with the information they need to achieve their desired goals. In this chapter, we begin with an overview of the intelligible machine learning landscape and give several examples of the diverse ways in which needs for intelligibility can arise. We provide an overview of the techniques for achieving intelligibility that have been proposed in the machine learning literature. We discuss the importance of taking a human-centered strategy when designing intelligibility techniques or when verifying that these techniques achieve their intended goals. We also argue that the notion of intelligibility should be expanded beyond machine learning models to other components of machine learning systems, such as datasets and performance metrics. Finally, we emphasize the necessity of tight integration between the machine learning and human{\textendash}computer interaction communities.},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Wortman Vaughan_Wallach_2022_A human-centered agenda for intelligible machine learning.pdf}
}

@misc{wyberTheatre1995,
  title = {Theatre},
  author = {Wyber, Brendon},
  year = {1995}
}

@article{xuDeepReinforcementLearning2020,
  title = {Deep {{Reinforcement Learning}} with {{Stacked Hierarchical Attention}} for {{Text-based Games}}},
  author = {Xu, Yunqiu and Chen, Ling and Zhou, Joey Tianyi and Fang, Meng},
  year = {2020},
  pages = {13},
  abstract = {We study reinforcement learning (RL) for text-based games, which are interactive simulations in the context of natural language. While different methods have been developed to represent the environment information and language actions, existing RL agents are not empowered with any reasoning capabilities to deal with textual games. In this work, we aim to conduct explicit reasoning with knowledge graphs for decision making, so that the actions of an agent are generated and supported by an interpretable inference procedure. We propose a stacked hierarchical attention mechanism to construct an explicit representation of the reasoning process by exploiting the structure of the knowledge graph. We extensively evaluate our method on a number of man-made benchmark games, and the experimental results demonstrate that our method performs better than existing text-based agents.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Xu et al_Deep Reinforcement Learning with Stacked Hierarchical Attention for Text-based.pdf}
}

@misc{xuPerceivingWorldQuestionguided2022,
  title = {Perceiving the {{World}}: {{Question-guided Reinforcement Learning}} for {{Text-based Games}}},
  shorttitle = {Perceiving the {{World}}},
  author = {Xu, Yunqiu and Fang, Meng and Chen, Ling and Du, Yali and Zhou, Joey Tianyi and Zhang, Chengqi},
  year = {2022},
  month = apr,
  eprint = {2204.09597},
  primaryclass = {cs},
  urldate = {2022-05-25},
  abstract = {Text-based games provide an interactive way to study natural language processing. While deep reinforcement learning has shown effectiveness in developing the game playing agent, the low sample efficiency and the large action space remain to be the two major challenges that hinder the DRL from being applied in the real world. In this paper, we address the challenges by introducing world-perceiving modules, which automatically decompose tasks and prune actions by answering questions about the environment. We then propose a two-phase training framework to decouple language learning from reinforcement learning, which further improves the sample efficiency. The experimental results show that the proposed method significantly improves the performance and sample efficiency. Besides, it shows robustness against compound error and limited pre-training data.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Xu et al_2022_Perceiving the World.pdf}
}

@misc{yaoKeepCALMExplore2020,
  title = {Keep {{CALM}} and {{Explore}}: {{Language Models}} for {{Action Generation}} in {{Text-based Games}}},
  shorttitle = {Keep {{CALM}} and {{Explore}}},
  author = {Yao, Shunyu and Rao, Rohan and Hausknecht, Matthew and Narasimhan, Karthik},
  year = {2020},
  month = oct,
  eprint = {2010.02903},
  primaryclass = {cs},
  urldate = {2022-05-25},
  abstract = {Text-based games present a unique challenge for autonomous agents to operate in natural language and handle enormous action spaces. In this paper, we propose the Contextual Action Language Model (CALM) to generate a compact set of action candidates at each game state. Our key insight is to train language models on human gameplay, where people demonstrate linguistic priors and a general game sense for promising actions conditioned on game history. We combine CALM with a reinforcement learning agent which re-ranks the generated action candidates to maximize in-game rewards. We evaluate our approach using the Jericho benchmark, on games unseen by CALM during training. Our method obtains a 69\% relative improvement in average game score over the previous state-of-the-art model. Surprisingly, on half of these games, CALM is competitive with or better than other models that have access to ground truth admissible actions. Code and data are available at https://github.com/princeton-nlp/calm-textgame.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Yao et al_2020_Keep CALM and Explore.pdf}
}

@misc{yaoReadingActingBlindfolded2021,
  title = {Reading and {{Acting}} While {{Blindfolded}}: {{The Need}} for {{Semantics}} in {{Text Game Agents}}},
  shorttitle = {Reading and {{Acting}} While {{Blindfolded}}},
  author = {Yao, Shunyu and Narasimhan, Karthik and Hausknecht, Matthew},
  year = {2021},
  month = apr,
  number = {arXiv:2103.13552},
  eprint = {2103.13552},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-05-25},
  abstract = {Text-based games simulate worlds and interact with players using natural language. Recent work has used them as a testbed for autonomous language-understanding agents, with the motivation being that understanding the meanings of words or semantics is a key component of how humans understand, reason, and act in these worlds. However, it remains unclear to what extent artificial agents utilize semantic understanding of the text. To this end, we perform experiments to systematically reduce the amount of semantic information available to a learning agent. Surprisingly, we find that an agent is capable of achieving high scores even in the complete absence of language semantics, indicating that the currently popular experimental setup and models may be poorly designed to understand and leverage game texts. To remedy this deficiency, we propose an inverse dynamics decoder to regularize the representation space and encourage exploration, which shows improved performance on several games including ZORK I. We discuss the implications of our findings for designing future agents with stronger semantic understanding.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Yao et al_2021_Reading and Acting while Blindfolded.pdf}
}

@misc{yuanCountingExploreGeneralize2019,
  title = {Counting to {{Explore}} and {{Generalize}} in {{Text-based Games}}},
  author = {Yuan, Xingdi and C{\^o}t{\'e}, Marc-Alexandre and Sordoni, Alessandro and Laroche, Romain and des Combes, Remi Tachet and Hausknecht, Matthew and Trischler, Adam},
  year = {2019},
  month = mar,
  number = {arXiv:1806.11525},
  eprint = {1806.11525},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-05-25},
  abstract = {We propose a recurrent RL agent with an episodic exploration mechanism that helps discovering good policies in text-based game environments. We show promising results on a set of generated text-based games of varying difficulty where the goal is to collect a coin located at the end of a chain of rooms. In contrast to previous text-based RL approaches, we observe that our agent learns policies that generalize to unseen games of greater difficulty.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {chain experiment,Computer Science - Computation and Language,Computer Science - Machine Learning,IF exploration,IF navigation,IF procedural benchmarks,reinforcement-learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Yuan et al_2019_Counting to Explore and Generalize in Text-based Games.pdf}
}

@misc{yuDerivingCommonsenseInference2020,
  title = {Deriving {{Commonsense Inference Tasks}} from {{Interactive Fictions}}},
  author = {Yu, Mo and Guo, Xiaoxiao and Feng, Yufei and Zhu, Xiaodan and Greenspan, Michael and Campbell, Murray},
  year = {2020},
  month = oct,
  eprint = {2010.09788},
  primaryclass = {cs},
  urldate = {2022-05-25},
  abstract = {Commonsense reasoning simulates the human ability to make presumptions about our physical world, and it is an indispensable cornerstone in building general AI systems. We propose a new commonsense reasoning dataset based on human's interactive fiction game playings as human players demonstrate plentiful and diverse commonsense reasoning. The new dataset mitigates several limitations of the prior art. Experiments show that our task is solvable to human experts with sufficient commonsense knowledge but poses challenges to existing machine reading models, with a big performance gap of more than 30\%.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Yu et al_2020_Deriving Commonsense Inference Tasks from Interactive Fictions.pdf}
}

@misc{yuSPIRITWRAK1996,
  title = {{{SPIRITWRAK}}},
  author = {Yu, D. S.},
  year = {1996}
}

@misc{zagurskiTrystFate1997,
  title = {Tryst of {{Fate}}},
  author = {Zagurski, G. M.},
  year = {1997}
}

@misc{zelinkaBuildingDynamicKnowledge2020,
  title = {Building {{Dynamic Knowledge Graphs}} from {{Text-based Games}}},
  author = {Zelinka, Mikul{\'a}{\v s} and Yuan, Xingdi and C{\^o}t{\'e}, Marc-Alexandre and Laroche, Romain and Trischler, Adam},
  year = {2020},
  month = jan,
  number = {arXiv:1910.09532},
  eprint = {1910.09532},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-07-07},
  abstract = {We are interested in learning how to update Knowledge Graphs (KG) from text. In this preliminary work, we propose a novel Sequence-to-Sequence (Seq2Seq) architecture to generate elementary KG operations. Furthermore, we introduce a new dataset for KG extraction built upon text-based game transitions (over 300k data points). We conduct experiments and discuss the results.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Zelinka et al_2020_Building Dynamic Knowledge Graphs from Text-based Games.pdf}
}

@misc{zelinkaUsingReinforcementLearning2018,
  title = {Using Reinforcement Learning to Learn How to Play Text-Based Games},
  author = {Zelinka, Mikul{\'a}{\v s}},
  year = {2018},
  month = jan,
  number = {arXiv:1801.01999},
  eprint = {1801.01999},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-05-25},
  abstract = {The ability to learn optimal control policies in systems where action space is defined by sentences in natural language would allow many interesting real-world applications such as automatic optimisation of dialogue systems. Textbased games with multiple endings and rewards are a promising platform for this task, since their feedback allows us to employ reinforcement learning techniques to jointly learn text representations and control policies. We present a general text game playing agent, testing its generalisation and transfer learning performance and showing its ability to play multiple games at once. We also present pyfiction, an open-source library for universal access to different text games that could, together with our agent that implements its interface, serve as a baseline for future research.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Text-based worlds/Zelinka_2018_Using reinforcement learning to learn how to play text-based games.pdf}
}

@misc{zhaoGenderBiasContextualized2019,
  title = {Gender {{Bias}} in {{Contextualized Word Embeddings}}},
  author = {Zhao, Jieyu and Wang, Tianlu and Yatskar, Mark and Cotterell, Ryan and Ordonez, Vicente and Chang, Kai-Wei},
  year = {2019},
  month = apr,
  number = {arXiv:1904.03310},
  eprint = {1904.03310},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-10-25},
  abstract = {In this paper, we quantify, analyze and mitigate gender bias exhibited in ELMo's contextualized word vectors. First, we conduct several intrinsic analyses and find that (1) training data for ELMo contains significantly more male than female entities, (2) the trained ELMo embeddings systematically encode gender information and (3) ELMo unequally encodes gender information about male and female entities. Then, we show that a state-of-the-art coreference system that depends on ELMo inherits its bias and demonstrates significant bias on the WinoBias probing corpus. Finally, we explore two methods to mitigate such gender bias and show that the bias demonstrated on WinoBias can be eliminated.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/home/morgan/Dropbox/eBooks/Articles/EmbeddingsPaper/Zhao et al. - 2019 - Gender Bias in Contextualized Word Embeddings.pdf}
}

@misc{zhaoGenderBiasCoreference2018,
  title = {Gender {{Bias}} in {{Coreference Resolution}}: {{Evaluation}} and {{Debiasing Methods}}},
  shorttitle = {Gender {{Bias}} in {{Coreference Resolution}}},
  author = {Zhao, Jieyu and Wang, Tianlu and Yatskar, Mark and Ordonez, Vicente and Chang, Kai-Wei},
  year = {2018},
  month = apr,
  number = {arXiv:1804.06876},
  eprint = {1804.06876},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-11-01},
  abstract = {We introduce a new benchmark, WinoBias, for coreference resolution focused on gender bias. Our corpus contains Winograd-schema style sentences with entities corresponding to people referred by their occupation (e.g. the nurse, the doctor, the carpenter). We demonstrate that a rule-based, a feature-rich, and a neural coreference system all link gendered pronouns to pro-stereotypical entities with higher accuracy than anti-stereotypical entities, by an average difference of 21.1 in F1 score. Finally, we demonstrate a data-augmentation approach that, in combination with existing word-embedding debiasing techniques, removes the bias demonstrated by these systems in WinoBias without significantly affecting their performance on existing coreference benchmark datasets. Our dataset and code are avialable at http://winobias.org.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/morgan/Dropbox/eBooks/Articles/EmbeddingsPaper/Zhao et al. - 2018 - Gender Bias in Coreference Resolution Evaluation .pdf}
}

@misc{zhaoLearningGenderNeutralWord2018,
  title = {Learning {{Gender-Neutral Word Embeddings}}},
  author = {Zhao, Jieyu and Zhou, Yichao and Li, Zeyu and Wang, Wei and Chang, Kai-Wei},
  year = {2018},
  month = aug,
  number = {arXiv:1809.01496},
  eprint = {1809.01496},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2022-10-31},
  abstract = {Word embedding models have become a fundamental component in a wide range of Natural Language Processing (NLP) applications. However, embeddings trained on human-generated corpora have been demonstrated to inherit strong gender stereotypes that reflect social constructs. To address this concern, in this paper, we propose a novel training procedure for learning gender-neutral word embeddings. Our approach aims to preserve gender information in certain dimensions of word vectors while compelling other dimensions to be free of gender influence. Based on the proposed method, we generate a GenderNeutral variant of GloVe (GN-GloVe). Quantitative and qualitative experiments demonstrate that GN-GloVe successfully isolates gender information without sacrificing the functionality of the embedding model.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/morgan/Dropbox/eBooks/Articles/EmbeddingsPaper/Zhao et al. - 2018 - Learning Gender-Neutral Word Embeddings.pdf}
}

@misc{zhouDeconstructingNLGEvaluation2022,
  title = {Deconstructing {{NLG Evaluation}}: {{Evaluation Practices}}, {{Assumptions}}, and {{Their Implications}}},
  shorttitle = {Deconstructing {{NLG Evaluation}}},
  author = {Zhou, Kaitlyn and Blodgett, Su Lin and Trischler, Adam and Daum{\'e} III, Hal and Suleman, Kaheer and Olteanu, Alexandra},
  year = {2022},
  month = may,
  number = {arXiv:2205.06828},
  eprint = {2205.06828},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-08-08},
  abstract = {There are many ways to express similar things in text, which makes evaluating natural language generation (NLG) systems difficult. Compounding this difficulty is the need to assess varying quality criteria depending on the deployment setting. While the landscape of NLG evaluation has been well-mapped, practitioners' goals, assumptions, and constraints{\textemdash}which inform decisions about what, when, and how to evaluate{\textemdash}are often partially or implicitly stated, or not stated at all. Combining a formative semi-structured interview study of NLG practitioners (N=18) with a survey study of a broader sample of practitioners (N=61), we surface goals, community practices, assumptions, and constraints that shape NLG evaluations, examining their implications and how they embody ethical considerations.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Zhou et al_2022_Deconstructing NLG Evaluation.pdf}
}

@misc{zmachine,
  title = {The {{Z-Machine Standards Document}}},
  urldate = {2022-08-11},
  howpublished = {https://www.inform-fiction.org/zmachine/standards/z1point1/},
  file = {/home/morgan/Zotero/storage/NGZTQICB/z1point1.html}
}

@article{zomickLinguisticAnalysisSchizophrenia2019,
  title = {Linguistic {{Analysis}} of {{Schizophrenia}} in {{Reddit Posts}}},
  author = {Zomick, Jonathan and Levitan, Sarah Ita and Serper, Mark},
  year = {2019},
  month = jun,
  pages = {10},
  abstract = {We explore linguistic indicators of schizophrenia in Reddit discussion forums. Schizophrenia (SZ) is a chronic mental disorder that affects a person's thoughts and behaviors. Identifying and detecting signs of SZ is difficult given that SZ is relatively uncommon, affecting approximately 1\% of the US population, and people suffering with SZ often believe that they do not have the disorder. Linguistic abnormalities are a hallmark of SZ and many of the illness's symptoms are manifested through language. In this paper we leverage the vast amount of data available from social media and use statistical and machine learning approaches to study linguistic characteristics of SZ. We collected and analyzed a large corpus of Reddit posts from users claiming to have received a formal diagnosis of SZ and identified several linguistic features that differentiated these users from a control (CTL) group. We compared these results to other findings on social media linguistic analysis and SZ. We also developed a machine learning classifier to automatically identify self-identified users with SZ on Reddit.},
  langid = {english},
  file = {/Users/morgan/Dropbox/eBooks/Articles/Ethics/Zomick et al_2019_Linguistic Analysis of Schizophrenia in Reddit Posts.pdf}
}

@article{Zork2022,
  title = {Zork {{I}}},
  year = {2022},
  month = apr,
  journal = {Wikipedia},
  urldate = {2022-05-19},
  abstract = {Zork: The Great Underground Empire - Part I, later known as Zork I, is an interactive fiction computer game written by Marc Blank, Dave Lebling, Bruce Daniels, and Tim Anderson and published by Infocom in 1980. It was the first game in the Zork trilogy and was released for a wide range of computer systems, followed by Zork II and Zork III. It was Infocom's first game, and sold 378,000 copies by 1986.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1081245440},
  file = {/home/morgan/Zotero/storage/KXPVCY9S/Zork_I.html}
}

@misc{ZoteroConnectors,
  title = {Zotero | {{Connectors}}},
  urldate = {2022-10-25},
  howpublished = {https://www.zotero.org/download/connectors},
  file = {/home/morgan/Zotero/storage/YBR6WYW5/connectors.html}
}

@misc{ZoteroConnectorsa,
  title = {Zotero | {{Connectors}}},
  urldate = {2022-10-25},
  howpublished = {https://www.zotero.org/download/connectors},
  file = {/home/morgan/Zotero/storage/8SIPZRXW/connectors.html}
}
